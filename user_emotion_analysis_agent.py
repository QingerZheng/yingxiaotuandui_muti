from typing import List, Dict, Optional, Any
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END

from Configurations import Configuration
from states import AgentState, EmotionalState, CustomerIntent, AppointmentInfo, DebugInfo
from json_parser_utils import robust_json_parse, create_fallback_dict
import asyncio
class Output(TypedDict):
    """å­å›¾çš„è¾“å‡ºçŠ¶æ€ - åªåŒ…å«æœ€ç»ˆå›å¤"""
    agent_temperature:Optional[float]
    emotional_state: Optional[EmotionalState]
    customer_intent: Optional[CustomerIntent]
    appointment_info: Optional[AppointmentInfo]
    customer_info:Optional[Dict[str, str]]
    debug_info: Optional[DebugInfo]
    candidate_actions: List[str]  # å€™é€‰è¡ŒåŠ¨
    invitation_status: Optional[int]
    invitation_time: Optional[int] # 13ä½æ¯«ç§’æ—¶é—´æˆ³
    invitation_project: Optional[str]

def analyze_sentiment_node(state: any, config=None):
    """
    æ ¹æ®å½“å‰çš„æƒ…æ„ŸçŠ¶æ€ï¼ŒåŠ¨æ€è®¾ç½®åŠ©æ‰‹çš„æ¸©åº¦ï¼ˆåˆ›é€ æ€§ï¼‰ã€‚
    å‰æœŸå…¶å®å¯ä»¥ä¸ç”¨è¿™ä¸ªæ¨¡å—7/3
    """
    user_requires_message = state["user_requires_message"]
    if not user_requires_message:  # ç”¨æˆ·æ²¡æœ‰å‘æ¶ˆæ¯ç»™é”€å”®ï¼Œä¸éœ€è¦å›å¤ï¼Œç›´æ¥é€€å‡ºè¿™ä¸ªèŠ‚ç‚¹
        return state

    # æ­£ç¡®è®¿é—® internal_monologueï¼Œå®ƒåœ¨ debug_info å¯¹è±¡å†…éƒ¨
    debug_info = state.get("debug_info",DebugInfo())
    internal_monologue = debug_info.internal_monologue if debug_info and debug_info.internal_monologue else []
    emotional_state = state.get("emotional_state", EmotionalState())  # æˆ‘ä»¬ä»è¿™é‡Œè·å–æƒ…æ„Ÿ
    verbose = state.get("verbose", False)  # ç°åœ¨å¯ä»¥ç›´æ¥ä» state è·å–

    if not emotional_state:
        # å¦‚æœæ²¡æœ‰æƒ…æ„ŸçŠ¶æ€ï¼Œä½¿ç”¨é»˜è®¤æ¸©åº¦
        return {"agent_temperature": 0.6}

    # åŸºäºèˆ’é€‚åº¦å’Œç†Ÿæ‚‰åº¦æ¥è®¾å®šæ¸©åº¦
    # å¦‚æœç”¨æˆ·æ„Ÿåˆ°èˆ’é€‚å’Œé«˜å…´ï¼Œæˆ‘ä»¬è¯´è¯çš„æ–¹å¼å°±ä¼šæ›´æ´»æ³¼ï¼Œæ›´åƒæœ‹å‹ã€‚
    # ä½†å…¶å®è¿™éƒ¨åˆ†ï¼Œåº”è¯¥åœ¨æ¨¡å‹æ•²å®šåå†åšè¯„ä¼°ï¼Œå› ä¸ºæ¯ä¸ªæ¨¡å‹çš„é£æ ¼å¹¶ä¸åŒã€‚
    comfort = emotional_state.comfort_level
    familiarity = emotional_state.familiarity_level

    agent_temperature = state.get("agent_temperature", 0.5)  # é»˜è®¤å€¼ï¼Œqwenä½¿ç”¨ä½æ¸©ï¼Œé¿å…è¿‡åº¦æ´»è·ƒ
    if comfort > 0.6 and familiarity > 0.5:
        agent_temperature = 0.6  # æ›´å¯Œåˆ›é€ æ€§ã€æ›´åƒæœ‹å‹
    elif comfort < 0.3:
        agent_temperature = 0.6  # æ›´ä¿å®ˆã€æ›´è°¨æ…

    new_monologue = internal_monologue + [
        f"æ¸©åº¦è®¾å®šï¼šæ ¹æ®å½“å‰æƒ…æ„Ÿ (èˆ’é€‚åº¦:{comfort:.2f}, ç†Ÿæ‚‰åº¦:{familiarity:.2f})ï¼Œè®¾å®šæ¸©åº¦ä¸º {agent_temperature}ã€‚"]

    # åªåœ¨verboseæ¨¡å¼ä¸‹è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    if verbose:
        print(f"[DEBUG] æƒ…æ„Ÿåˆ†æèŠ‚ç‚¹: æ¸©åº¦è®¾å®šä¸º {agent_temperature}")

    # æ›´æ–° debug_info ä¸­çš„ internal_monologue
    updated_debug_info = DebugInfo(
        current_stage=debug_info.current_stage if debug_info else "initial_contact",
        emotional_state=debug_info.emotional_state if debug_info else EmotionalState(),
        internal_monologue=new_monologue
    )

    return {
        "agent_temperature": agent_temperature,
        "debug_info": updated_debug_info,
    }


async def _design_node(state: AgentState, config=None) -> Dict[str, Any]:
    """
    æ™ºèƒ½å†³ç­–èŠ‚ç‚¹ï¼Œé‡æ–°è®¾è®¡ä¸ºæœåŠ¡å¯¼å‘è€Œéé”€å”®å¯¼å‘ã€‚
    å…è®¸"æ­£ç¡®çš„ç¼ºç‚¹"ï¼Œè¡¨ç°å¾—æ›´åŠ è‡ªç„¶å’Œäººæ€§åŒ–ã€‚
    """
    user_requires_message = state["user_requires_message"]
    if not user_requires_message:#ç”¨æˆ·æ²¡æœ‰å‘æ¶ˆæ¯ç»™é”€å”®ï¼Œä¸éœ€è¦å›å¤ï¼Œç›´æ¥é€€å‡ºè¿™ä¸ªèŠ‚ç‚¹
        return state

    # æ­£ç¡®è®¿é—® internal_monologueï¼Œå®ƒåœ¨ debug_info å¯¹è±¡å†…éƒ¨
    debug_info = state.get("debug_info")
    internal_monologue = debug_info.internal_monologue if debug_info and debug_info.internal_monologue else []
    verbose = state.get("verbose", False)  # ç°åœ¨å¯ä»¥ç›´æ¥ä» state è·å–

    # 1. è°ƒç”¨çŠ¶æ€è¯„ä¼°å™¨ï¼Œè·å–æœ€æ–°çš„æƒ…æ„ŸçŠ¶æ€
    from blocks.state_evaluator import evaluate_state
    from blocks.intent_analyzer import analyze_customer_intent, update_appointment_info
    state_data=dict(state)

    # å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªå·¥å…·è°ƒç”¨
    evaluation_result, intent_result,judge_invitation_result = await asyncio.gather(
                asyncio.to_thread(evaluate_state.invoke, {"state_dict": state_data}),
        asyncio.to_thread(analyze_customer_intent.invoke, {"state_dict": state_data}),
        asyncio.to_thread(judge_invitation_state.invoke, {"state_dict": state_data, "config": config}),
        return_exceptions=True
    )
    
    # å¤„ç†å¼‚å¸¸æƒ…å†µ
    if isinstance(evaluation_result, Exception):
        print(f"çŠ¶æ€è¯„ä¼°å¤±è´¥: {evaluation_result}")
        evaluation_result = {}
    if isinstance(intent_result, Exception):
        print(f"æ„å›¾åˆ†æå¤±è´¥: {intent_result}")
        intent_result = {}
    if isinstance(judge_invitation_result, Exception):
        print(f"é‚€çº¦çŠ¶æ€åˆ¤æ–­å¤±è´¥: {judge_invitation_result}")
        judge_invitation_result = {}



    # æ›´æ–°çŠ¶æ€ã€‚å¦‚æœè¯„ä¼°å¤±è´¥ï¼Œåˆ™ä½¿ç”¨æ—§çŠ¶æ€
    # å®‰å…¨åœ°è·å–æƒ…æ„ŸçŠ¶æ€
    from json_parser_utils import safe_create_emotional_state
    
    if "emotional_state" in evaluation_result and evaluation_result["emotional_state"] is not None:
        current_emotional_state = safe_create_emotional_state(evaluation_result["emotional_state"])
    else:
        # ä»çŠ¶æ€ä¸­è·å–ç°æœ‰çš„æƒ…æ„ŸçŠ¶æ€ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºæ–°çš„
        existing_state = state.get("emotional_state")
        current_emotional_state = safe_create_emotional_state(existing_state)
    
    customer_intent = evaluation_result.get("customer_intent_level", state.get("customer_intent_level", "low"))
    customer_info = evaluation_result.get("customer_info", state.get("customer_info", {}))
    current_customer_intent = intent_result.get("customer_intent")


    # 3. æ–°å¢ï¼šæ›´æ–°é¢„çº¦ä¿¡æ¯
    appointment_updates = {}
    if current_customer_intent:
        appointment_updates = update_appointment_info(state, current_customer_intent)

    # åˆå¹¶é¢„çº¦ä¿¡æ¯æ›´æ–°
    current_appointment_info = state.get("appointment_info")
    if appointment_updates.get("appointment_info"):
        current_appointment_info = appointment_updates["appointment_info"]

    internal_monologue.append(f"æƒ…æ„Ÿè¯„ä¼°å®Œæˆ: {current_emotional_state.model_dump_json()}")
    internal_monologue.append(f"å®¢æˆ·æ„å‘è¯„ä¼°: {customer_intent}")
    if current_customer_intent:
        internal_monologue.append(
            f"è¡Œä¸ºæ„å›¾è¯†åˆ«: {current_customer_intent.intent_type} (ç½®ä¿¡åº¦: {current_customer_intent.confidence:.2f})")
        if current_customer_intent.extracted_info:
            internal_monologue.append(f"æå–ä¿¡æ¯: {current_customer_intent.extracted_info}")
    if current_appointment_info:
        internal_monologue.append(
            f"é¢„çº¦çŠ¶æ€: {current_appointment_info.appointment_status}, æ—¶é—´: {current_appointment_info.preferred_time or 'æœªå®š'}")

    if verbose:
        print(f"[DEBUG] ç­–ç•¥è®¾è®¡èŠ‚ç‚¹: å®¢æˆ·æ„å‘={customer_intent}, ä¿¡ä»»åº¦={current_emotional_state.trust_level:.2f}")

    # 2. æ”¹è¿›å¯¹è¯é˜¶æ®µ - æ›´è‡ªç„¶çš„æ¨è¿›é€»è¾‘
    # ä» debug_info ä¸­è·å– current_stage
    current_stage = debug_info.current_stage if debug_info and debug_info.current_stage else "initial_contact"
    trust_level = current_emotional_state.trust_level
    comfort_level = current_emotional_state.comfort_level
    familiarity_level = current_emotional_state.familiarity_level
    turn_count = state.get("turn_count", 0)

    new_stage = current_stage  # é»˜è®¤ä¿æŒå½“å‰é˜¶æ®µ

    # æ”¹è¿›çš„é˜¶æ®µæ¨è¿›é€»è¾‘ï¼ˆä¿æŒåŸæœ‰é˜¶æ®µåç§°ï¼‰
    if current_stage == "initial_contact":
        # é˜¶æ®µ1ï¼šåˆæ¬¡æ¥è§¦ - è‡ªç„¶é—®å€™ï¼Œå»ºç«‹åŸºç¡€è¿æ¥
        if turn_count >= 1 and comfort_level > 0.2:
            new_stage = "ice_breaking"
    elif current_stage == "ice_breaking":
        # é˜¶æ®µ2ï¼šè½»æ¾ç ´å†° - å»ºç«‹çœŸå®è¿æ¥ï¼Œå…è®¸"ç¼ºé™·"
        if familiarity_level > 0.3:
            new_stage = "subtle_expertise"
    elif current_stage == "subtle_expertise":
        # é˜¶æ®µ3ï¼šå±•ç¤ºä¸“ä¸š - å®¢è§‚å±•ç¤ºï¼Œéå¤¸å¤§å®£ä¼ 
        if trust_level > 0.4:
            new_stage = "pain_point_mining"
    elif current_stage == "pain_point_mining":
        # é˜¶æ®µ4ï¼šäº†è§£éœ€æ±‚ - çœŸè¯šè¯¢é—®ï¼Œéæ¨é”€å¼
        if trust_level > 0.6 and customer_intent in ["medium", "high"]:
            new_stage = "solution_visualization"
    elif current_stage == "solution_visualization":
        # é˜¶æ®µ5ï¼šè§£å†³æ–¹æ¡ˆ - ååŠ©å†³ç­–ï¼Œéå¼ºåˆ¶æ¨é”€
        if trust_level > 0.7 and customer_intent == "high":
            new_stage = "natural_invitation"

    # è‡ªç„¶å›é€€æœºåˆ¶ï¼šå¦‚æœå®¢æˆ·ä¸èˆ’æœï¼Œå›åˆ°æ›´è½»æ¾çš„é˜¶æ®µ
    if comfort_level < 0.3 and current_stage not in ["initial_contact", "ice_breaking"]:
        new_stage = "ice_breaking"  # è‡ªç„¶å›é€€åˆ°è½»æ¾ç ´å†°
        internal_monologue.append(f"æ£€æµ‹åˆ°èˆ’é€‚åº¦è¿‡ä½ ({comfort_level:.2f})ï¼Œè‡ªç„¶å›é€€åˆ°è½»æ¾ç ´å†°")
    elif trust_level < 0.2 and current_stage not in ["initial_contact"]:
        new_stage = "initial_contact"  # é‡æ–°å¼€å§‹
        internal_monologue.append(f"æ£€æµ‹åˆ°ä¿¡ä»»åº¦è¿‡ä½ ({trust_level:.2f})ï¼Œé‡æ–°å¼€å§‹å¯¹è¯")

    if new_stage != current_stage:
        internal_monologue.append(
            f"è‡ªç„¶æµç¨‹æ¨è¿›: '{current_stage}' â†’ '{new_stage}' (ä¿¡ä»»{trust_level:.2f}/èˆ’é€‚{comfort_level:.2f}/ç†Ÿæ‚‰{familiarity_level:.2f})")

    # 3. æ”¹è¿›åŠ¨ä½œå†³ç­– - åŸºäºç°æœ‰æ¨¡å—ï¼Œè®©è¡Œä¸ºæ›´è‡ªç„¶
    candidate_actions = []

    # ä¼˜å…ˆçº§0ï¼šå¤„ç†é‚€çº¦ç¡®è®¤çŠ¶æ€ï¼ˆæ–°å¢ï¼‰
    invitation_status = judge_invitation_result.get("invitation_status")
    if invitation_status == 1:
        # å®¢æˆ·å·²ç¡®è®¤é‚€çº¦ï¼Œåº”è¯¥è¿›è¡Œç¡®è®¤å’Œåç»­å®‰æ’
        candidate_actions = ["active_close", "value_display"]
        internal_monologue.append(f"æ£€æµ‹åˆ°é‚€çº¦ç¡®è®¤çŠ¶æ€ï¼Œè¿›è¡Œé¢„çº¦ç¡®è®¤å’Œåç»­å®‰æ’")
    
    # ä¼˜å…ˆçº§1ï¼šå¤„ç†æ˜ç¡®çš„é¢„çº¦æ„å›¾
    elif current_customer_intent and current_customer_intent.intent_type in ["appointment_request", "time_confirmation",
                                                                           "ready_to_book"]:
        if current_customer_intent.confidence > 0.8:
            # é«˜ç½®ä¿¡åº¦ï¼šä½¿ç”¨è‡ªç„¶é‚€çº¦
            candidate_actions = ["active_close", "value_display"]
            internal_monologue.append(f"æ£€æµ‹åˆ°æ˜ç¡®é¢„çº¦éœ€æ±‚ï¼Œè¿›è¡Œè‡ªç„¶é‚€çº¦")
        else:
            # ä½ç½®ä¿¡åº¦ï¼šå…ˆäº†è§£éœ€æ±‚
            candidate_actions = ["needs_analysis", "value_display"]
            internal_monologue.append(f"é¢„çº¦æ„å›¾ä¸æ˜ç¡®ï¼Œå…ˆäº†è§£å…·ä½“éœ€æ±‚")

    # ä¼˜å…ˆçº§2ï¼šå¤„ç†ä¿¡æ¯å’¨è¯¢
    elif current_customer_intent and current_customer_intent.intent_type == "info_seeking":
        # æ˜ç¡®éœ€æ±‚æ—¶ä¼˜å…ˆæä¾›ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŒ–æ˜éœ€æ±‚
        candidate_actions = ["value_display"]
        # åªæœ‰åœ¨æä¾›åŸºæœ¬ä¿¡æ¯åï¼Œæ‰è€ƒè™‘äº†è§£ç»†èŠ‚
        if familiarity_level > 0.4:  # å·²ç»æœ‰ä¸€å®šåŸºç¡€æ—¶æ‰è¯¢é—®ç»†èŠ‚
            candidate_actions.append("needs_analysis")
        internal_monologue.append(f"å®¢æˆ·å¯»æ±‚ä¿¡æ¯ï¼Œä¼˜å…ˆæä¾›é¡¹ç›®ä»‹ç»")

    # ä¼˜å…ˆçº§3ï¼šå¤„ç†ä»·æ ¼è¯¢é—®ï¼ˆçœŸå®å›åº”è€Œéé”€å”®è¯æœ¯ï¼‰
    elif current_customer_intent and current_customer_intent.intent_type == "price_inquiry":
        candidate_actions = ["value_display", "value_pitch"]
        if trust_level > 0.5:
            candidate_actions.append("active_close")  # é«˜ä¿¡ä»»æ—¶å¯ä»¥æ¨è¿›
        internal_monologue.append(f"ä»·æ ¼å’¨è¯¢ï¼Œæä¾›çœŸå®ä¿¡æ¯")

    # ä¼˜å…ˆçº§4ï¼šå¤„ç†é¡¾è™‘ï¼ˆç†è§£è€Œéåé©³ï¼‰
    elif current_customer_intent and current_customer_intent.intent_type == "concern_raised":
        candidate_actions = ["stress_response", "rapport_building"]
        if comfort_level < 0.4:
            candidate_actions.append("rapport_building")  # èˆ’é€‚åº¦ä½æ—¶é‡å»ºå…³ç³»
        internal_monologue.append(f"å®¢æˆ·æœ‰é¡¾è™‘ï¼Œç»™äºˆç†è§£å’Œç¼“è§£")

    # ä¼˜å…ˆçº§5ï¼šåŸºäºé˜¶æ®µçš„è‡ªç„¶å¯¹è¯æµç¨‹
    else:
        # æ ¹æ®å½“å‰é˜¶æ®µå†³å®šè‡ªç„¶å›åº”ç­–ç•¥
        if new_stage == "initial_contact":
            candidate_actions = ["greeting","needs_analysis", "value_display"]
        elif new_stage == "ice_breaking":
            candidate_actions = ["rapport_building", "needs_analysis", "value_display"]
            # å¶å°”å…è®¸"ç¼ºé™·"ï¼šç®€çŸ­å›å¤
            if turn_count % 4 == 0:  # å¶å°”è¡¨ç°å¾—ä¸é‚£ä¹ˆå®Œç¾
                candidate_actions = ["rapport_building"]  # ä¿æŒç®€æ´
        elif new_stage == "subtle_expertise":
            candidate_actions = ["value_display", "needs_analysis"]
            if familiarity_level > 0.4:
                candidate_actions.append("needs_analysis")
        elif new_stage == "pain_point_mining":
            # æ ¹æ®å®¢æˆ·éœ€æ±‚æ˜ç¡®ç¨‹åº¦è°ƒæ•´ç­–ç•¥
            if current_customer_intent and current_customer_intent.intent_type == "info_seeking":
                # å¦‚æœå®¢æˆ·å·²ç»è¡¨è¾¾æ˜ç¡®éœ€æ±‚ï¼Œç›´æ¥æä¾›ä¿¡æ¯
                candidate_actions = ["value_display", "needs_analysis"]
            else:
                # å¦åˆ™æ‰è¿›è¡Œéœ€æ±‚æŒ–æ˜
                candidate_actions = ["needs_analysis", "pain_point_test"]
                if trust_level > 0.6:
                    candidate_actions.append("value_display")
        elif new_stage == "solution_visualization":
            candidate_actions = ["value_pitch", "value_display"]
            if customer_intent == "high":
                candidate_actions.append("active_close")
        elif new_stage == "natural_invitation":
            candidate_actions = ["active_close"]
            if customer_intent != "high":
                candidate_actions.append("value_pitch")

    #     # æ–°å¢ï¼šåŸºäºè¯­ä¹‰çš„åŠ¨ä½œå»ºè®®--7/18å‡Œæ™¨â€”â€”æ•ˆæœå¾ˆå·®
    #     last_user_message = ''
    #     for msg in reversed(state.get("messages", [])):
    #         if msg.type == 'human':
    #             last_user_message = msg.content
    #             break
    #     if last_user_message:
    #         feedback_sampler, _ = SamplerFactory.get_sampler_and_cost(state.get("feedback_model") or "o3")
    #         semantic_prompt = f'''
    # ä½ æ˜¯ä¸€ä¸ªå¯¹è¯ç­–ç•¥ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æœ€åæ¶ˆæ¯"{last_user_message}"ï¼Œä»ä»¥ä¸‹åŠ¨ä½œä¸­å»ºè®®1-3ä¸ªæœ€åˆé€‚çš„ï¼š
    # å¯ç”¨åŠ¨ä½œ: greeting, rapport_building, needs_analysis, value_display, stress_response, pain_point_test, value_pitch, active_close, reverse_probe
    # è¾“å‡ºJSON: {{"suggested_actions": ["action1", "action2"]}}
    #         '''
    #         semantic_response, _ = feedback_sampler([{'role': 'user', 'content': semantic_prompt}], temperature=0.1, response_format='json_object')
    #         try:
    #             suggested = json.loads(semantic_response).get('suggested_actions', [])
    #             candidate_actions.extend(suggested)
    #             internal_monologue.append(f'è¯­ä¹‰å»ºè®®åŠ¨ä½œ: {suggested}')
    #         except:
    #             pass

    # æ™ºèƒ½ç­–ç•¥è°ƒæ•´ï¼šè®©è¡Œä¸ºæ›´è‡ªç„¶å’Œè´´è¿‘çœŸäºº

    # 1. æ ¹æ®æƒ…æ„ŸçŠ¶æ€è°ƒæ•´ç­–ç•¥
    if trust_level < 0.3:
        # ä¿¡ä»»åº¦ä½æ—¶ï¼Œä¼˜å…ˆå»ºç«‹å…³ç³»
        candidate_actions = ["rapport_building", "stress_response", "needs_analysis"]
        internal_monologue.append(f"ä¿¡ä»»åº¦è¿‡ä½ ({trust_level:.2f})ï¼Œä¼˜å…ˆå»ºç«‹å…³ç³»")
    elif comfort_level < 0.2 and new_stage in ["solution_visualization", "natural_invitation"]:
        # èˆ’é€‚åº¦ä½æ—¶ï¼Œå›é€€åˆ°ç¼“è§£å‹åŠ›
        candidate_actions.insert(0, "stress_response")
        internal_monologue.append(f"èˆ’é€‚åº¦è¿‡ä½ ({comfort_level:.2f})ï¼Œä¼˜å…ˆç¼“è§£å‹åŠ›")

    # 2. æ„å‘ç­‰çº§ç‰¹æ®Šå¤„ç†
    if customer_intent == "fake_high" and "reverse_probe" not in candidate_actions:
        candidate_actions.append("reverse_probe")  # è¯†åˆ«è™šå‡é«˜æ„å‘
        internal_monologue.append(f"æ£€æµ‹åˆ°è™šå‡é«˜æ„å‘ï¼Œæ·»åŠ åå‘è¯•æ¢")
    elif customer_intent == "low" and new_stage in ["solution_visualization", "natural_invitation"]:
        # ä½æ„å‘å®¢æˆ·ä¸åº”è¯¥è¿›å…¥é«˜å‹é”€å”®é˜¶æ®µ
        candidate_actions = ["rapport_building", "needs_analysis", "stress_response"]
        internal_monologue.append(f"ä½æ„å‘å®¢æˆ·ï¼Œå›é€€åˆ°åŸºç¡€äº¤æµ")

    # 3. è‡ªç„¶æœç´¢ç©ºé—´ç®¡ç†
    search_space_size = len(candidate_actions)

    if search_space_size == 1:
        # é€‚å½“æ‰©å±•ï¼Œä¿æŒçµæ´»æ€§
        primary_action = candidate_actions[0]

        if primary_action == "active_close":
            if comfort_level < 0.6:
                candidate_actions.append("stress_response")
            if trust_level > 0.7:
                candidate_actions.append("value_display")
        elif primary_action in ["value_display", "value_pitch"]:
            candidate_actions.append("needs_analysis")
            if trust_level > 0.6:
                candidate_actions.append("active_close")
        elif primary_action == "stress_response":
            candidate_actions.append("rapport_building")

        internal_monologue.append(f"æ‰©å±•æœç´¢ç©ºé—´: {primary_action} â†’ {candidate_actions}")

    elif search_space_size > 3:
        # ä¿æŒåˆç†èŒƒå›´
        candidate_actions = candidate_actions[:3]
        internal_monologue.append(f"é™åˆ¶æœç´¢ç©ºé—´ä¸º3ä¸ªé€‰é¡¹")

    # ç¡®ä¿è‡³å°‘æœ‰åŸºç¡€å›åº”èƒ½åŠ›
    if not candidate_actions:
        candidate_actions = ["rapport_building"]
        internal_monologue.append(f"å…œåº•ç­–ç•¥ï¼šä½¿ç”¨åŸºç¡€å…³ç³»å»ºç«‹")

    final_search_space = len(candidate_actions)
    decision_context = f"é˜¶æ®µ:{new_stage}, æƒ…æ„Ÿ:{customer_intent}, ä¿¡ä»»:{trust_level:.2f}"
    if current_customer_intent:
        decision_context += f", æ„å›¾:{current_customer_intent.intent_type}"
    internal_monologue.append(f"ç­–ç•¥å†³ç­– ({decision_context}) -> å€™é€‰åŠ¨ä½œ: {candidate_actions}")

    # æ„å»ºè¿”å›çŠ¶æ€
    result = {
        "emotional_state": current_emotional_state,
        "customer_intent_level": customer_intent,
        "candidate_actions": list(set(candidate_actions)),
        "current_stage": new_stage,
    }

    # æ›´æ–° debug_info å¯¹è±¡ï¼ŒåŒ…å« current_stage å’Œ internal_monologue
    updated_debug_info = DebugInfo(
        current_stage=new_stage,
        emotional_state=current_emotional_state.model_dump() if current_emotional_state else None,
        internal_monologue=internal_monologue
    )
    result["debug_info"] = updated_debug_info

    # æ·»åŠ æ–°çš„çŠ¶æ€å­—æ®µï¼ˆåªæ·»åŠ  AgentState ä¸­å­˜åœ¨çš„å­—æ®µï¼‰
    if current_customer_intent:
        result["customer_intent"] = current_customer_intent
    if current_appointment_info:
        result["appointment_info"] = current_appointment_info
    if customer_info:
        result["customer_info"] = customer_info
    result.update(judge_invitation_result)

    return result

from langchain_core.tools import tool
from langchain_core.messages import HumanMessage
import json
from datetime import datetime, timezone, timedelta

@tool
def judge_invitation_state(state_dict: dict = None, config=None) -> dict:
    """
    ã€åˆ¤æ–­é‚€çº¦æƒ…å†µå·¥å…·ã€‘
    ä½¿ç”¨å¤§æ¨¡å‹æ ¹æ®èŠå¤©è®°å½•åˆ¤æ–­å®¢æˆ·æ˜¯å¦å·²æ˜ç¡®åŒæ„é‚€çº¦ï¼Œå¹¶æå–æœ€æ–°é‚€çº¦æ—¶é—´å’Œé¡¹ç›®ã€‚
    è¿”å›å­—æ®µï¼š
    - invitation_status: æ˜¯å¦å·²é‚€çº¦ï¼ˆintï¼‰
    - invitation_time: é‚€çº¦çš„13ä½æ—¶é—´æˆ³ï¼ˆå¦‚æ— åˆ™ä¸º nullï¼‰
    - invitation_project: é¡¹ç›®åç§°ï¼ˆå¦‚æ— åˆ™ä¸º nullï¼‰
    """
    print("=" * 80)
    print("ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å¼€å§‹æ‰§è¡Œjudge_invitation_state")
    print("=" * 80)

    if isinstance(state_dict, dict) and "state_dict" in state_dict:
        state_dict = state_dict["state_dict"]
        print("ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] è§£åŒ…äº†state_dictåŒ…è£…")

    messages = state_dict.get("long_term_messages", [])
    print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] è·å–åˆ° {len(messages)} æ¡æ¶ˆæ¯")

    role_map = {
        "human": "å®¢æˆ·",
        "user": "å®¢æˆ·",
        "ai": "é”€å”®é¡¾é—®",
        "assistant": "é”€å”®é¡¾é—®"
    }

    history = []
    for msg in messages:
        # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯å¯¹è±¡
        if isinstance(msg, dict):
            # å­—å…¸æ ¼å¼çš„æ¶ˆæ¯
            msg_type = msg.get("type", "").lower()
            content = msg.get("content", "")
            # è·å–æ—¶é—´æˆ³ä¿¡æ¯
            timestamp = msg.get("additional_kwargs", {}).get("timestamp", "")
        elif hasattr(msg, 'type') and hasattr(msg, 'content'):
            # HumanMessage/AIMessage ç­‰å¯¹è±¡
            msg_type = getattr(msg, 'type', '').lower()
            content = getattr(msg, 'content', '')
            # è·å–æ—¶é—´æˆ³ä¿¡æ¯
            timestamp = getattr(msg, 'additional_kwargs', {}).get("timestamp", "") if hasattr(msg, 'additional_kwargs') else ""
        else:
            # å…¶ä»–æ ¼å¼ï¼Œå°è¯•é€šç”¨å±æ€§è®¿é—®
            msg_type = getattr(msg, 'type', '').lower()
            content = getattr(msg, 'content', str(msg))
            timestamp = ""
        
        role = role_map.get(msg_type, msg_type if msg_type else "æœªçŸ¥")
        # åŒ…å«æ—¶é—´æˆ³çš„å¯¹è¯å†å²
        if timestamp:
            history.append(f"[{timestamp}] {role}: {content}")
        else:
            history.append(f"{role}: {content}")
    from datetime import datetime, timezone, timedelta
    now = datetime.now(timezone(timedelta(hours=8)))
    current_time_iso = now.strftime("%Y-%m-%dT%H:%M:%S.%f")[:-3] + "+08:00"

    #ç¡®è®¤é‚€çº¦çš„æ—¶é—´ç”Ÿæˆä»ç„¶å­˜åœ¨é—®é¢˜ï¼šä¸ä¸€å®šéƒ½æ˜¯å‡†çš„ï¼Œå¯èƒ½éå¸¸æ™šï¼Œä¹Ÿå¯èƒ½æ˜¯è¿‡å»çš„æ—¶é—´ã€‚ä¸è¿‡ä¸€æ—¦æŒ‡å®šäº†æ—¶é—´ï¼Œç¡®å®æ˜¯å‡†çš„ã€‚ä½†æ˜¯ä¸‹æ¬¡å¯¹è¯ï¼Œ**å¯èƒ½**ä¼šèƒ¡ä¹±ä¿®æ”¹æ‰æ—¶é—´ã€‚éœ€è¦åšä¸ªå¤§ä¿®æ”¹ï¼Œç”Ÿæˆ13ä½æ¯«ç§’çº§æ—¶é—´æˆ³ä¸èƒ½å®Œå…¨ä¾èµ–llmï¼Œå¤šé å·¥å…·--08-15_é»„å›½å¼º

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½é‚€çº¦åˆ¤æ–­åŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹å¯¹è¯ä¸­åˆ¤æ–­å®¢æˆ·æ˜¯å¦å·²**æ˜ç¡®åŒæ„é‚€çº¦**ï¼Œå¹¶æå–**æœ€æ–°æœ‰æ•ˆ**çš„é‚€çº¦ä¿¡æ¯ï¼ˆæ—¶é—´å’Œé¡¹ç›®ï¼‰ã€‚

**å…³é”®è¦æ±‚**ï¼šè¯·ä»”ç»†åˆ†æå¯¹è¯ä¸­çš„æ—¶é—´æˆ³ï¼Œæ ¹æ®å¯¹è¯å‘ç”Ÿçš„å…·ä½“æ—¶é—´æ¥è®¡ç®—ç›¸å¯¹æ—¶é—´è¡¨è¾¾ï¼ˆå¦‚"æ˜å¤©"ã€"åå¤©"ç­‰ï¼‰çš„ç»å¯¹æ—¥æœŸã€‚

- ç¡®è®¤é‚€çº¦çš„æŒ‡æ ‡ä¸º"invitation_status": 1ï¼Œä½ éœ€è¦åˆ†æå¯¹è¯å†å²ï¼Œè¯†åˆ«è¯¥å®¢æˆ·æ˜¯å¦å·²ç»åŒæ„åˆ°åº—ï¼Œæ­¤æ—¶æ‰èƒ½å°†"invitation_status"è®¾ç½®ä¸º1ã€‚å¦‚æœå®¢æˆ·ä»å·²é‚€çº¦çŠ¶æ€å˜æ›´ï¼Œå¹¶æ¨è¿Ÿæ—¶é—´ä¸ºæœªçŸ¥åˆ™ä¸º2ã€‚å¦‚æœå®¢æˆ·åˆæ¬¡èŠå¤©ï¼Œå¹¶ä¸”æ— åˆ°åº—æ„å‘ä¸º0
- å¦‚æœå®¢æˆ·æå‡ºå˜æ›´æ—¶é—´ã€æ¨è¿Ÿæˆ–å–æ¶ˆé‚€çº¦ï¼Œåˆ™"invitation_status": 2 
- é‚€çº¦æ—¶é—´è¯·è¾“å‡ºISOæ ¼å¼æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚ï¼š2025-08-12T15:30:00+08:00ï¼‰ï¼Œè‹¥æ— æœ‰æ•ˆæ—¶é—´è¾“å‡º nullã€‚
- é¡¹ç›®åç§°è‹¥æ— ä¹Ÿè¾“å‡º nullã€‚
- **é‡è¦ï¼šå¦‚æœå®¢æˆ·ç¡®è®¤é‚€çº¦ï¼Œè¯·æ ¹æ®å¯¹è¯ä¸­çš„æ—¶é—´æˆ³æ¥ç¡®å®šç›¸å¯¹æ—¶é—´è¡¨è¾¾çš„å…·ä½“æ—¥æœŸ**
  - å¦‚æœå®¢æˆ·åŒæ„äº†é‚€çº¦çŠ¶æ€ï¼Œå¹¶ä¸”è¯´"æ˜å¤©"ï¼Œè¯·æ ¹æ®å¯¹è¯æ—¶é—´æˆ³è®¡ç®—ä¸‹ä¸€å¤©çš„æ—¥æœŸ
  - å¦‚æœå®¢æˆ·åŒæ„äº†é‚€çº¦çŠ¶æ€ï¼Œå¹¶ä¸”è¯´"åå¤©"ï¼Œè¯·æ ¹æ®å¯¹è¯æ—¶é—´æˆ³è®¡ç®—ä¸‹ä¸¤å¤©çš„æ—¥æœŸ
  - å¦‚æœå®¢æˆ·åŒæ„äº†é‚€çº¦çŠ¶æ€ï¼Œå¹¶ä¸”è¯´"ä¸‹å‘¨ä¸€"ï¼Œè¯·æ ¹æ®å¯¹è¯æ—¶é—´æˆ³è®¡ç®—ä¸‹ä¸€ä¸ªå‘¨ä¸€çš„æ—¥æœŸ
  - **æ—¶é—´è®¡ç®—ç¤ºä¾‹**ï¼š
    - å¯¹è¯æ—¶é—´ï¼š2025-08-11T12:06:18+08:00ï¼Œå®¢æˆ·è¯´"æ˜å¤©ä¸‹åˆ" â†’ é‚€çº¦æ—¶é—´ï¼š2025-08-12 15:30:00
    - å¯¹è¯æ—¶é—´ï¼š2025-08-11T12:06:18+08:00ï¼Œå®¢æˆ·è¯´"åå¤©ä¸Šåˆ" â†’ é‚€çº¦æ—¶é—´ï¼š2025-08-13 10:30:00
- è‹¥å®¢æˆ·åŒæ„äº†é‚€çº¦çŠ¶æ€ï¼Œä½†å´åªè¯´äº†â€œä¸Šåˆâ€æˆ–â€œä¸‹åˆâ€ç­‰æ¨¡ç³Šæ—¶é—´æ®µï¼Œè€Œå¹¶æœªæ˜ç¡®å…·ä½“æ—¶é—´ç‚¹ï¼Œè¯·æ ¹æ®å¯¹è¯å†å²ç”Ÿæˆä¸€ä¸ªåˆç†çš„å·¥ä½œæ—¶é—´é»˜è®¤æ—¶é—´



- æ™šä¸Šä¸åšé»˜è®¤æ—¶é—´ï¼Œè‹¥æ— æ˜ç¡®æ—¶é—´åˆ™è¿”å› nullã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§å¦‚ä¸‹æ ¼å¼è¾“å‡º JSONï¼Œä¸”åªè¾“å‡º JSONï¼Œä¸è¦å¸¦å…¶ä»–è¯´æ˜ï¼š

{{
  "invitation_status": 0    å¦‚æœå®¢æˆ·æ— åˆ°åº—æ„å‘ä¸º0ï¼Œå¦‚æœå®¢æˆ·**ç¡®è®¤é‚€çº¦ï¼Œæ¯”å¦‚â€œå¥½çš„ï¼Œæ˜å¤©ä¸Šåˆ10ç‚¹â€â€œæ©ï¼Œæˆ‘è¿‡å»çœ‹ä¸€ä¸‹â€**åˆ™ä¸º1ï¼Œå¦åˆ™ä¸º0ï¼Œ
  å¦‚æœå®¢æˆ·ä»å·²é‚€çº¦çŠ¶æ€å˜æ›´ï¼Œå¹¶æ¨è¿Ÿæ—¶é—´ä¸ºæœªçŸ¥åˆ™ä¸º2 å¦‚æœå®¢æˆ·æå‡ºå˜æ›´æ—¶é—´ã€æ¨è¿Ÿæˆ–å–æ¶ˆé‚€çº¦ï¼Œåˆ™"invitation_status": 2 
  "schedule_time": é‚€çº¦çš„ISOæ ¼å¼æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚æ— åˆ™ä¸º nullï¼‰ï¼Œ
  "invitation_project": é¡¹ç›®åç§°å­—ç¬¦ä¸²ï¼ˆå¦‚æ— åˆ™ä¸º nullï¼‰
}}

æ ¹æ®å¯¹è¯å†å²ï¼š
{history}

# ä»¥ä¸‹æ˜¯ç¤ºä¾‹ï¼š

ç¤ºä¾‹1ï¼š
å¯¹è¯å†å²:
[2025-08-03T12:04:18.830868+08:00] user: ä½ ä»¬ä»€ä¹ˆæ—¶å€™æœ‰ç©ºï¼Ÿ
[2025-08-03T12:04:48.830868+08:00] assistant: æˆ‘ä»¬å‘¨å…­ä¸Šåˆæœ‰ç©ºï¼Œå¯ä»¥è¿‡æ¥å—ï¼Ÿ
[2025-08-03T12:05:18.830868+08:00] user: å¥½çš„ã€‚
è¾“å‡ºï¼š
{{
  "invitation_status": 1,
  "schedule_time": "2025-08-09T10:30:00+08:00",  // 2025-08-09 10:30:00ï¼ˆç¤ºä¾‹æ—¶é—´ï¼‰
  "invitation_project": null
}}

ç¤ºä¾‹2ï¼ˆå®¢æˆ·å˜æ›´æ—¶é—´ï¼‰ï¼š
å¯¹è¯å†å²:
[2025-08-03T15:20:15.123+08:00] user: å‘¨å…­ä¸Šåˆå¯ä»¥å—ï¼Ÿ
[2025-08-03T15:20:45.123+08:00] assistant: å¯ä»¥çš„ï¼Œæ‚¨å‘¨å…­ä¸Šåˆå‡ ç‚¹æ–¹ä¾¿ï¼Ÿ
[2025-08-03T15:21:15.123+08:00] user: æˆ‘å‘¨å…­ä¸Šåˆæ²¡ç©ºï¼Œæ”¹æˆå‘¨æ—¥ä¸Šåˆ9ç‚¹å¯ä»¥å—ï¼Ÿ
[2025-08-03T15:21:45.123+08:00] assistant: å¥½çš„ï¼Œå‘¨æ—¥ä¸Šåˆ9ç‚¹ä¸ºæ‚¨é¢„çº¦ã€‚
è¾“å‡ºï¼š
{{
  "invitation_status": 1,
  "schedule_time": "2025-08-10T09:00:00+08:00",  // 2025-08-10 09:00:00ï¼ˆç¤ºä¾‹æ—¶é—´ï¼‰
  "invitation_project": null
}}

ç¤ºä¾‹3ï¼ˆå®¢æˆ·æ‹’ç»æˆ–æ— åŒæ„ï¼‰ï¼š
å¯¹è¯å†å²:
[2025-08-03T14:30:45.789+08:00] user: ä½ ä»¬ä»€ä¹ˆæ—¶å€™æœ‰ç©ºï¼Ÿ
[2025-08-03T14:31:15.789+08:00] assistant: å‘¨å…­ä¸Šåˆå¯ä»¥æ¥å—ï¼Ÿ
[2025-08-03T14:31:45.789+08:00] user: æˆ‘å…ˆè€ƒè™‘ä¸€ä¸‹ã€‚
è¾“å‡ºï¼š
{{
  "invitation_status": 0,
  "schedule_time": null,
  "invitation_project": null
}}

ç¤ºä¾‹4ï¼ˆå®¢æˆ·æ˜ç¡®æ¥å—å¹¶æŒ‡å®šé¡¹ç›®ï¼‰ï¼š
å¯¹è¯å†å²:
[2025-08-03T16:45:22.456+08:00] user: ä½ ä»¬é‚£ä¸ªæ°´å…‰é’ˆæœ€è¿‘æœ‰æ´»åŠ¨å—ï¼Ÿ
[2025-08-03T16:45:52.456+08:00] assistant: æœ‰çš„ï¼Œæœ€è¿‘æ°´å…‰é’ˆåšæ´»åŠ¨ï¼Œæ‚¨å¯ä»¥å‘¨å…­ä¸Šåˆæ¥ä½“éªŒä¸€ä¸‹ã€‚
[2025-08-03T16:46:22.456+08:00] user: å¥½çš„ï¼Œé‚£å°±å‘¨å…­ä¸Šåˆåšæ°´å…‰é’ˆã€‚
è¾“å‡ºï¼š
{{
  "invitation_status": 1,
  "schedule_time": "2025-08-09T10:30:00+08:00",  // 2025-08-09 10:30:00ï¼ˆç¤ºä¾‹æ—¶é—´ï¼‰
  "invitation_project": "æ°´å…‰é’ˆ"
}}

ç¤ºä¾‹5ï¼ˆç›¸å¯¹æ—¶é—´è¡¨è¾¾ï¼‰ï¼š
å¯¹è¯å†å²:
[2025-08-11T12:06:18.830868+08:00] user: æˆ‘æƒ³æ˜å¤©ä¸‹åˆå»ä½ ä»¬åº—é‡Œåšæ°´å…‰é’ˆï¼Œå¯ä»¥å—ï¼Ÿ
[2025-08-11T12:06:48.830868+08:00] assistant: å¯ä»¥çš„ï¼Œæ˜å¤©ä¸‹åˆ3:30ä¸ºæ‚¨é¢„çº¦æ°´å…‰é’ˆã€‚
**æ—¶é—´è®¡ç®—è¯´æ˜**ï¼šå¯¹è¯æ—¶é—´æ˜¯8æœˆ11æ—¥12:06ï¼Œå®¢æˆ·è¯´"æ˜å¤©ä¸‹åˆ" = 8æœˆ12æ—¥ä¸‹åˆ15:30
è¾“å‡ºï¼š
{{
  "invitation_status": 1,
  "schedule_time": "2025-08-12T15:30:00+08:00",  // 2025-08-12 15:30:00ï¼ˆæ˜å¤©ä¸‹åˆ3:30ï¼‰
  "invitation_project": "æ°´å…‰é’ˆ"
}}

è¯·åŸºäºä»¥ä¸Šè¦æ±‚åˆ¤æ–­å¹¶è¾“å‡ºç»“æœã€‚
"""

    try:
        print("ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å¼€å§‹é…ç½®æ¨¡å‹...")

        # ä»configä¸­æå–çƒ­æ›´æ–°é…ç½®
        hot_config = None
        if config and hasattr(config, 'get'):
            configurable = config.get("configurable", {})
            if configurable:
                hot_config = configurable
                print("ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å‘ç°çƒ­æ›´æ–°é…ç½®")

        agent_temperature = state_dict.get("agent_temperature", 0.5)
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] agent_temperature: {agent_temperature}")

        # ä¼˜å…ˆä½¿ç”¨çƒ­æ›´æ–°é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        configuration = Configuration.from_context()
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] é»˜è®¤é…ç½® - provider: {configuration.model_provider}, model: {configuration.evaluation_model}")

        # é»˜è®¤å€¼è®¾ç½®
        model_provider = "openrouter"
        model_name = "deepseek/deepseek-chat-v3.1"
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] ä½¿ç”¨é»˜è®¤å€¼ - provider: {model_provider}, model: {model_name}")

        if hot_config:
            model_provider = hot_config.get("model_provider", model_provider)
            # ä¼˜å…ˆä½¿ç”¨çƒ­æ›´æ–°é…ç½®ä¸­çš„evaluation_modelï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨model_name
            model_name = hot_config.get("evaluation_model", hot_config.get("model_name", model_name))
            # ä½¿ç”¨çƒ­æ›´æ–°çš„temperatureï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨çŠ¶æ€ä¸­çš„
            agent_temperature = hot_config.get("agent_temperature", agent_temperature)
            config_dict = hot_config
            print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] çƒ­æ›´æ–°é…ç½®è¦†ç›– - provider: {model_provider}, model: {model_name}, temp: {agent_temperature}")
        else:
            model_provider = configuration.model_provider
            model_name = configuration.evaluation_model
            config_dict = configuration.model_dump()
            print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] ä½¿ç”¨é»˜è®¤é…ç½® - provider: {model_provider}, model: {model_name}")

        from llm import create_llm
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å‡†å¤‡åˆ›å»ºLLM - provider: {model_provider}, model: {model_name}")

        llm = create_llm(
            model_provider=model_provider,
            model_name=model_name,
            temperature=0.5
        )
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] LLMåˆ›å»ºæˆåŠŸ - {type(llm)}")
    except Exception as e:
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] é”™è¯¯ï¼šæ— æ³•åˆ›å»ºè¯„ä¼°æ¨¡å‹ '{model_name}' (provider: {model_provider}): {e}")
        import traceback
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
        return {
            "invitation_status": 0,
            "invitation_time": None,
            "invitation_project": None,
            "error": "æ— æ³•åˆå§‹åŒ–æ¨¡å‹"
        }

    try:
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å‡†å¤‡è°ƒç”¨æ¨¡å‹ï¼Œprompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] prompté¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰:\n{prompt[:200]}...")

        message = HumanMessage(content=prompt)
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] åˆ›å»ºHumanMessageæˆåŠŸ")

        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å¼€å§‹è°ƒç”¨LLM...")
        response = llm.invoke(
            [message],
            response_format={"type": "json_object"}
        )
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] LLMè°ƒç”¨å®Œæˆï¼Œå“åº”ç±»å‹: {type(response)}")

        response_text = response.content
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] è·å–å“åº”å†…å®¹ï¼Œé•¿åº¦: {len(response_text)} å­—ç¬¦")
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] åŸå§‹æ¨¡å‹å“åº”:\n{response_text}")

        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
        if not response_text or response_text.strip() == "":
            print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] è­¦å‘Šï¼šæ¨¡å‹è¿”å›ç©ºå“åº”")
            return {
                "invitation_status": 0,
                "invitation_time": None,
                "invitation_project": None,
                "error": "æ¨¡å‹è¿”å›ç©ºå“åº”"
            }

        # ä½¿ç”¨é²æ£’çš„JSONè§£æå·¥å…·
        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] å¼€å§‹JSONè§£æ...")
        fallback_dict = create_fallback_dict("é‚€çº¦åˆ¤æ–­")
        data = robust_json_parse(
            response_text,
            context="é‚€çº¦åˆ¤æ–­",
            fallback_dict=fallback_dict,
            debug=True
        )

        print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] JSONè§£æå®Œæˆï¼Œç»“æœ: {data}")

        # éªŒè¯è§£æç»“æœ
        if not isinstance(data, dict):
            print(f"ğŸ” [DEBUG-é‚€çº¦åˆ¤æ–­] é”™è¯¯ï¼šè§£æç»“æœä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå®é™…ç±»å‹: {type(data)}")
            return {
                "invitation_status": 0,
                "invitation_time": None,
                "invitation_project": None,
                "error": "è§£æç»“æœæ ¼å¼é”™è¯¯"
            }

        def safe_timestamp(value):
            try:
                return int(value)
            except (TypeError, ValueError):
                return None

        # è·å–é‚€çº¦ä¿¡æ¯
        invitation_status = data.get("invitation_status")
        schedule_time = data.get("schedule_time")
        invitation_project = data.get("invitation_project")
        
        # å°†ISOæ ¼å¼æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º13ä½æ¯«ç§’æ—¶é—´æˆ³
        invitation_time = None
        if schedule_time:
            try:
                from datetime import datetime
                # è§£æISOæ ¼å¼æ—¶é—´å­—ç¬¦ä¸²
                schedule_datetime = datetime.fromisoformat(schedule_time.replace('Z', '+00:00'))
                # è½¬æ¢ä¸º13ä½æ¯«ç§’æ—¶é—´æˆ³
                invitation_time = int(schedule_datetime.timestamp() * 1000)
                print(f"[DEBUG] è½¬æ¢æ—¶é—´: {schedule_time} -> {invitation_time}")
            except Exception as e:
                print(f"[DEBUG] æ—¶é—´è½¬æ¢å¤±è´¥: {e}")
                invitation_time = None

        # åˆ¤æ–­é‚€çº¦æ—¶é—´æ˜¯å¦å·²è¿‡æœŸ
        if invitation_status and invitation_time:
            # å°†13ä½æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetimeå¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
            from datetime import datetime, timezone
            # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼ˆ+8å°æ—¶ï¼‰
            invitation_datetime = datetime.fromtimestamp(invitation_time / 1000, tz=timezone(timedelta(hours=8)))
            current_datetime = datetime.now(timezone(timedelta(hours=8)))
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print(f"[DEBUG] é‚€çº¦æ—¶é—´: {invitation_datetime}")
            print(f"[DEBUG] å½“å‰æ—¶é—´: {current_datetime}")
            print(f"[DEBUG] é‚€çº¦çŠ¶æ€: {invitation_status}")
            print(f"[DEBUG] é‚€çº¦é¡¹ç›®: {invitation_project}")
            
            # å¦‚æœå½“å‰æ—¶é—´å·²ç»è¿‡äº†é‚€çº¦æ—¶é—´è¶…è¿‡1å¤©ï¼Œåˆ™é‚€çº¦å¤±æ•ˆ
            # ç»™å®¢æˆ·1å¤©çš„ç¼“å†²æ—¶é—´
            from datetime import timedelta
            buffer_time = invitation_datetime + timedelta(days=1)
            
            if current_datetime > buffer_time:
                print(f"[DEBUG] é‚€çº¦å·²è¿‡æœŸè¶…è¿‡1å¤©ï¼Œè‡ªåŠ¨å¤±æ•ˆ")
                invitation_status = 2
                invitation_time = None
                invitation_project = None
            elif current_datetime > invitation_datetime:
                print(f"[DEBUG] é‚€çº¦æ—¶é—´å·²è¿‡ï¼Œä½†åœ¨1å¤©ç¼“å†²æœŸå†…ï¼Œä¿æŒæœ‰æ•ˆ")

        return {
            "invitation_status": invitation_status,
            "invitation_time": invitation_time,
            "invitation_project": invitation_project
        }

    except Exception as e:
        return {
            "invitation_status": 0,
            "invitation_time": None,
            "invitation_project": None,
            "error": f"æ¨¡å‹è§£æå¤±è´¥: {e}"
        }


def user_emotion_analysis_workflow():
    """åˆ›å»ºå¤–éƒ¨ä¿¡æ¯æŸ¥è¯¢å·¥ä½œæµ"""
    # åˆ›å»ºä¸»å›¾
    config_schema = Configuration
    user_emotion_analysis_graph = StateGraph(AgentState,config_schema=config_schema, output=Output)

    # æ·»åŠ èŠ‚ç‚¹
    user_emotion_analysis_graph.add_node("analyze_sentiment", analyze_sentiment_node)
    user_emotion_analysis_graph.add_node("analyze_decision", _design_node)  # å¹¶è¡Œæ‰§è¡Œå·¥å…·ï¼Œè·å¾—tool_results

    # æ·»åŠ è¾¹
    user_emotion_analysis_graph.add_edge(START, "analyze_decision")
    user_emotion_analysis_graph.add_edge("analyze_decision", "analyze_sentiment")
    user_emotion_analysis_graph.add_edge("analyze_sentiment", END)  # ç›´æ¥ç»“æŸ

    # ç¼–è¯‘å¹¶è¿”å›
    return user_emotion_analysis_graph.compile()