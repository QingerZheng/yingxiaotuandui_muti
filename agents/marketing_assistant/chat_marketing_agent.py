"""èŠå¤©è¥é”€æ™ºèƒ½ä½“å·¥ä½œæµ
é‡‡ç”¨LangGraphçš„Plan-and-Executeæ¨¡å¼å®ç°æ™ºèƒ½è¥é”€åŠ©æ‰‹ï¼š
1. è®¡åˆ’é˜¶æ®µ - åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œåˆ¶å®šå¤šæ­¥éª¤æ‰§è¡Œè®¡åˆ’
2. æ‰§è¡Œé˜¶æ®µ - æŒ‰è®¡åˆ’é€æ­¥æ‰§è¡Œï¼ŒåŒ…æ‹¬ï¼š
   - èŠå¤©å¯¹è¯ä¸éœ€æ±‚ç†è§£
   - æ—¶é—´ä¿¡æ¯è·å–
   - è”ç½‘æœç´¢æœ€æ–°è¶‹åŠ¿
   - è¥é”€æ–‡æ¡ˆç”Ÿæˆ
3. é‡æ–°è§„åˆ’ - æ ¹æ®æ‰§è¡Œç»“æœè°ƒæ•´è®¡åˆ’æˆ–å®Œæˆä»»åŠ¡

è¾“å…¥æ ¼å¼:
{
  "messages": [
    {
      "type": "human",
      "content": "ç”¨æˆ·è¾“å…¥å†…å®¹"
    }
  ]
}
"""

from __future__ import annotations

import json
import os
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Sequence, Literal, Union
from typing_extensions import TypedDict, Annotated
import asyncio

from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from llm import create_llm
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel, Field

# å¯¼å…¥è¥é”€å·¥å…·
from agents.marketing_assistant.marketing_tool import get_current_time, web_search_tool, marketing_copy_generator
from agents.marketing_assistant.marketing_tool.time_tool import TimeInfo
# å¯¼å…¥äººè®¾æç¤ºè¯æ¨¡æ¿
from agents.marketing_assistant.persona_prompt_template import PersonaPromptTemplate

# ==================== å…¨å±€å˜é‡ ====================

# å­˜å‚¨è®¡åˆ’é˜¶æ®µå†³å®šä½¿ç”¨çš„å·¥å…·åç§°åˆ—è¡¨
planned_tools = []

# å½“å‰è½®æ¬¡æ•°æ®å­—å…¸ - æ›¿ä»£inter_node_memoryçŠ¶æ€ä¼ é€’æœºåˆ¶
current_round_data = {
    "round_id": 0,
    "user_input": "",
    "plan_steps": [],
    "execution_results": [],
    "tool_outputs": {},
    "marketing_copies": None,
    "search_results": None,
    "time_info": None
}

# ç‹¬ç«‹çš„å¯¹è¯è®°å¿†å…¨å±€å­—å…¸ - å­˜å‚¨è¿‘ä¸¤è½®å¯¹è¯
recent_conversation_memory = {
    "messages": [],  # å­˜å‚¨è¿‘ä¸¤è½®å¯¹è¯æ¶ˆæ¯
    "last_updated": None  # æœ€åæ›´æ–°æ—¶é—´
}

# ==================== å…¨å±€å­—å…¸ç®¡ç†å‡½æ•° ====================

def init_round_data(round_id: int, user_input: str) -> None:
    """åˆå§‹åŒ–å½“å‰è½®æ¬¡æ•°æ®"""
    global current_round_data
    current_round_data = {
        "round_id": round_id,
        "user_input": user_input,
        "plan_steps": [],
        "execution_results": [],
        "tool_outputs": {},
        "marketing_copies": None,
        "search_results": None,
        "time_info": None
    }
    # print(f"ğŸ”„ åˆå§‹åŒ–è½®æ¬¡ {round_id} æ•°æ®: {user_input}")

def update_recent_conversation_memory(conversation_memory: list) -> None:
    """æ›´æ–°è¿‘ä¸¤è½®å¯¹è¯è®°å¿†åˆ°å…¨å±€å­—å…¸"""
    global recent_conversation_memory
    from datetime import datetime
    
    # åªä¿ç•™æœ€è¿‘ä¸¤è½®å¯¹è¯ï¼ˆæœ€å4æ¡æ¶ˆæ¯ï¼šç”¨æˆ·-AI-ç”¨æˆ·-AIï¼‰
    recent_messages = conversation_memory[-4:] if len(conversation_memory) > 4 else conversation_memory
    
    recent_conversation_memory = {
        "messages": recent_messages,
        "last_updated": datetime.now().isoformat()
    }
    # print(f"ğŸ“ æ›´æ–°è¿‘ä¸¤è½®å¯¹è¯è®°å¿†: {len(recent_messages)}æ¡æ¶ˆæ¯")

def get_recent_conversation_memory() -> list:
    """è·å–è¿‘ä¸¤è½®å¯¹è¯è®°å¿†"""
    global recent_conversation_memory
    return recent_conversation_memory.get("messages", [])

def get_round_data(key: str = None):
    """è·å–å½“å‰è½®æ¬¡æ•°æ®"""
    global current_round_data
    if key:
        return current_round_data.get(key)
    return current_round_data.copy()

def set_round_data(key: str, value) -> None:
    """è®¾ç½®å½“å‰è½®æ¬¡æ•°æ®"""
    global current_round_data
    current_round_data[key] = value
    # print(f"ğŸ“ è®¾ç½®è½®æ¬¡æ•°æ® {key}: {value}")

def clear_round_data() -> None:
    """æ¸…ç†å½“å‰è½®æ¬¡æ•°æ®"""
    global current_round_data
    current_round_data = {
        "round_id": 0,
        "user_input": "",
        "plan_steps": [],
        "execution_results": [],
        "tool_outputs": {},
        "marketing_copies": None,
        "search_results": None,
        "time_info": None
    }
    # print("ğŸ§¹ æ¸…ç†è½®æ¬¡æ•°æ®å®Œæˆ")

# ==================== é…ç½®å’Œæšä¸¾ ====================

class ChatMarketingStep(Enum):
    """èŠå¤©è¥é”€å·¥ä½œæµæ­¥éª¤æšä¸¾"""
    PLAN = "plan"
    EXECUTE = "execute"
    REPLAN = "replan"
    COMPLETE = "complete"
    CHAT = "chat"
# ==================== æ•°æ®æ¨¡å‹ ====================

class Plan(BaseModel):
    """æ‰§è¡Œè®¡åˆ’æ¨¡å‹"""
    conversation_type: str = Field(
        description="å¯¹è¯ç±»å‹ï¼šchatã€discussionæˆ–generation"
    )
    execution_plan: str = Field(
        description="è¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤è¯´æ˜"
    )
    steps: List[str] = Field(
        description="æŒ‰é¡ºåºæ‰§è¡Œçš„æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åº”è¯¥æ˜¯å…·ä½“å¯æ‰§è¡Œçš„ä»»åŠ¡",
        default_factory=list
    )

class Response(BaseModel):
    """æœ€ç»ˆå›å¤æ¨¡å‹"""
    response: str = Field(description="ç»™ç”¨æˆ·çš„æœ€ç»ˆå›å¤")
    marketing_copies: Optional[str] = Field(description="è¥é”€æ–‡æ¡ˆå†…å®¹ï¼ŒJSONæ ¼å¼", default=None)

class Act(BaseModel):
    """é‡æ–°è§„åˆ’åŠ¨ä½œæ¨¡å‹"""
    action: Plan | Response = Field(
        description="ä¸‹ä¸€æ­¥åŠ¨ä½œï¼šç»§ç»­æ‰§è¡Œæ–°è®¡åˆ’æˆ–ç»™å‡ºæœ€ç»ˆå›å¤"
    )

class ChatMarketingState(TypedDict):
    """èŠå¤©è¥é”€å·¥ä½œæµçŠ¶æ€"""
    # è¾“å…¥æ¶ˆæ¯å­—æ®µ - ä¸ChatMarketingInputä¿æŒä¸€è‡´
    messages: Optional[Sequence[BaseMessage]]  # è¾“å…¥æ¶ˆæ¯
    
    # ä¼šè¯è®°å¿†å­—æ®µ
    conversation_memory: Optional[List[BaseMessage]]  # ä¼šè¯è®°å¿†ï¼Œå­˜å‚¨ç”¨æˆ·ä¸AIçš„èŠå¤©è®°å½•
    
    # å½“å‰ç”¨æˆ·è¾“å…¥å­—æ®µ - ä¸“é—¨å­˜å‚¨å½“å‰è½®æ¬¡çš„ç”¨æˆ·è¾“å…¥
    current_user_input: Optional[str]  # å½“å‰ç”¨æˆ·è¾“å…¥ï¼Œé¿å…ä»å…¨å±€å­—å…¸ä¸­è§£æ
    
    # è½®æ¬¡IDå­—æ®µ - ç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯è½®æ¬¡ï¼Œé¿å…è·¨è½®æ±¡æŸ“
    round_id: Optional[int]  # å½“å‰å¯¹è¯è½®æ¬¡IDï¼Œä»1å¼€å§‹è®¡æ•°
    
    # Plan-and-Execute çŠ¶æ€å­—æ®µ
    plan: List[str]
    past_steps: List[tuple[str, str]]  # (æ­¥éª¤, æ‰§è¡Œç»“æœ)
    response: Optional[str]
    
    # å…¶ä»–çŠ¶æ€å­—æ®µ
    current_step: Optional[ChatMarketingStep]
    time_info: Optional[TimeInfo]
    search_results: Optional[str]
    marketing_copies: Optional[str]  # è¥é”€æ–‡æ¡ˆå·¥å…·è¿”å›ç»“æœ
    error_message: Optional[str]

class ChatMarketingInput(TypedDict):
    """èŠå¤©è¥é”€å·¥ä½œæµè¾“å…¥"""
    messages: Sequence[BaseMessage]  # æ ‡å‡†LangGraphæ¶ˆæ¯æ ¼å¼

class ChatMarketingOutput(TypedDict):
    """èŠå¤©è¥é”€å·¥ä½œæµè¾“å‡º"""
    response: str
    marketing_copies: Optional[str]

# ==================== å·¥ä½œæµèŠ‚ç‚¹ ====================

class ChatMarketingNodes:
    """èŠå¤©è¥é”€å·¥ä½œæµèŠ‚ç‚¹é›†åˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŠå¤©è¥é”€å·¥ä½œæµèŠ‚ç‚¹"""
        # print(f"ğŸš€ å¼€å§‹åˆå§‹åŒ–èŠå¤©è¥é”€å·¥ä½œæµèŠ‚ç‚¹")
        
# ==================== æç¤ºè¯é…ç½® ====================
# è¿™é‡Œéœ€è¦é…ç½®è¥é”€åŠ©æ‰‹çš„åŸºç¡€æç¤ºè¯å’Œç³»ç»ŸæŒ‡ä»¤
# åŒ…å«:
# 1. è¥é”€ä¸“å®¶è§’è‰²å®šä½
# 2. ä¸“ä¸šçŸ¥è¯†èŒƒå›´ç•Œå®š
# 3. å›å¤é£æ ¼å’Œè¯­æ°”è®¾ç½®
# 4. å·¥å…·ä½¿ç”¨è§„èŒƒ
# 5. å®‰å…¨é™åˆ¶å’Œè¾¹ç•Œ
  # ==================== æç¤ºè¯é…ç½® ====================     
        # åˆå§‹åŒ–äººè®¾æç¤ºè¯æ¨¡æ¿
        self.persona_template = PersonaPromptTemplate()
        # æŒ‰éœ€ç»„åˆåŸºç¡€æç¤ºè¯
        persona_parts = [
            self.persona_template.FOUNDATION_PROMPTS["role_identity"],
            self.persona_template.FOUNDATION_PROMPTS["core_principles"],
            self.persona_template.INTERACTION_PROMPTS["communication_style"],
            self.persona_template.INTERACTION_PROMPTS["output_format"]
        ]
        self.persona_prompt = "\n\n".join(persona_parts)
        
        # åˆ›å»ºå·¥å…·å’ŒLLM
        self.tools = [get_current_time, web_search_tool, marketing_copy_generator]
        # print(f"ğŸ“¦ å·¥å…·åˆ—è¡¨åˆå§‹åŒ–å®Œæˆï¼Œå…±{len(self.tools)}ä¸ªå·¥å…·")
        
        try:
            self.planner_llm = self._create_llm(temperature=0.1)  # è®¡åˆ’éœ€è¦æ›´ç²¾ç¡®
            self.executor_llm = self._create_llm(temperature=0.6)  # æ‰§è¡Œå¯ä»¥æ›´æœ‰åˆ›æ„
            
            
            self.planner = self._create_planner()
            self.replanner = self._create_replanner()
            
            # æ³¨æ„ï¼šæ‰§è¡Œå™¨Agentå°†åœ¨execute_stepä¸­åŠ¨æ€åˆ›å»ºï¼Œä»¥ä¾¿ä¼ å…¥å¯¹è¯è®°å¿†
            
            # print(f"âœ… èŠå¤©è¥é”€å·¥ä½œæµèŠ‚ç‚¹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            # print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            # è®¾ç½®ä¸ºNoneä»¥ä¾¿åç»­æ£€æŸ¥
            self.planner = None
            self.replanner = None
            raise Exception(f"èŠå¤©è¥é”€å·¥ä½œæµèŠ‚ç‚¹åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _create_planner(self):
        """åˆ›å»ºè®¡åˆ’å™¨"""
        if not self.planner_llm:
            return None
        
        return self.planner_llm.with_structured_output(Plan)
    
    def _create_replanner(self):
        """åˆ›å»ºé‡æ–°è§„åˆ’å™¨"""
        if not self.planner_llm:
            return None
            
        # ä¸ºreplanneræ·»åŠ ç³»ç»Ÿæç¤ºè¯
        replanner_system_prompt = self.persona_template.REPLANNER_PROMPTS["system_prompt"]
        
        # åˆ›å»ºå¸¦æœ‰ç³»ç»Ÿæç¤ºè¯çš„LLM
        from langchain_core.prompts import ChatPromptTemplate
        
        # åˆ›å»ºæç¤ºè¯æ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", replanner_system_prompt),
            ("human", "{input}")
        ])
        
        # åˆ›å»ºé“¾å¼è°ƒç”¨ï¼šprompt -> llm -> structured_output
        chain = prompt | self.planner_llm.with_structured_output(Act)
        return chain
    
    def _create_executor_agent(self, conversation_memory_text: str = ""):
        """åˆ›å»ºæ‰§è¡Œå™¨Agent
        
        Args:
            conversation_memory_text: æ ¼å¼åŒ–çš„å¯¹è¯è®°å¿†æ–‡æœ¬ï¼Œç”¨äºæ–‡æ¡ˆä¿®æ”¹åœºæ™¯
        """
        try:
            if not self.executor_llm:
                # print(f"âŒ executor_llmä¸ºNoneï¼Œæ— æ³•åˆ›å»ºæ‰§è¡Œå™¨Agent")
                raise Exception("executor_llmæœªæ­£ç¡®åˆå§‹åŒ–")
                
                
            # print(f"ğŸ“ å¼€å§‹åˆ›å»ºæ‰§è¡Œå™¨Agentï¼Œå·¥å…·æ•°é‡: {len(self.tools)}")
            # print(f"ğŸ“ å¯ç”¨å·¥å…·: {[tool.name for tool in self.tools]}")
          

             # æ·»åŠ æ‰§è¡Œå™¨ç‰¹å®šçš„æŒ‡å¯¼
            executor_instructions = f"""

æ‰§è¡ŒæŒ‡å¯¼ï¼š
ä½ æ­£åœ¨æ‰§è¡Œä¸€ä¸ªå¤šæ­¥éª¤è®¡åˆ’ä¸­çš„ç‰¹å®šæ­¥éª¤ã€‚è¯·ä¸“æ³¨äºå½“å‰ä»»åŠ¡ï¼Œä½¿ç”¨åˆé€‚çš„å·¥å…·å®Œæˆç›®æ ‡ã€‚

{self.persona_template.EXECUTOR_PROMPTS["classification_rules"]}

{self.persona_template.EXECUTOR_PROMPTS["tool_usage_requirements"]}

{self.persona_template.EXECUTOR_PROMPTS["important_reminders"]}

## å½“å‰å¯ç”¨çš„å¯¹è¯è®°å¿†ï¼š
{conversation_memory_text}

è¯·æ ¹æ®ç»™å®šçš„æ­¥éª¤æè¿°ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å®Œæˆä»»åŠ¡ã€‚ä»…åœ¨æ–‡æ¡ˆä¿®æ”¹åœºæ™¯ï¼ˆuse_previous_copy=Trueï¼‰æ—¶ä¼ é€’conversation_memoryå‚æ•°ã€‚"""
            
            system_prompt = self.persona_prompt + executor_instructions
            #==================== æç¤ºè¯é…ç½®ç»“æŸ ====================
            
            agent = create_react_agent(self.executor_llm, self.tools, prompt=system_prompt)
            # print(f"âœ… æ‰§è¡Œå™¨Agentåˆ›å»ºæˆåŠŸ")
            return agent
        except Exception as e:
            # print(f"âŒ åˆ›å»ºæ‰§è¡Œå™¨Agentå¤±è´¥: {e}")
            raise Exception(f"æ— æ³•åˆ›å»ºæ‰§è¡Œå™¨Agent: {e}")
    

    
    def _create_llm(self, temperature: float = 0.1):
        """åˆ›å»ºLLMå®ä¾‹"""
        try:
            from agents.persona_config.config_manager import config_manager
            cfg = config_manager.get_config() or {}
            
            llm = create_llm(
                model_provider=cfg.get("model_provider", "openrouter"),
                model_name=cfg.get("model_name", "openai/gpt-4o"),
                temperature=temperature
            )
            # print(f"âœ… LLMåˆ›å»ºæˆåŠŸ: {cfg.get('model_provider', 'openrouter')}/{cfg.get('model_name', 'openai/gpt-5-chat')}")
            return llm
        except Exception as e:
            # print(f"âŒ åˆ›å»ºLLMå¤±è´¥: {e}")
            raise Exception(f"æ— æ³•åˆ›å»ºLLM: {e}")
    
    async def input_step(self, state: ChatMarketingState) -> Dict[str, Any]:
        """è¾“å…¥å¤„ç†æ­¥éª¤ - å¤„ç†å’Œè½¬é€’è¾“å…¥æ¶ˆæ¯ï¼Œå¹¶åˆå§‹åŒ–å½“å‰è½®æ¬¡æ•°æ®"""
        try:
            # æ¸…ç©ºä¸Šä¸€è½®çš„å…¨å±€å­—å…¸æ•°æ®
            clear_round_data()
            # print("ğŸ§¹ å·²æ¸…ç©ºä¸Šä¸€è½®çš„å…¨å±€å­—å…¸æ•°æ®")
            
            # ç”Ÿæˆæ–°çš„è½®æ¬¡ID
            current_round_id = state.get("round_id", 0) + 1
            # print(f"ğŸ”„ å¼€å§‹æ–°ä¸€è½®å¯¹è¯ï¼Œè½®æ¬¡ID: {current_round_id}")
            
            # è·å–è¾“å…¥æ¶ˆæ¯
            input_messages = state.get("messages", [])
            
            # print(f"[DEBUG] input_step - åŸå§‹è¾“å…¥æ¶ˆæ¯: {input_messages}")
            # print(f"[DEBUG] input_step - åŸå§‹è¾“å…¥æ¶ˆæ¯ç±»å‹: {type(input_messages)}")
            
            # æå–ç”¨æˆ·è¾“å…¥å†…å®¹
            user_input = ""
            for msg in input_messages:
                if isinstance(msg, dict):
                    user_input = msg.get("content", "")
                    break
                elif hasattr(msg, 'content'):
                    # å¤„ç†BaseMessageå¯¹è±¡
                    user_input = msg.content
                    break
            
            # åˆå§‹åŒ–å½“å‰è½®æ¬¡çš„å…¨å±€æ•°æ®
            init_round_data(current_round_id, user_input)
            
            # è·å–å†å²ä¼šè¯è®°å¿†
            conversation_memory = state.get("conversation_memory", [])
            # print(f"ğŸ“š è·å–åˆ°å†å²ä¼šè¯è®°å¿†: {len(conversation_memory)}æ¡æ¶ˆæ¯")
            # print(f"ğŸ” conversation_memoryè¯¦ç»†å†…å®¹:")
            # for i, msg in enumerate(conversation_memory):
            #     print(f"  æ¶ˆæ¯{i}: ç±»å‹={type(msg)}, å†…å®¹={getattr(msg, 'content', 'No content')[:50]}...")
            
            # print(f"ğŸ” è°ƒç”¨update_recent_conversation_memoryä¹‹å‰ï¼Œrecent_conversation_memoryçŠ¶æ€:")
            # print(f"  current recent_conversation_memory: {recent_conversation_memory}")
            
            # æ›´æ–°è¿‘ä¸¤è½®å¯¹è¯è®°å¿†åˆ°ç‹¬ç«‹çš„å…¨å±€å­—å…¸
            update_recent_conversation_memory(conversation_memory)
            
            # print(f"ğŸ” è°ƒç”¨update_recent_conversation_memoryä¹‹åï¼Œrecent_conversation_memoryçŠ¶æ€:")
            # print(f"  updated recent_conversation_memory: {recent_conversation_memory}")
            
            # éªŒè¯get_recent_conversation_memoryå‡½æ•°
            test_messages = get_recent_conversation_memory()
            print(f"é€šè¿‡get_recent_conversation_memory()è·å–çš„æ¶ˆæ¯: {test_messages}")
            print(f"get_recent_conversation_memory()è¿”å›ç±»å‹: {type(test_messages)}")
            print(f"get_recent_conversation_memory()è¿”å›é•¿åº¦: {len(test_messages) if test_messages else 0}")
            
            # print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
            # print(f"å†å²è®°å¿†æ•°é‡: {len(conversation_memory)}")
            # print(f"å½“å‰è½®æ¬¡ID: {current_round_id}")
            # print(f"[DEBUG] input_step - å³å°†è¿”å›çš„current_user_input: {user_input}")
            
            return {
                "current_user_input": user_input,  # å­˜å‚¨å½“å‰ç”¨æˆ·è¾“å…¥
                "round_id": current_round_id,  # è®¾ç½®å½“å‰è½®æ¬¡ID
                "current_step": ChatMarketingStep.PLAN
            }
        
        except Exception as e:
            # print(f"è¾“å…¥å¤„ç†æ­¥éª¤å¤±è´¥: {e}")
            raise e
    
    async def plan_step(self, state: ChatMarketingState) -> Dict[str, Any]:
        """è®¡åˆ’æ­¥éª¤ - åˆ†æç”¨æˆ·éœ€æ±‚å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’"""
        try:
            # å¦‚æœæ²¡æœ‰è®¡åˆ’å™¨å°±æŠ¥é”™
            if not self.planner:
                raise Exception("è®¡åˆ’å™¨æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆæ‰§è¡Œè®¡åˆ’")
            
            # ä»å…¨å±€å­—å…¸è·å–å½“å‰è½®æ¬¡æ•°æ®
            round_data = get_round_data()
            if not round_data:
                raise Exception("æ— æ³•è·å–å½“å‰è½®æ¬¡æ•°æ®")
            
            user_input = round_data.get('user_input', '')
            round_id = round_data.get('round_id', 0)
            
            # print(f"[DEBUG] ä»å…¨å±€å­—å…¸è·å–ç”¨æˆ·è¾“å…¥: {user_input}")
            # print(f"[DEBUG] å½“å‰è½®æ¬¡ID: {round_id}")
            
            if not user_input:
                plan_steps = ["ç”¨æˆ·æ²¡æœ‰è¾“å…¥å“¦ï¼Œé—®é—®æ˜¯æ€ä¹ˆå›äº‹ï¼Œéœ€è¦ä»€ä¹ˆéœ€æ±‚"]
                set_round_data('plan', plan_steps)
                return {
                    "plan": plan_steps,
                    "current_step": ChatMarketingStep.PLAN
                }
            
            # è·å–å†å²ä¼šè¯è®°å¿†ç”¨äºæ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            conversation_memory = list(state.get("conversation_memory", []))
            
            # æ„å»ºç®€åŒ–çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å†å²è®°å¿†å’Œå½“å‰è¾“å…¥ï¼‰
            conversation_context = ""
            if conversation_memory and len(conversation_memory) > 0:
                # åªå–æœ€è¿‘4æ¡å†å²æ¶ˆæ¯ï¼Œå¹¶æ™ºèƒ½å¤„ç†æ¶ˆæ¯é•¿åº¦
                recent_messages = conversation_memory[-4:]
                conversation_context = "\n\n## ç®€è¦å¯¹è¯å†å²\n"
                for msg in recent_messages:
                    if hasattr(msg, 'content'):
                        # ä¿ç•™æ‰€æœ‰æ¶ˆæ¯çš„å®Œæ•´å†…å®¹ï¼Œä»¥ä¾¿å‡†ç¡®å¼•ç”¨å†å²å¯¹è¯
                        if hasattr(msg, 'type') and msg.type == 'human':
                            conversation_context += f"ç”¨æˆ·: {msg.content}\n"
                        elif hasattr(msg, 'type') and msg.type == 'ai':
                            conversation_context += f"åŠ©æ‰‹: {msg.content}\n"
            
            conversation_context += f"\n**å½“å‰ç”¨æˆ·è¾“å…¥ï¼š{user_input}**\n"
              

            
            # æ„å»ºè®¡åˆ’å™¨çš„ç³»ç»Ÿæç¤ºè¯
            planner_system_prompt = f"""

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¥é”€ä»»åŠ¡è§„åˆ’å™¨ã€‚ä½ çš„èŒè´£æ˜¯åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œç¡®å®šåˆé€‚çš„å¯¹è¯ç±»å‹å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚

{conversation_context}

## ä½ çš„ä»»åŠ¡
åˆ†æç”¨æˆ·çš„è¾“å…¥ï¼Œå°†å…¶åˆ†ç±»ä¸ºä¸‰ç§å¯¹è¯ç±»å‹ä¹‹ä¸€ï¼Œç„¶åæä¾›å…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚

## å¯¹è¯ç±»å‹å®šä¹‰
### ç±»å‹1ï¼šchatï¼ˆé—²èŠï¼‰
**ä½¿ç”¨åœºæ™¯ï¼š** é—®å€™ã€é—²èŠã€è¥é”€çŸ¥è¯†é—®ç­”ã€ä¸€èˆ¬æ€§å’¨è¯¢ã€æ—¶é—´æŸ¥è¯¢ã€ä¿¡æ¯æœç´¢
**ç‰¹å¾ï¼š**
- ç”¨æˆ·è¿›è¡Œæ—¥å¸¸å¯¹è¯
- å…³äºè¥é”€æ¦‚å¿µæˆ–ä¸€èˆ¬å»ºè®®çš„é—®é¢˜
- é—®å€™å’Œç¤¾äº¤äº’åŠ¨
- è¯¢é—®å½“å‰æ—¶é—´ã€æ—¥æœŸç­‰æ—¶é—´ä¿¡æ¯
- éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯æˆ–è¶‹åŠ¿çš„é—®é¢˜
**æ‰§è¡Œæ–¹å¼ï¼š** æ ¹æ®ç”¨æˆ·éœ€æ±‚çµæ´»ä½¿ç”¨å·¥å…·ï¼Œå¯èƒ½åŒ…æ‹¬get_current_timeè·å–æ—¶é—´ä¿¡æ¯ã€web_search_toolæœç´¢ç›¸å…³å†…å®¹ï¼Œæˆ–ç›´æ¥å›å¤
**é‡è¦è§„åˆ™ï¼š** å¦‚æœéœ€è¦ä½¿ç”¨web_search_toolè¿›è¡Œç½‘ç»œæœç´¢ï¼Œå¿…é¡»å…ˆè°ƒç”¨get_current_timeè·å–å½“å‰æ—¶é—´ï¼Œä»¥ç¡®ä¿æœç´¢ç»“æœçš„æ—¶æ•ˆæ€§å’Œå‡†ç¡®æ€§

### ç±»å‹2ï¼šdiscussionï¼ˆè®¨è®ºï¼‰
**ä½¿ç”¨åœºæ™¯ï¼š** ç”¨æˆ·éœ€è¦æ¾„æ¸…æˆ–å¯¹ç°æœ‰æ–‡æ¡ˆæä¾›åé¦ˆï¼Œæˆ–è€…æ–‡æ¡ˆéœ€æ±‚ä¿¡æ¯ä¸è¶³
**ç‰¹å¾ï¼š**
- ç”¨æˆ·çš„æ–‡æ¡ˆéœ€æ±‚ä¸å®Œæ•´æˆ–æ¨¡ç³Šï¼ˆå¦‚"å¸®æˆ‘ç”Ÿæˆä¸€ä¸ªè¥é”€æ–‡æ¡ˆ"ã€"å†™ä¸ªæ–‡æ¡ˆ"ç­‰æ²¡æœ‰å…·ä½“äº§å“æˆ–å—ä¼—æˆ–åœºæ™¯ä¿¡æ¯çš„è¯·æ±‚ï¼‰
- ç”¨æˆ·å¯¹ä¹‹å‰ç”Ÿæˆçš„æ–‡æ¡ˆæä¾›åé¦ˆï¼ˆ"ç¬¬ä¸€ä¸ªä¸é”™"ã€"è¿™ä¸ªæ–‡æ¡ˆå¾ˆå¥½"ã€"ä¸é”™"ã€"å¾ˆæ£’"ï¼‰
- éœ€è¦æ”¶é›†æ›´å¤šå…³äºç›®æ ‡å—ä¼—ã€äº§å“ç‰¹ç‚¹æˆ–è¥é”€ç›®æ ‡çš„ä¿¡æ¯
- ç”¨æˆ·è®¨è®ºç°æœ‰æ–‡æ¡ˆä½†ä¸è¦æ±‚ç”Ÿæˆæ–°æ–‡æ¡ˆ
- é¦–æ¬¡æåŠæ–‡æ¡ˆç”Ÿæˆä½†ç¼ºä¹å…·ä½“ä¿¡æ¯çš„æƒ…å†µ
**é‡è¦åˆ¤æ–­è§„åˆ™ï¼š** å¦‚æœå¯¹è¯å†å²ä¸­åŠ©æ‰‹å·²ç»è¯¢é—®è¿‡æ–‡æ¡ˆéœ€æ±‚ï¼Œä¸”ç”¨æˆ·åœ¨å½“å‰å›å¤ä¸­æä¾›äº†äº§å“ä¿¡æ¯ï¼ˆå³ä½¿ç®€å•å¦‚"æŠ¤æ‰‹éœœ"ï¼‰ï¼Œæˆ–è€…ç”¨æˆ·è¡¨ç¤º"éƒ½è¡Œ"ã€"éšä¾¿"ã€"å¯ä»¥"ç­‰åŒæ„è¯æ±‡ï¼Œåº”è¯¥è½¬ä¸ºgenerationç±»å‹
**æ‰§è¡Œæ–¹å¼ï¼š** é€šè¿‡å¯¹è¯æ¾„æ¸…éœ€æ±‚æˆ–ç¡®è®¤åé¦ˆï¼Œä¸ä½¿ç”¨å·¥å…·

### ç±»å‹3ï¼šgenerationï¼ˆç”Ÿæˆï¼‰
**ä½¿ç”¨åœºæ™¯ï¼š** ç”¨æˆ·æä¾›äº†è¶³å¤Ÿä¿¡æ¯çš„æ–‡æ¡ˆåˆ›ä½œæˆ–ä¿®æ”¹è¯·æ±‚
**å…³é”®è¯ï¼š** "å†™æ–‡æ¡ˆ"ã€"ç”Ÿæˆæ–‡æ¡ˆ"ã€"åˆ›ä½œæ–‡æ¡ˆ"ã€"ç»™XXå†™æ–‡æ¡ˆ"ã€"å¸®æˆ‘å†™XXæ–‡æ¡ˆ"ã€"å¸®æˆ‘ç”ŸæˆXXæ–‡æ¡ˆ"
**ç‰¹å¾ï¼š**
- ç”¨æˆ·æ˜ç¡®è¦æ±‚ç”Ÿæˆæ–°æ–‡æ¡ˆä¸”æä¾›äº†å…·ä½“çš„äº§å“ã€å—ä¼—æˆ–åœºæ™¯ä¿¡æ¯
- åŒ…å«å…·ä½“äº§å“åç§°çš„æ–‡æ¡ˆè¯·æ±‚ï¼ˆå¦‚"å¸®æˆ‘ç”ŸæˆæŠ¤æ‰‹éœœæ–‡æ¡ˆ"ã€"å†™ä¸ªæœ‹å‹åœˆæ–‡æ¡ˆ"ï¼‰
- åŒ…å«å‘å¸ƒæ¸ é“ä¿¡æ¯çš„è¯·æ±‚ï¼ˆå¦‚"æœ‹å‹åœˆæ–‡æ¡ˆ"ã€"ç¾¤å‘æ–‡æ¡ˆ"ï¼‰
- åŒ…å«çƒ­é”€ã€è¶‹åŠ¿ç­‰æœç´¢éœ€æ±‚çš„æ–‡æ¡ˆè¯·æ±‚ï¼ˆå¦‚"ä»Šå¹´ä»€ä¹ˆçƒ­é”€ï¼Œå¸®æˆ‘ç”Ÿæˆæœ‹å‹åœˆæ–‡æ¡ˆ"ï¼‰
- ç”¨æˆ·æƒ³è¦ä¿®æ”¹ã€ä¼˜åŒ–ã€é‡å†™æˆ–æ¶¦è‰²ç°æœ‰æ–‡æ¡ˆ
- è¦æ±‚ç¼©çŸ­ã€åŠ é•¿æˆ–é£æ ¼å˜åŒ–çš„è¯·æ±‚
- ç”¨æˆ·ä½¿ç”¨"ç¬¬ä¸€ç§"ã€"ç¬¬ä¸€æ¡"ã€"ç¬¬ä¸€ä¸ª"ç­‰è¡¨è¿°æŒ‡ä»£ç‰¹å®šæ–‡æ¡ˆè¿›è¡Œä¿®æ”¹
- åœ¨discussionç¯èŠ‚åï¼Œç”¨æˆ·æä¾›äº†è¶³å¤Ÿä¿¡æ¯çš„æ–‡æ¡ˆç”Ÿæˆè¯·æ±‚
- **é‡è¦ï¼š** å½“å¯¹è¯å†å²æ˜¾ç¤ºåŠ©æ‰‹å·²è¯¢é—®æ–‡æ¡ˆéœ€æ±‚ï¼Œä¸”ç”¨æˆ·æä¾›äº†äº§å“åç§°ï¼ˆå¦‚"æŠ¤æ‰‹éœœ"ã€"é¢è†œ"ç­‰ï¼‰æˆ–è¡¨ç¤º"éƒ½è¡Œ"ã€"éšä¾¿"ã€"å¯ä»¥"ç­‰åŒæ„è¯æ±‡æ—¶ï¼Œåº”ç«‹å³ç”Ÿæˆæ–‡æ¡ˆè€Œéç»§ç»­è¯¢é—®
**æ‰§è¡Œæ–¹å¼ï¼š** ä½¿ç”¨é€‚å½“çš„å·¥å…· - å¯èƒ½åŒ…æ‹¬ get_current_timeã€web_search_toolã€marketing_copy_generator
**é‡è¦è§„åˆ™ï¼š** å¦‚æœéœ€è¦ä½¿ç”¨web_search_toolè¿›è¡Œç½‘ç»œæœç´¢ï¼Œå¿…é¡»å…ˆè°ƒç”¨get_current_timeè·å–å½“å‰æ—¶é—´ï¼Œä»¥ç¡®ä¿æœç´¢ç»“æœçš„æ—¶æ•ˆæ€§å’Œå‡†ç¡®æ€§

## è¾“å‡ºè¦æ±‚
ä½ å¿…é¡»è¾“å‡ºç»“æ„åŒ–çš„JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- conversation_type: å¯¹è¯ç±»å‹ï¼ˆchat/discussion/generationï¼‰
- execution_plan: è¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤è¯´æ˜
- steps: å…·ä½“æ‰§è¡Œæ­¥éª¤åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæ²¡æœ‰å…·ä½“æ­¥éª¤å¯ä»¥ä¸ºç©ºï¼‰

## åˆ†ç±»è¦æ±‚
1. å§‹ç»ˆåˆ†ç±»ä¸ºä¸‰ç§ç±»å‹ä¸­çš„ä¸€ç§
2. **ä¼˜å…ˆçº§åŸåˆ™ï¼š** å¯¹äºæ¨¡ç³Šçš„æ–‡æ¡ˆç”Ÿæˆè¯·æ±‚ï¼ˆå¦‚"å¸®æˆ‘ç”Ÿæˆä¸€ä¸ªè¥é”€æ–‡æ¡ˆ"ã€"å†™ä¸ªæ–‡æ¡ˆ"ç­‰ç¼ºä¹å…·ä½“ä¿¡æ¯çš„è¯·æ±‚ï¼‰ï¼Œä¼˜å…ˆé€‰æ‹©discussionç±»å‹è¿›è¡Œéœ€æ±‚æ¾„æ¸…
3. **å…³é”®åˆ¤æ–­ï¼š** ä»”ç»†åˆ†æå¯¹è¯å†å²ï¼Œå¦‚æœåŠ©æ‰‹ä¹‹å‰å·²ç»è¯¢é—®è¿‡æ–‡æ¡ˆéœ€æ±‚ä¿¡æ¯ï¼Œä¸”ç”¨æˆ·åœ¨å½“å‰å›å¤ä¸­ï¼š
   - æä¾›äº†å…·ä½“äº§å“åç§°ï¼ˆå¦‚"æŠ¤æ‰‹éœœ"ã€"é¢è†œ"ã€"å£çº¢"ç­‰ï¼‰
   - æˆ–è¡¨ç¤ºåŒæ„/éšæ„çš„è¯æ±‡ï¼ˆå¦‚"éƒ½è¡Œ"ã€"éšä¾¿"ã€"å¯ä»¥"ã€"è¡Œ"ç­‰ï¼‰
   åˆ™åº”è¯¥é€‰æ‹©generationç±»å‹ï¼Œç«‹å³ç”Ÿæˆæ–‡æ¡ˆï¼Œè€Œä¸æ˜¯ç»§ç»­discussion
4. å¯¹äºgenerationç±»å‹ï¼Œåœ¨execution_planä¸­æŒ‡å®šè¦ä½¿ç”¨çš„å·¥å…·ï¼šget_current_timeã€web_search_toolã€marketing_copy_generator
5. å¯¹äºchatç±»å‹ï¼Œæ ¹æ®ç”¨æˆ·éœ€æ±‚åœ¨execution_planä¸­æŒ‡å®šè¦ä½¿ç”¨çš„å·¥å…·ï¼ˆå¦‚æ—¶é—´æŸ¥è¯¢ä½¿ç”¨get_current_timeï¼Œä¿¡æ¯æœç´¢ä½¿ç”¨web_search_toolï¼‰æˆ–è¯´æ˜"ç›´æ¥å›å¤ï¼Œä¸ä½¿ç”¨å·¥å…·"
6. å¯¹äºdiscussionç±»å‹ï¼Œä¸»è¦é€šè¿‡å¯¹è¯æ¾„æ¸…éœ€æ±‚ï¼Œå¿…è¦æ—¶å¯åœ¨execution_planä¸­æŒ‡å®šä½¿ç”¨ç›¸å…³å·¥å…·ï¼ˆå¦‚æ—¶é—´æŸ¥è¯¢ã€ä¿¡æ¯æœç´¢ç­‰ï¼‰
7. execution_planè¦å…·ä½“æ˜ç¡®

## è¾“å‡ºæ ¼å¼
è¾“å‡ºç»“æ„åŒ–JSONï¼ŒåŒ…å«conversation_typeã€execution_planå’Œstepså­—æ®µã€‚å¯¹äºgenerationç±»å‹ï¼Œéœ€åœ¨execution_planä¸­è¯´æ˜å·¥å…·ä½¿ç”¨å’Œå­—æ•°è®¾ç½®ç­–ç•¥ã€‚

      """
            
            # è°ƒç”¨è®¡åˆ’å™¨ç”Ÿæˆè®¡åˆ’
            user_prompt = f"å½“å‰ç”¨æˆ·éœ€æ±‚ï¼š{user_input}"
            plan_result = await self.planner.ainvoke([
                ("system", planner_system_prompt),
                ("user", user_prompt)
            ])
            
            # ä»structured outputä¸­ç›´æ¥è·å–ç»“æœ
            conversation_type = plan_result.conversation_type
            execution_plan = plan_result.execution_plan
            plan_steps = plan_result.steps if plan_result.steps else [execution_plan]
            
            # print(f"[DEBUG] LLMç»“æ„åŒ–è¾“å‡º - å¯¹è¯ç±»å‹: {conversation_type}")
            # print(f"[DEBUG] LLMç»“æ„åŒ–è¾“å‡º - æ‰§è¡Œè®¡åˆ’: {execution_plan}")
            # print(f"[DEBUG] LLMç»“æ„åŒ–è¾“å‡º - æ­¥éª¤åˆ—è¡¨: {plan_steps}")
            
            # éªŒè¯å¯¹è¯ç±»å‹æ˜¯å¦æœ‰æ•ˆ
            available_conversation_types = ["chat", "discussion", "generation"]
            if conversation_type not in available_conversation_types:
                raise ValueError(f"æ— æ•ˆçš„å¯¹è¯ç±»å‹: {conversation_type}ï¼Œæœ‰æ•ˆç±»å‹: {available_conversation_types}")
            
            # æå–å·¥å…·åç§°
            available_tools = ["get_current_time", "web_search_tool", "marketing_copy_generator"]
            planned_tools = []
            execution_plan_lower = execution_plan.lower()
            for tool in available_tools:
                if tool in execution_plan_lower:
                    planned_tools.append(tool)
            
            # print(f"[DEBUG] å¤§æ¨¡å‹è®¡åˆ’ä½¿ç”¨çš„å·¥å…·: {planned_tools}")
          
            # å­˜å‚¨åˆ°å…¨å±€å­—å…¸
            set_round_data('plan', plan_steps)
            set_round_data('planned_tools', planned_tools)
            set_round_data('conversation_type', conversation_type)
            
            # print(f"ğŸ“‹ æœ¬æ¬¡å¯¹è¯ç±»å‹: {conversation_type}")
            # print(f"ğŸ”§ è®¡åˆ’ä½¿ç”¨çš„å·¥å…·: {planned_tools}")
            # print(f"ğŸ“ æ‰§è¡Œè®¡åˆ’: {plan_steps}")
            
            # å¦‚æœæ²¡æœ‰å·¥å…·éœ€è¦ä½¿ç”¨ï¼Œç›´æ¥å›å¤
            if not planned_tools:
                # print("ğŸ—£ï¸ è§„åˆ’å™¨å†³å®šç›´æ¥å›å¤")
                # å³ä½¿ç›´æ¥å›å¤ï¼Œä¹Ÿè¦åœ¨planä¸­ä½“ç°å‡ºæ‰§è¡Œè®¡åˆ’
                direct_reply_plan = [f"æ ¹æ®{conversation_type}ç±»å‹å¯¹è¯ç›´æ¥å›å¤ç”¨æˆ·: {execution_plan}"]
                return {
                    "current_step": ChatMarketingStep.COMPLETE,
                    "plan": direct_reply_plan,
                    "past_steps": []
                }
            
            return {
                "plan": plan_steps,
                "current_step": ChatMarketingStep.PLAN,
                "past_steps": []
            }
            
        except Exception as e:
            # print(f"âŒ è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise e
    
    async def execute_step(self, state: ChatMarketingState) -> Dict[str, Any]:
        """æ‰§è¡Œæ­¥éª¤ - æ‰§è¡Œè®¡åˆ’ä¸­çš„å½“å‰æ­¥éª¤"""
        try:
            # ä»å…¨å±€å­—å…¸å’ŒçŠ¶æ€è·å–æ•°æ®
            round_data = get_round_data()
            if not round_data:
                raise Exception("æ— æ³•è·å–å½“å‰è½®æ¬¡æ•°æ®")
            
            plan = state.get("plan", [])
            past_steps = state.get("past_steps", [])
            
            if not plan:
                raise ValueError("æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’ï¼Œç¨‹åºç»ˆæ­¢æ‰§è¡Œ")
            
            # è·å–å½“å‰è¦æ‰§è¡Œçš„æ­¥éª¤
            current_task = plan[0]
            round_id = round_data.get('round_id', 0)
            
            # print(f"[DEBUG] æ‰§è¡Œæ­¥éª¤: {current_task}")
            # print(f"[DEBUG] å½“å‰è½®æ¬¡ID: {round_id}")
            
            # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            plan_str = "\n".join(f"{i+1}. {step}" for i, step in enumerate(plan))
            past_steps_str = "\n".join(f"- {step}: {result}" for step, result in past_steps)
            
            # è·å–å¯¹è¯å†å²ä¸Šä¸‹æ–‡
            conversation_memory = state.get("conversation_memory", [])
            conversation_context = ""
            if conversation_memory:
                conversation_context = "\n\n## å¯¹è¯å†å²\n"
                for msg in conversation_memory:
                    if hasattr(msg, 'content'):
                        if hasattr(msg, 'type') and msg.type == 'human':
                            conversation_context += f"ç”¨æˆ·: {msg.content}\n"
                        elif hasattr(msg, 'type') and msg.type == 'ai':
                            conversation_context += f"åŠ©æ‰‹: {msg.content}\n"
            
            # è·å–å½“å‰ç”¨æˆ·è¾“å…¥
            current_user_input = state.get("current_user_input", "")
            # print(f"[DEBUG] execute_step - ä»stateè·å–çš„current_user_input: {current_user_input}")
            if current_user_input:
                conversation_context += f"\n**å½“å‰ç”¨æˆ·è¾“å…¥ï¼š{current_user_input}**\n"
            
            # æ„å»ºå¯¹è¯è®°å¿†æ–‡æœ¬ä¾›å·¥å…·ä½¿ç”¨
            conversation_memory_text = ""
            if conversation_memory:
                for msg in conversation_memory[-4:]:  # åªå–æœ€è¿‘4æ¡æ¶ˆæ¯
                    if hasattr(msg, 'content') and hasattr(msg, 'type'):
                        if msg.type == 'human':
                            conversation_memory_text += f"ç”¨æˆ·: {msg.content}\n"
                        elif msg.type == 'ai':
                            conversation_memory_text += f"åŠ©æ‰‹: {msg.content}\n"
            
            task_prompt = f"""æ‰§è¡Œè®¡åˆ’ï¼š
{plan_str}

å·²å®Œæˆæ­¥éª¤ï¼š
{past_steps_str}

å½“å‰ä»»åŠ¡ï¼šæ‰§è¡Œæ­¥éª¤{len(past_steps) + 1} - {current_task}
{conversation_context}

è¯·ä¸“æ³¨å®Œæˆè¿™ä¸ªå…·ä½“ä»»åŠ¡ï¼Œæ ¹æ®å¯¹è¯å†å²å’Œå½“å‰ç”¨æˆ·è¾“å…¥æ¥æ‰§è¡Œã€‚

**å­—æ•°è¦æ±‚è®¾ç½®**ï¼šè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚æ™ºèƒ½è®¾ç½®min_word_countå‚æ•°ï¼š
- æ ‡å‡†æ–‡æ¡ˆéœ€æ±‚ï¼šè®¾ç½®ä¸º50-80å­—
- ç‰¹å®šåœºæ™¯ï¼šæœ‹å‹åœˆ/æ ‡é¢˜(50-80å­—)ã€äº§å“ä»‹ç»(100-150å­—)ã€å“ç‰Œæ•…äº‹(200-300å­—)"""
            
            # åŠ¨æ€åˆ›å»ºæ‰§è¡Œå™¨Agentï¼Œä¼ å…¥å¯¹è¯è®°å¿†
            executor_agent = self._create_executor_agent(conversation_memory_text)
            if not executor_agent:
                raise RuntimeError("æ‰§è¡Œå™¨Agentåˆ›å»ºå¤±è´¥ï¼Œæ— æ³•æ‰§è¡Œå·¥å…·è°ƒç”¨ä»»åŠ¡")
            
            # è°ƒç”¨æ‰§è¡Œå™¨Agent
            response = await executor_agent.ainvoke({
                "messages": [("ai", task_prompt)]
            })
            
            # æå–æ‰§è¡Œç»“æœ - åªå­˜å‚¨ç®€å•çš„çŠ¶æ€ä¿¡æ¯ï¼Œé¿å…å†—ä½™çš„æ–‡æ¡ˆå†…å®¹
            ai_messages = [msg for msg in response["messages"] if isinstance(msg, AIMessage)]
            execution_result = ai_messages[-1].content if ai_messages else "æ‰§è¡Œå®Œæˆ"
            
            # å°†æ‰§è¡Œç»“æœå­˜å‚¨åˆ°å…¨å±€å­—å…¸ - ä¸å­˜å‚¨å†—ä½™çš„resultå­—æ®µ
            current_execution_results = round_data.get('execution_results', [])
            current_execution_results.append({
                'task': current_task,
                'response_messages': response["messages"]
            })
            set_round_data('execution_results', current_execution_results)
            
            # print(f"ğŸ“‹ æ‰§è¡Œç»“æœå·²å­˜å‚¨åˆ°å…¨å±€å­—å…¸: {current_task}")
            
            result = {
                "past_steps": past_steps + [(current_task, execution_result)],
                "plan": plan[1:],  # ç§»é™¤å·²æ‰§è¡Œçš„æ­¥éª¤
                "current_step": ChatMarketingStep.EXECUTE
            }

            return result
            
        except Exception as e:
            # print(f"âŒ æ‰§è¡Œæ­¥éª¤å¤±è´¥: {str(e)}")
            raise e
    
    def _format_past_steps(self, past_steps: List[tuple]) -> str:
        """æ ¼å¼åŒ–å·²å®Œæˆæ­¥éª¤ï¼Œä¿ç•™ToolMessageçš„åŸå§‹ç»“æ„"""
        formatted_steps = []
        for step, result in past_steps:
            # å¦‚æœç»“æœåŒ…å«ToolMessageï¼Œä¿ç•™å…¶åŸå§‹JSONç»“æ„
            if isinstance(result, str) and 'ToolMessage' in result and 'marketing_copies' in result:
                formatted_steps.append(f"- {step}: {result}")
            else:
                formatted_steps.append(f"- {step}: {result}")
        return "\n".join(formatted_steps)
    
    async def replan_step(self, state: ChatMarketingState) -> Dict[str, Any]:
        """é‡æ–°è§„åˆ’æ­¥éª¤ - å†³å®šç»§ç»­æ‰§è¡Œè¿˜æ˜¯å®Œæˆä»»åŠ¡"""
        import json
        try:
            plan = state.get("plan", [])
            past_steps = state.get("past_steps", [])
            
            # å¦‚æœæ²¡æœ‰å‰©ä½™è®¡åˆ’ï¼Œè½¬åˆ°finalèŠ‚ç‚¹å¤„ç†å›å¤
            if not plan:
                raise ValueError("æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’ï¼Œç¨‹åºç»ˆæ­¢æ‰§è¡Œ")
            
            # è·å–é‡è¯•æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
            retry_count = state.get("retry_count", 0)
            max_retries = 3
            
            if retry_count >= max_retries:
                # print(f"âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œå¼ºåˆ¶å®Œæˆä»»åŠ¡")
                return {
                    "current_step": ChatMarketingStep.COMPLETE
                }
            
            # åˆ†ææ‰§è¡Œç»“æœï¼Œæ£€æµ‹å¤±è´¥çš„æ­¥éª¤
            round_data = get_round_data()
            execution_results = round_data.get('execution_results', []) if round_data else []
            planned_tools = round_data.get('planned_tools', []) if round_data else []
            conversation_type = round_data.get('conversation_type', 'chat') if round_data else 'chat'
            
            # æ£€æŸ¥è¥é”€æ–‡æ¡ˆç”ŸæˆçŠ¶æ€
            marketing_copy_success = False
            if 'marketing_copy_generator' in planned_tools:
                for execution_result in execution_results:
                    response_messages = execution_result.get('response_messages', [])
                    for msg in response_messages:
                        if hasattr(msg, 'name') and msg.name == 'marketing_copy_generator':
                            try:
                                content_data = json.loads(msg.content)
                                if content_data.get('marketing_copies'):
                                    marketing_copy_success = True
                                    break
                            except:
                                pass
                    if marketing_copy_success:
                        break
            
            # æ„å»ºè¯¦ç»†çš„é‡æ–°è§„åˆ’ä¸Šä¸‹æ–‡
            remaining_plan_str = "\n".join(f"{i+1}. {step}" for i, step in enumerate(plan))
            
            # åˆ†ææ‰§è¡ŒçŠ¶æ€
            execution_status = "æ‰§è¡ŒçŠ¶æ€åˆ†æï¼š\n"
            if conversation_type == 'generation':
                if marketing_copy_success:
                    execution_status += "è¥é”€æ–‡æ¡ˆç”ŸæˆæˆåŠŸ\n"
                else:
                    execution_status += "è¥é”€æ–‡æ¡ˆç”Ÿæˆå¤±è´¥ï¼Œéœ€è¦é‡æ–°å°è¯•\n"
            elif conversation_type in ['chat', 'discussion']:
                if past_steps:
                    execution_status += "å¯¹è¯/è®¨è®ºæ­¥éª¤å·²æ‰§è¡Œ\n"
                else:
                    execution_status += "å¯¹è¯/è®¨è®ºæ­¥éª¤æ‰§è¡Œå¼‚å¸¸\n"
            
            replan_context = f"""## å½“å‰çŠ¶æ€åˆ†æ
å¯¹è¯ç±»å‹: {conversation_type}
é‡è¯•æ¬¡æ•°: {retry_count + 1}/{max_retries}

{execution_status}
å·²å®Œæˆçš„æ­¥éª¤ï¼š
{self._format_past_steps(past_steps)}

å‰©ä½™è®¡åˆ’ï¼š
{remaining_plan_str}

## å†³ç­–è¦æ±‚
æ ¹æ®ä¸Šè¿°åˆ†æï¼Œè¯·å†³å®šï¼š
1. å¦‚æœä»»åŠ¡å·²æˆåŠŸå®Œæˆï¼Œè¿”å›Response
2. å¦‚æœéœ€è¦é‡æ–°æ‰§è¡Œå¤±è´¥çš„æ­¥éª¤ï¼Œè¿”å›åŒ…å«å…·ä½“æ­¥éª¤çš„Plan
3. é‡ç‚¹å…³æ³¨è¥é”€æ–‡æ¡ˆç”Ÿæˆæ˜¯å¦æˆåŠŸï¼ˆå¦‚æœæ˜¯generationç±»å‹ï¼‰

è¯·åŸºäºæ‰§è¡ŒçŠ¶æ€åšå‡ºæ˜æ™ºå†³ç­–ã€‚"""
            
            replan_result = await self.replanner.ainvoke({"input": replan_context})
            
            if isinstance(replan_result.action, Response):
                return {
                    "current_step": ChatMarketingStep.COMPLETE
                }
            else:
                # å¢åŠ é‡è¯•æ¬¡æ•°
                return {
                    "plan": replan_result.action.steps,
                    "current_step": ChatMarketingStep.EXECUTE,
                    "retry_count": retry_count + 1
                }
                
        except Exception as e:
            # print(f"âŒ é‡æ–°è§„åˆ’å¤±è´¥: {str(e)}")
            raise e
    

    
    async def chat_node(self, state: ChatMarketingState) -> Dict[str, Any]:
        """èŠå¤©èŠ‚ç‚¹ - Plan-and-Executeæ¨¡å¼çš„å…¥å£"""
        try:
            current_step = state.get("current_step", ChatMarketingStep.PLAN)
            
            # æ ¹æ®å½“å‰æ­¥éª¤è°ƒç”¨ç›¸åº”çš„å¤„ç†æ–¹æ³•
            if current_step == ChatMarketingStep.PLAN:
                return await self.plan_step(state)
            elif current_step == ChatMarketingStep.EXECUTE:
                return await self.execute_step(state)
            elif current_step == ChatMarketingStep.REPLAN:
                return await self.replan_step(state)
            else:
                # é»˜è®¤æƒ…å†µæˆ–å®ŒæˆçŠ¶æ€
                response = state.get("response")
                
                return {
                    "current_step": ChatMarketingStep.COMPLETE
                }
            
        except Exception as e:
            # print(f"âŒ èŠå¤©èŠ‚ç‚¹å¤„ç†å¤±è´¥: {str(e)}")
            raise e
    



# ==================== å·¥ä½œæµæ§åˆ¶ ====================

async def create_final_output(state: ChatMarketingState) -> Dict[str, Any]:
    """åˆ›å»ºæœ€ç»ˆè¾“å‡º - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥ä»å·¥å…·ç»“æœè·å–æ–‡æ¡ˆå¹¶è®©LLMç”Ÿæˆè‡ªç„¶å›å¤"""
    from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
    import json
    
    try:
        # ä»å…¨å±€å­—å…¸è·å–å½“å‰è½®æ¬¡æ•°æ®
        round_data = get_round_data()
        if not round_data:
            raise Exception("æ— æ³•è·å–å½“å‰è½®æ¬¡æ•°æ®")
        
        user_input = round_data.get('user_input', '')
        execution_results = round_data.get('execution_results', [])
        if not user_input:
            raise ValueError("ç”¨æˆ·è¾“å…¥ä¸ºç©º")
        
        # print(f"[DEBUG] FinalèŠ‚ç‚¹ - ç”¨æˆ·è¾“å…¥: {user_input}")
        
        # å…ˆæ£€æŸ¥planned_toolsæ˜¯å¦åŒ…å«æ–‡æ¡ˆç”Ÿæˆå·¥å…·
        planned_tools = round_data.get('planned_tools', [])
        # print(f"[DEBUG] FinalèŠ‚ç‚¹ - planned_tools: {planned_tools}")
        
        # è·å– marketing_copies - ä½¿ç”¨ä¸print_memoryèŠ‚ç‚¹ç›¸åŒçš„æå–é€»è¾‘
        marketing_copies = None
        try:
            # éå†æŸ¥æ‰¾marketing_copy_generatorå·¥å…·ç»“æœ
            for execution_result in execution_results:
                response_messages = execution_result.get('response_messages', [])
                for msg in response_messages:
                    if hasattr(msg, 'name') and msg.name == 'marketing_copy_generator':
                        try:
                            content_data = json.loads(msg.content)
                            found_copies = content_data.get('marketing_copies', [])
                            # åªæœ‰å½“æ‰¾åˆ°éç©ºæ–‡æ¡ˆæ—¶æ‰è®¾ç½®marketing_copies
                            if found_copies:
                                marketing_copies = found_copies
                                # print(f"[DEBUG] FinalèŠ‚ç‚¹ - è·å–åˆ° {len(marketing_copies)} ä¸ªæ–‡æ¡ˆ")
                            break
                        except json.JSONDecodeError as e:
                            # print(f"[DEBUG] FinalèŠ‚ç‚¹ - JSONè§£æå¤±è´¥: {e}")
                            continue
                if marketing_copies:  # æ‰¾åˆ°åè·³å‡ºå¤–å±‚å¾ªç¯
                    break
            if not marketing_copies:
                marketing_copies = None
        except Exception as e:
            # print(f"[DEBUG] FinalèŠ‚ç‚¹ - è·å–marketing_copieså¤±è´¥: {e}")
            marketing_copies = None
        # print(f"[DEBUG] FinalèŠ‚ç‚¹ - marketing_copiesæœ€ç»ˆå€¼: {marketing_copies}")
        
        # åˆ›å»ºLLMå®ä¾‹
        from agents.persona_config.config_manager import config_manager
        cfg = config_manager.get_config() or {}
        
        llm = create_llm(
            model_provider=cfg.get("model_provider", "openrouter"),
            model_name=cfg.get("model_name", "openai/gpt-5-chat"),
            temperature=0.7
        )
        
        # è·å–äººè®¾æç¤ºè¯
        from agents.marketing_assistant.persona_prompt_template import PersonaPromptTemplate
        persona_template = PersonaPromptTemplate()
        
        # æŒ‰éœ€ç»„åˆåŸºç¡€äººè®¾æç¤ºè¯
        persona_parts = [
            persona_template.FOUNDATION_PROMPTS["role_identity"],
            persona_template.FOUNDATION_PROMPTS["core_principles"],
            persona_template.COGNITIVE_PROMPTS["analysis"],
            persona_template.TASK_PROMPTS["copywriting"],
            persona_template.INTERACTION_PROMPTS["communication_style"],
            persona_template.INTERACTION_PROMPTS["output_format"]
        ]
        persona_prompt = "\n\n".join(persona_parts)
        
        # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«è‡ªç„¶å¯¹è¯å’Œä¸šåŠ¡å¼•å¯¼è§„åˆ™
        system_parts = [
            persona_prompt,
            persona_template.TASK_PROMPTS["consultation"],
            persona_template.TASK_PROMPTS["copywriting"],
            persona_template.INTERACTION_PROMPTS["interaction_rules"],
            persona_template.INTERACTION_PROMPTS["natural_conversation"],
            persona_template.INTERACTION_PROMPTS["business_guidance"]
        ]
        
        # æ ¹æ®å¯¹è¯ç±»å‹æ·»åŠ ä¸åŒçš„æç¤ºè¯
        conversation_type = round_data.get('conversation_type')
        if conversation_type == "discussion":
            system_parts.append(persona_template.TASK_PROMPTS["discussion_mode"])
        else:
            # æ·»åŠ é’ˆå¯¹æ–‡æ¡ˆå±•ç¤ºçš„ç‰¹å®šè¦æ±‚
            system_parts.append(persona_template.TASK_PROMPTS["copywriting_display"])
        system_prompt = "\n\n".join(system_parts)
        
        # è·å–å¯¹è¯å†å²
        conversation_memory = state.get("conversation_memory", [])
        conversation_text = ""
        is_first_chat = not conversation_memory or len(conversation_memory) == 0
        
        if conversation_memory:
            for msg in conversation_memory[-4:]:  # åªå–æœ€è¿‘4æ¡æ¶ˆæ¯
                if hasattr(msg, 'content') and hasattr(msg, 'type'):
                    if msg.type == 'human':
                        conversation_text += f"ç”¨æˆ·: {msg.content}\n"
                    elif msg.type == 'ai':
                        conversation_text += f"åŠ©æ‰‹: {msg.content}\n"
        
        # è·å–å¯¹è¯ç±»å‹
        conversation_type = round_data.get('conversation_type')
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        if marketing_copies:
            # æœ‰æ–‡æ¡ˆæ—¶å±•ç¤ºæ–‡æ¡ˆ
            user_message = f"""ç”¨æˆ·æœ€æ–°æ¶ˆæ¯: {user_input}

å¯¹è¯å†å²:
{conversation_text}

å¯¹è¯ç±»å‹: {conversation_type}

æˆ‘åˆšåˆšæ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆäº†ä»¥ä¸‹è¥é”€æ–‡æ¡ˆ:
{json.dumps(marketing_copies, ensure_ascii=False, indent=2)}

ç°åœ¨è¯·ä½œä¸º{{XX}}ï¼ˆè¥é”€ä¸“å®¶ï¼‰è‡ªç„¶åœ°å›å¤ç”¨æˆ·ï¼š
- ç”¨å£è¯­åŒ–çš„æ–¹å¼ä»‹ç»ä½ åˆšåˆ›ä½œçš„æ–‡æ¡ˆï¼Œé¿å…ä¹¦é¢åŒ–è¡¨è¾¾
- ä¸è¦è¯´"é›†ä¸­åœ¨"ã€"ä»¥åŠ"ã€"åŒæ—¶"ç­‰è¯æ±‡ï¼Œç”¨"è¿˜æœ‰"ã€"å¦å¤–å°±æ˜¯"ç­‰è‡ªç„¶è¡¨è¾¾
- åƒæœ‹å‹èŠå¤©ä¸€æ ·è½»æ¾ä»‹ç»æ–‡æ¡ˆç‰¹ç‚¹
- å›å¤åè¦åˆ¤æ–­æ˜¯å¦ä¸è¥é”€ä¸šåŠ¡ç›¸å…³ï¼Œå¦‚æœç›¸å…³å°±è‡ªç„¶å¼•å¯¼åˆ°ä½ çš„ä¸“ä¸šæœåŠ¡
- ç”¨"å¯¹äº†"ã€"è¯´åˆ°è¿™ä¸ª"ç­‰è‡ªç„¶è¿‡æ¸¡ï¼Œä¸è¦ç”Ÿç¡¬æ¨é”€
- è®©å®¢æˆ·æ„Ÿè§‰ä½ æ˜¯åœ¨åˆ†äº«ç»éªŒï¼Œè€Œä¸æ˜¯åœ¨æ¨é”€"""
        
        # æ²¡æœ‰æ–‡æ¡ˆæ—¶æ ¹æ®å¯¹è¯ç±»å‹å›å¤
        if not marketing_copies:
            # è·å–past_stepsä¿¡æ¯
            past_steps = state.get("past_steps", [])
            past_steps_text = ""
            if past_steps:
                # æ ¼å¼åŒ–past_stepsä¿¡æ¯
                for i, (step_name, step_result) in enumerate(past_steps):
                    past_steps_text += f"æ­¥éª¤{i+1}: {step_name}\nç»“æœ: {step_result}\n\n"
            
            # æ ¹æ®å¯¹è¯ç±»å‹æ„å»ºä¸åŒçš„ç”¨æˆ·æ¶ˆæ¯
            if conversation_type == "discussion":
                user_message = f"""ç”¨æˆ·æœ€æ–°æ¶ˆæ¯: {user_input}

å¯¹è¯å†å²:
{conversation_text}

å¯¹è¯ç±»å‹: {conversation_type}

ç°åœ¨è¯·ä½œä¸º{{XX}}ï¼ˆè¥é”€ä¸“å®¶ï¼‰è‡ªç„¶åœ°å›å¤ç”¨æˆ·ï¼š
- ç”¨æˆ·çš„æ–‡æ¡ˆéœ€æ±‚è¿˜ä¸å¤Ÿå…·ä½“ï¼Œéœ€è¦äº†è§£æ›´å¤šä¿¡æ¯
- ç”¨å£è¯­åŒ–çš„æ–¹å¼è¯¢é—®äº§å“ä¿¡æ¯ã€ç›®æ ‡å—ä¼—ç­‰
- ä¸è¦åˆ—ä¸¾å¼æé—®ï¼Œè¦åƒæœ‹å‹èŠå¤©ä¸€æ ·è‡ªç„¶è¯¢é—®
- é¿å…"ç¬¬ä¸€ã€ç¬¬äºŒã€ç¬¬ä¸‰"çš„è¡¨è¾¾æ–¹å¼
- ç”¨"æˆ‘æƒ³äº†è§£ä¸€ä¸‹"ã€"ä½ èƒ½è·Ÿæˆ‘è¯´è¯´"ç­‰è‡ªç„¶è¡¨è¾¾
- è®©ç”¨æˆ·æ„Ÿè§‰ä½ æ˜¯çœŸå¿ƒæƒ³å¸®åŠ©ä»–ä»¬ï¼Œè€Œä¸æ˜¯åœ¨èµ°æµç¨‹"""
            else:
                user_message = f"""ç”¨æˆ·æœ€æ–°æ¶ˆæ¯: {user_input}

å¯¹è¯å†å²:
{conversation_text}

å¯¹è¯ç±»å‹: {conversation_type}

æ‰§è¡Œæ­¥éª¤å’Œç»“æœ:
{past_steps_text}

ç°åœ¨è¯·ä½œä¸º{{XX}}ï¼ˆè¥é”€ä¸“å®¶ï¼‰è‡ªç„¶åœ°å›å¤ç”¨æˆ·ï¼š
- æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œæ‰§è¡Œç»“æœç»™å‡ºå£è¯­åŒ–çš„å›å¤
- é¿å…ä¹¦é¢åŒ–è¡¨è¾¾ï¼Œç”¨"æˆ‘è§‰å¾—"ã€"æˆ‘å‘ç°"ç­‰å£è¯­åŒ–è¡¨è¾¾
- å›ç­”å®Œé—®é¢˜åè¦åˆ¤æ–­æ˜¯å¦ä¸è¥é”€ç›¸å…³ï¼Œå¦‚æœç›¸å…³å°±è‡ªç„¶å¼•å¯¼
- ç”¨"å¯¹äº†"ã€"è¯´åˆ°è¿™ä¸ª"ç­‰è¿‡æ¸¡è¯è‡ªç„¶å¼•å¯¼åˆ°ä¸šåŠ¡
- è®©å®¢æˆ·æ„Ÿè§‰ä½ æ˜¯åœ¨åˆ†äº«ä¸“ä¸šè§è§£ï¼Œè€Œä¸æ˜¯æ¨é”€"""
        
        # è°ƒç”¨LLMç”Ÿæˆå›å¤
        # print(f"[DEBUG] FinalèŠ‚ç‚¹ - System Prompt: {system_prompt[:200]}...")
        # print(f"[DEBUG] FinalèŠ‚ç‚¹ - User Message: {user_message[:300]}...")
        
        response = await llm.ainvoke([
            ("system", system_prompt),
            ("user", user_message)
        ])
        
        # å¤„ç†å›å¤æ ¼å¼ï¼Œç§»é™¤å¤šä½™ç©ºè¡Œ
        final_response = response.content.strip()
        # å°†å¤šä¸ªè¿ç»­æ¢è¡Œæ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œ
        import re
        final_response = re.sub(r'\n\s*\n', '\n', final_response)
        # print(f"[DEBUG] LLMç”Ÿæˆå›å¤: {final_response[:100]}...")
        
        # æ›´æ–°ä¼šè¯è®°å¿†
        conversation_memory = state.get("conversation_memory", [])
        updated_memory = list(conversation_memory)
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        updated_memory.append(HumanMessage(content=user_input))
        
        # æ·»åŠ åŠ©æ‰‹å›å¤ï¼ˆå¦‚æœæœ‰æ–‡æ¡ˆï¼ŒåŒ…å«åœ¨è®°å¿†ä¸­ï¼‰
        ai_message_content = final_response
        if marketing_copies:
            ai_message_content += f"\n\n[ç”Ÿæˆçš„è¥é”€æ–‡æ¡ˆ]\n{json.dumps(marketing_copies, ensure_ascii=False, indent=2)}"
        updated_memory.append(AIMessage(content=ai_message_content))
        
        # ä¿æŒæœ€è¿‘çš„å¯¹è¯ï¼ˆæœ€å¤š6è½®ï¼Œå³12æ¡æ¶ˆæ¯ï¼‰
        if len(updated_memory) > 12:
            updated_memory = updated_memory[-12:]
        
        # print(f"âœ… FinalèŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œæ–‡æ¡ˆæ•°é‡: {len(marketing_copies) if marketing_copies else 0}")
        
        return {
            "response": final_response,
            "marketing_copies": marketing_copies,  # ç›´æ¥ä»å·¥å…·ç»“æœèµ‹å€¼
            "conversation_memory": updated_memory,
            "current_step": ChatMarketingStep.COMPLETE
        }
        
    except Exception as e:
        import traceback
        # print(f"âŒ FinalèŠ‚ç‚¹å¤„ç†å¤±è´¥: {str(e)}")
        # print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise

def print_conversation_memory(state: ChatMarketingState) -> Dict[str, Any]:
    """
    æ‰“å°ä¼šè¯è®°å¿†å†…å®¹å’Œå½“å‰è½®æ¬¡çš„å…¨å±€å­—å…¸ä¿¡æ¯
    """
    # print("\nğŸ”ğŸ”ğŸ” PRINT_MEMORYèŠ‚ç‚¹è¢«è°ƒç”¨äº†ï¼ğŸ”ğŸ”ğŸ”")
    conversation_memory = state.get("conversation_memory", [])
    current_round_id = state.get("round_id", 1)
    
    # print("\n=== conversation_memory ===")
    # print(conversation_memory)
    # print("=== conversation_memory ç»“æŸ ===\n")
    
    # æ‰“å°å½“å‰è½®æ¬¡çš„å…¨å±€å­—å…¸ä¿¡æ¯
    round_data = get_round_data()
    
    print(f"\n=== å½“å‰è½®æ¬¡({current_round_id})çš„å…¨å±€å­—å…¸æ•°æ® ===")
    print(round_data)
    print("=== å…¨å±€å­—å…¸æ•°æ® ç»“æŸ ===\n")
    
    # æ‰“å°æœ¬æ¬¡å¯¹è¯çš„ç±»å‹åˆ†ç±»
    conversation_type = round_data.get('conversation_type', 'æœªåˆ†ç±»') if round_data else 'æœªåˆ†ç±»'
    # print(f"\nğŸ“‹ æœ¬æ¬¡å¯¹è¯ç±»å‹: {conversation_type}\n")
    
    # ç›´æ¥è·å– marketing_copies æ•°æ®
    print("\nğŸ§ªğŸ§ªğŸ§ª æµ‹è¯•æ‰“å° marketing_copies æ•°æ® ğŸ§ªğŸ§ªğŸ§ª")
    try:
        if round_data and round_data.get('execution_results'):
            import json
            marketing_copies = []
            # éå†æŸ¥æ‰¾marketing_copy_generatorå·¥å…·ç»“æœ
            for execution_result in round_data['execution_results']:
                response_messages = execution_result.get('response_messages', [])
                for msg in response_messages:
                    if hasattr(msg, 'name') and msg.name == 'marketing_copy_generator':
                        try:
                            content_data = json.loads(msg.content)
                            marketing_copies = content_data.get('marketing_copies', [])
                            print(f"\n=== Marketing Copies æ•°æ® ===")
                            print(marketing_copies)
                            break
                        except json.JSONDecodeError as e:
                            print(f"JSONè§£æå¤±è´¥: {e}")
                if marketing_copies:  # æ‰¾åˆ°åè·³å‡ºå¤–å±‚å¾ªç¯
                    break
            if not marketing_copies:
                print("æœªæ‰¾åˆ°marketing_copiesæ•°æ®")
    except Exception as e:
        print(f"è·å– marketing_copies å¤±è´¥: {e}")
    print("ğŸ§ªğŸ§ªğŸ§ª æµ‹è¯•ç»“æŸ ğŸ§ªğŸ§ªğŸ§ª\n")
    
    return {}

class ChatMarketingWorkflow:
    """èŠå¤©è¥é”€å·¥ä½œæµ - Plan-and-Executeæ¨¡å¼"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŠå¤©è¥é”€å·¥ä½œæµ"""
        self.nodes = ChatMarketingNodes()
        self.workflow = self._build_workflow()
    
    def _build_workflow(self):
        """æ„å»ºPlan-and-Executeå·¥ä½œæµå›¾"""
        try:
            from langgraph.graph import StateGraph, START, END
            from langgraph.checkpoint.memory import MemorySaver
            
            # åˆ›å»ºçŠ¶æ€å›¾
            builder = StateGraph(ChatMarketingState, input=ChatMarketingInput, output=ChatMarketingOutput)
            
            # æ·»åŠ èŠ‚ç‚¹
            builder.add_node("input", self.nodes.input_step)
            builder.add_node("plan", self.nodes.plan_step)
            builder.add_node("execute", self.nodes.execute_step)
            builder.add_node("replan", self.nodes.replan_step)
            builder.add_node("final_output", create_final_output)
            builder.add_node("print_memory", print_conversation_memory)
            
            # æ·»åŠ è¾¹å’Œæ¡ä»¶åˆ¤æ–­
            # å·¥ä½œæµé¡ºåºï¼šSTART -> input -> plan -> execute -> replan -> final_output -> END
            builder.add_edge(START, "input")
            builder.add_edge("input", "plan")
            
            # ä»è®¡åˆ’èŠ‚ç‚¹çš„æ¡ä»¶åˆ¤æ–­
            builder.add_conditional_edges(
                "plan",
                lambda state: "final_output" if state.get("current_step") == ChatMarketingStep.COMPLETE else "execute",
                {
                    "execute": "execute",  # æœ‰å·¥å…·éœ€è¦æ‰§è¡Œæ—¶è¿›å…¥æ‰§è¡ŒèŠ‚ç‚¹
                    "final_output": "final_output"  # ç›´æ¥å›å¤æ—¶è·³è¿‡æ‰§è¡Œç›´æ¥åˆ°æœ€ç»ˆè¾“å‡º
                }
            )
            
            # ä»æ‰§è¡ŒèŠ‚ç‚¹çš„æ¡ä»¶åˆ¤æ–­
            builder.add_conditional_edges(
                "execute",
                self._should_continue,
                {
                    "continue": "replan",  # ç»§ç»­æ‰§è¡Œéœ€è¦é‡æ–°è§„åˆ’
                    "end": "final_output"  # ç»“æŸæ—¶å¤„ç†æœ€ç»ˆè¾“å‡º
                }
            )
            
            # ä»é‡æ–°è§„åˆ’èŠ‚ç‚¹å›åˆ°æ‰§è¡ŒèŠ‚ç‚¹
            builder.add_edge("replan", "execute")
            
            # ä»æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹åˆ°æ‰“å°è®°å¿†èŠ‚ç‚¹
            builder.add_edge("final_output", "print_memory")
            
            # ä»æ‰“å°è®°å¿†èŠ‚ç‚¹åˆ°ç»“æŸ
            builder.add_edge("print_memory", END)
            
            # ç¼–è¯‘å·¥ä½œæµï¼ˆLangGraph APIä¼šè‡ªåŠ¨å¤„ç†æŒä¹…åŒ–ï¼‰
            return builder.compile()
            
        except Exception as e:
            print(f"æ„å»ºå·¥ä½œæµå¤±è´¥: {e}")
            # ä¸è¿”å›Noneï¼Œè€Œæ˜¯æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†
            raise e
    
    def _should_continue(self, state: ChatMarketingState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œ"""
        import json
        
        # å¦‚æœæœ‰responseå­—æ®µï¼Œè¯´æ˜ä»»åŠ¡å®Œæˆ
        if "response" in state and state["response"]:
            return "end"
        
        # æ£€æŸ¥é‡è¯•æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        retry_count = state.get("retry_count", 0)
        max_retries = 3
        if retry_count >= max_retries:
            return "end"
        
        # è·å–æ‰§è¡Œç»“æœå’Œè®¡åˆ’ä¿¡æ¯
        plan = state.get("plan", [])
        round_data = get_round_data()
        
        if not round_data:
            return "end"
            
        planned_tools = round_data.get('planned_tools', [])
        conversation_type = round_data.get('conversation_type', 'chat')
        execution_results = round_data.get('execution_results', [])
        
        # å¯¹äºç”Ÿæˆç±»å‹ï¼Œæ£€æŸ¥è¥é”€æ–‡æ¡ˆæ˜¯å¦æˆåŠŸç”Ÿæˆ
        if conversation_type == 'generation' and 'marketing_copy_generator' in planned_tools:
            marketing_copy_success = False
            for execution_result in execution_results:
                response_messages = execution_result.get('response_messages', [])
                for msg in response_messages:
                    if hasattr(msg, 'name') and msg.name == 'marketing_copy_generator':
                        try:
                            content_data = json.loads(msg.content)
                            if content_data.get('marketing_copies'):
                                marketing_copy_success = True
                                break
                        except:
                            pass
                if marketing_copy_success:
                    break
            
            # å¦‚æœæ–‡æ¡ˆç”ŸæˆæˆåŠŸï¼Œå¯ä»¥ç»“æŸï¼›å¦åˆ™éœ€è¦é‡è¯•
            if marketing_copy_success:
                return "end"
            elif plan and len(plan) > 0:
                return "continue"  # è¿˜æœ‰è®¡åˆ’ä¸”æ–‡æ¡ˆæœªæˆåŠŸï¼Œç»§ç»­é‡è¯•
            else:
                return "end"  # æ²¡æœ‰è®¡åˆ’äº†ï¼Œå¼ºåˆ¶ç»“æŸ
        
        # å¯¹äºèŠå¤©å’Œè®¨è®ºç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰è®¡åˆ’è¦æ‰§è¡Œ
        elif conversation_type in ['chat', 'discussion']:
            if plan and len(plan) > 0:
                return "continue"
            else:
                return "end"
        
        # é»˜è®¤æƒ…å†µï¼šæ£€æŸ¥æ˜¯å¦è¿˜æœ‰è®¡åˆ’è¦æ‰§è¡Œ
        if plan and len(plan) > 0:
            return "continue"
        
        return "end"

# ==================== å·¥ä½œæµæ„å»º ====================

def create_chat_marketing_workflow():
    """åˆ›å»ºèŠå¤©è¥é”€å·¥ä½œæµ - Plan-and-Executeæ¨¡å¼"""
    try:
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow_instance = ChatMarketingWorkflow()
        if workflow_instance.workflow is None:
            raise ValueError("Failed to build workflow graph")
        return workflow_instance.workflow
        
    except Exception as e:
        print(f"åˆ›å»ºèŠå¤©è¥é”€å·¥ä½œæµå¤±è´¥: {e}")
        # åˆ›å»ºä¸€ä¸ªæœ€å°çš„fallbackå›¾ä»¥é¿å…None
        from langgraph.graph import StateGraph, START, END
        fallback_builder = StateGraph(ChatMarketingState, input=ChatMarketingInput, output=ChatMarketingOutput)
        
        # æ·»åŠ ä¸€ä¸ªç®€å•çš„fallbackèŠ‚ç‚¹
        def fallback_node(state: ChatMarketingState) -> Dict[str, Any]:
            return {
                "response": "ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "messages": [AIMessage(content="ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")]
            }
        
        fallback_builder.add_node("fallback", fallback_node)
        fallback_builder.add_edge(START, "fallback")
        fallback_builder.add_edge("fallback", END)
        
        return fallback_builder.compile()



# ==================== å¯¼å‡º ====================

# ç¼–è¯‘å·¥ä½œæµ
chat_marketing_graph = create_chat_marketing_workflow()

# å¯¼å‡ºä¸»è¦ç»„ä»¶
__all__ = [
    "ChatMarketingState",
    "ChatMarketingInput",
    "ChatMarketingOutput",
    "ChatMarketingStep",
    "IntentType",
    "TimeInfo",
    "ChatMarketingNodes",
    "chat_marketing_graph"
]