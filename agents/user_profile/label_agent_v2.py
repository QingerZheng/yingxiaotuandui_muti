"""ç”¨æˆ·ç”»åƒç”Ÿæˆæ¨¡å— - åˆ†æ­¥å¼ä¼˜åŒ–ç‰ˆæœ¬

é‡‡ç”¨åˆ†æ­¥å¼Promptè®¾è®¡ï¼š
1. ç¬¬ä¸€æ­¥ï¼šåˆ†æå¯¹è¯ï¼Œæå–åŸºç¡€ç”¨æˆ·ä¿¡æ¯
2. ç¬¬äºŒæ­¥ï¼šåŸºäºåŸºç¡€ä¿¡æ¯ï¼Œç”Ÿæˆæ ‡å‡†åŒ–æ ‡ç­¾
3. è‡ªåŠ¨éªŒè¯å’Œä¿®æ­£ä¸åˆè§„æ ‡ç­¾
"""

import asyncio
import json
import logging
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage
from llm import create_llm # å¯¼å…¥æ–°çš„ LLM å·¥å‚å‡½æ•°
# é»˜è®¤æ¨¡å‹ä½¿ç”¨ OpenRouter å¯ç”¨çš„å¿«é€Ÿæ¨¡å‹
from agents.shared.profile_variables import profile_variables
from dataclasses import dataclass, field
from typing_extensions import TypedDict, Annotated
from langgraph.graph import StateGraph, START
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import trim_messages, RemoveMessage

logger = logging.getLogger(__name__)


class UserProfile(BaseModel):
    """ç”¨æˆ·ç”»åƒç»“æ„ - æŒ‰ä¸šåŠ¡é€»è¾‘åˆ†ç»„æ’åº"""
    
    # === ç¤¾ä¼šç”»åƒ ===
    occupation: Optional[str] = Field(default=None, description="èŒä¸š")
    age: Optional[str] = Field(default=None, description="å¹´é¾„æ®µ") 
    region: Optional[str] = Field(default=None, description="åœ°åŒº")
    lifestyle: Optional[str] = Field(default=None, description="ç”Ÿæ´»æ–¹å¼")
    family_status: Optional[str] = Field(default=None, description="å®¶åº­çŠ¶å†µ")
    emotion: Optional[str] = Field(default=None, description="æƒ…ç»ªçŠ¶æ€")
    
    # === æ€§æ ¼ç‰¹å¾ ===
    character: Optional[str] = Field(default=None, description="æ€§æ ¼ç±»å‹")
    values: Optional[str] = Field(default=None, description="ä»·å€¼è§‚")
    aesthetic_style: Optional[str] = Field(default=None, description="å®¡ç¾é£æ ¼")
    
    # === æ¶ˆè´¹ç”»åƒ ===
    ability: Optional[str] = Field(default=None, description="æ¶ˆè´¹èƒ½åŠ›")
    willingness: Optional[str] = Field(default=None, description="æ¶ˆè´¹æ„æ„¿")
    preferences: Optional[str] = Field(default=None, description="å“ç‰Œåå¥½")
    
    # === äº§å“æ„å›¾ ===
    current_use: Optional[str] = Field(default=None, description="å½“å‰ä½¿ç”¨äº§å“")
    potential_needs: Optional[str] = Field(default=None, description="æ½œåœ¨éœ€æ±‚")
    decision_factors: Optional[str] = Field(default=None, description="å†³ç­–å› ç´ ")
    purchase_intent_score: Optional[str] = Field(default=None, description="è´­ä¹°æ„å‘è¯„åˆ†")
    
    # === å®¢æˆ·ç”Ÿå‘½å‘¨æœŸ ===
    stage: Optional[str] = Field(default=None, description="å®¢æˆ·é˜¶æ®µ")
    value: Optional[str] = Field(default=None, description="å®¢æˆ·ä»·å€¼")
    retention_strategy: Optional[str] = Field(default=None, description="ç•™å­˜ç­–ç•¥")

    def get_filled_count(self) -> int:
        """è·å–å·²å¡«å……å­—æ®µæ•°é‡"""
        return sum(1 for v in self.model_dump().values() if v is not None)
    
    def get_total_count(self) -> int:
        """è·å–æ€»å­—æ®µæ•°é‡"""
        return len(self.model_fields)
    
    def get_grouped_data(self) -> Dict[str, Dict[str, Optional[str]]]:
        """è·å–æŒ‰åˆ†ç»„ç»„ç»‡çš„æ•°æ®"""
        data = self.model_dump()
        return {
            "ç¤¾ä¼šç”»åƒ": {
                "occupation": data["occupation"],
                "age": data["age"], 
                "region": data["region"],
                "lifestyle": data["lifestyle"],
                "family_status": data["family_status"],
                "emotion": data["emotion"]
            },
            "æ€§æ ¼ç‰¹å¾": {
                "character": data["character"],
                "values": data["values"],
                "aesthetic_style": data["aesthetic_style"]
            },
            "æ¶ˆè´¹ç”»åƒ": {
                "ability": data["ability"],
                "willingness": data["willingness"],
                "preferences": data["preferences"]
            },
            "äº§å“æ„å›¾": {
                "current_use": data["current_use"],
                "potential_needs": data["potential_needs"],
                "decision_factors": data["decision_factors"],
                "purchase_intent_score": data["purchase_intent_score"]
            },
            "å®¢æˆ·ç”Ÿå‘½å‘¨æœŸ": {
                "stage": data["stage"],
                "value": data["value"],
                "retention_strategy": data["retention_strategy"]
            }
        }

# å®šä¹‰åˆ†æç»“æœæ•°æ®æ¨¡å‹ - å¿…é¡»åœ¨ProfileGeneratorç±»ä¹‹å‰å®šä¹‰
class AnalysisResult(BaseModel):
    """ç¬¬ä¸€æ­¥åˆ†æç»“æœç»“æ„"""
    basic_info: str = Field(description="ç”¨æˆ·åŸºæœ¬ä¿¡æ¯æ‘˜è¦")
    personality: str = Field(description="æ€§æ ¼ç‰¹å¾æ‘˜è¦")
    consumption: str = Field(description="æ¶ˆè´¹è¡Œä¸ºæ‘˜è¦")
    beauty_needs: str = Field(description="ç¾å®¹éœ€æ±‚æ‘˜è¦")
    customer_status: str = Field(description="å®¢æˆ·çŠ¶æ€æ‘˜è¦")
    dialogue_quality: str = Field(description="å¯¹è¯ä¿¡æ¯å……è¶³åº¦(1-10åˆ†)")
    summarize: str = Field(description="ç»¼åˆæ‰€æœ‰åˆ†æå†…å®¹çš„ä¸€å¥è¯æ€»ç»“")


class ProfileGenerator:
    """åˆ†æ­¥å¼ç”¨æˆ·ç”»åƒç”Ÿæˆå™¨"""
    
    def __init__(self, model_provider: str, model_name: str, temperature: float):
        # åˆ›å»ºæ”¯æŒJSONæ ¼å¼è¾“å‡ºçš„æ¨¡å‹
        # ç»Ÿä¸€é€šè¿‡å·¥å‚åˆ›å»ºï¼Œåº•å±‚å·²å°† openai è·¯ç”±åˆ° openrouter
        self.model = create_llm(
            model_provider=model_provider,
            model_name=model_name,
            temperature=temperature,
        )
    
    def _build_analysis_prompt(self) -> str:
        """ç¬¬ä¸€æ­¥ï¼šæ„å»ºå¯¹è¯åˆ†ææç¤º"""
        return """ä½ æ˜¯ä¸“ä¸šçš„ç”¨æˆ·ç”»åƒåˆ†æä¸“å®¶ã€‚è¯·åŸºäºä¸Šè¿°èŠå¤©è®°å½•è¿›è¡Œç”¨æˆ·ç”»åƒåˆ†æã€‚

**é‡è¦ï¼šä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬æˆ–æ ¼å¼æ ‡è®°ã€‚**

**åˆ†ææŒ‡å¯¼ï¼šé€šè¿‡ç”¨æˆ·çš„è¡¨è¾¾æ–¹å¼ã€è¯­è¨€ä¹ æƒ¯ã€å…³æ³¨ç‚¹ç­‰ä¿¡æ¯ï¼Œè¿›è¡Œä¸“ä¸šçš„ç”¨æˆ·ç”»åƒåˆ†æã€‚**

åˆ†æè¦ç‚¹ï¼š
- åŸºæœ¬ä¿¡æ¯ï¼šä»å¯¹è¯å†…å®¹åˆ†æç”¨æˆ·çš„åŸºæœ¬ç‰¹å¾
- æ€§æ ¼ç‰¹å¾ï¼šåˆ†æç”¨æˆ·çš„è¡¨è¾¾æ–¹å¼å’Œæ²Ÿé€šé£æ ¼
- æ¶ˆè´¹è¡Œä¸ºï¼šäº†è§£ç”¨æˆ·çš„æ¶ˆè´¹åå¥½å’Œèƒ½åŠ›
- ç¾å®¹éœ€æ±‚ï¼šåˆ†æç”¨æˆ·å¯¹ç¾å®¹æœåŠ¡çš„éœ€æ±‚
- å®¢æˆ·çŠ¶æ€ï¼šè¯„ä¼°ç”¨æˆ·çš„æœåŠ¡æ»¡æ„åº¦å’Œè´­ä¹°æ„å‘
- å¯¹è¯è´¨é‡ï¼šè¯„ä¼°æœ¬æ¬¡å¯¹è¯ä¿¡æ¯çš„ä¸°å¯Œç¨‹åº¦

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{
    "basic_info": "ç”¨æˆ·åŸºæœ¬ä¿¡æ¯æ‘˜è¦ï¼ˆä»å¯¹è¯æ—¶é—´ã€è¡¨è¾¾æ–¹å¼ã€å…³æ³¨ç‚¹ç­‰æ¨æ–­å¹´é¾„æ®µã€èŒä¸šç±»å‹ã€åœ°åŒºç­‰ï¼‰",
    "personality": "æ€§æ ¼ç‰¹å¾æ‘˜è¦ï¼ˆä»å¯¹è¯æ–¹å¼ã€æƒ…ç»ªè¡¨è¾¾ã€è¯­è¨€é£æ ¼ç­‰åˆ†ææ€§æ ¼ç±»å‹ã€ä»·å€¼è§‚ç­‰ï¼‰", 
    "consumption": "æ¶ˆè´¹è¡Œä¸ºæ‘˜è¦ï¼ˆä»å·¥ä½œçŠ¶æ€ã€å¯¹è¯æ—¶é—´ã€è¡¨è¾¾æ–¹å¼ç­‰æ¨æ–­æ¶ˆè´¹èƒ½åŠ›ã€æ¶ˆè´¹åå¥½ç­‰ï¼‰",
    "beauty_needs": "ç¾å®¹éœ€æ±‚æ‘˜è¦ï¼ˆä»å¯¹è¯ä¸­çš„ç¾å®¹è¯é¢˜ã€å…³æ³¨ç‚¹ã€è¯¢é—®æ–¹å¼ç­‰åˆ†æéœ€æ±‚ï¼‰",
    "customer_status": "å®¢æˆ·çŠ¶æ€æ‘˜è¦ï¼ˆä»å¯¹è¯æ€åº¦ã€æœåŠ¡æ»¡æ„åº¦ã€äº’åŠ¨æ–¹å¼ç­‰åˆ¤æ–­å®¢æˆ·é˜¶æ®µã€è´­ä¹°æ„å‘ã€æµå¤±é£é™©ç­‰ï¼‰",
    "dialogue_quality": "å¯¹è¯ä¿¡æ¯å……è¶³åº¦(å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¦‚\"5\")ï¼Œ1=ä¿¡æ¯å¾ˆå°‘ï¼Œ10=ä¿¡æ¯ä¸°å¯Œ",
    "summarize": "ç»¼åˆä»¥ä¸Šåˆ†æï¼Œå½¢æˆç”¨æˆ·çš„æ•´ä½“ç”»åƒæè¿°"
}

è¾“å‡ºè¦æ±‚ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. åŸºäºå¯¹è¯å†…å®¹è¿›è¡Œä¸“ä¸šåˆ†æ
2. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¾“å‡º
3. åªè¾“å‡ºJSONå†…å®¹ï¼Œä¸è¦æ·»åŠ å…¶ä»–æ–‡å­—"""

    def _normalize_messages(self, messages: List[Any]) -> List[BaseMessage]:
        """å°†è¾“å…¥çš„æ¶ˆæ¯åˆ—è¡¨ç»Ÿä¸€è½¬æ¢ä¸º LangChain çš„ BaseMessage åˆ—è¡¨ï¼Œé¿å… MESSAGE_COERCION_FAILUREã€‚

        æ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
        - å­—å…¸ï¼š{"role": "user|human|assistant|ai|system", "content": ...}
        - BaseMessage å®ä¾‹
        - content ä¸ºå¤šæ¨¡æ€ listï¼Œæå–å…¶ä¸­çš„ text å­—æ®µ
        - å¤§å°å†™ä¸è§„èŒƒçš„è§’è‰²åï¼ˆå¦‚ "Human"ï¼‰
        æœªè¯†åˆ«è§’è‰²é™çº§ä¸º humanã€‚
        """
        normalized: List[BaseMessage] = []
        if not messages:
            return normalized

        def _extract_text(content: Any) -> str:
            if isinstance(content, list):
                parts: List[str] = []
                for part in content:
                    if isinstance(part, dict) and part.get("type") == "text":
                        parts.append(str(part.get("text", "")))
                return "".join(parts)
            return str(content) if content is not None else ""

        for msg in messages:
            if isinstance(msg, BaseMessage):
                normalized.append(msg)
                continue
            if isinstance(msg, dict):
                role = str(msg.get("role", "")).strip().lower()
                content = _extract_text(msg.get("content", ""))
                if role in ("user", "human"):
                    normalized.append(HumanMessage(content=content))
                elif role in ("assistant", "ai"):
                    normalized.append(AIMessage(content=content))
                elif role == "system":
                    normalized.append(SystemMessage(content=content))
                else:
                    normalized.append(HumanMessage(content=content))
                continue
            normalized.append(HumanMessage(content=str(msg)))
        return normalized

    def _build_labeling_prompt(self, analysis: Dict[str, str]) -> str:
        """ç¬¬äºŒæ­¥ï¼šæ„å»ºæ ‡ç­¾ç”Ÿæˆæç¤º"""
        options_str = self._format_options()
        
        dialogue_quality = analysis.get("dialogue_quality", "5")
        
        return f"""åŸºäºåˆ†æç»“æœï¼Œç”Ÿæˆæ ‡å‡†åŒ–ç”¨æˆ·ç”»åƒæ ‡ç­¾ã€‚æ ¹æ®å¯¹è¯è´¨é‡({dialogue_quality}åˆ†)è°ƒæ•´æ¨ç†ç§¯æåº¦ã€‚

**é‡è¦ï¼šä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›æ ‡ç­¾ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬æˆ–æ ¼å¼æ ‡è®°ã€‚**

åˆ†æç»“æœï¼š
{json.dumps(analysis, ensure_ascii=False, indent=2)}

å¯é€‰æ ‡ç­¾ï¼š
{options_str}

æ ‡ç­¾ç”Ÿæˆç­–ç•¥ï¼š
1. å¯¹è¯è´¨é‡â‰¥7åˆ†ï¼šç§¯ææ¨ç†ï¼ŒåŸºäºçº¿ç´¢åˆç†æ¨æ–­æ ‡ç­¾
2. å¯¹è¯è´¨é‡4-6åˆ†ï¼šé€‚åº¦æ¨ç†ï¼Œæ˜ç¡®çº¿ç´¢æ‰å¡«å†™æ ‡ç­¾  
3. å¯¹è¯è´¨é‡â‰¤3åˆ†ï¼šä¿å®ˆç­–ç•¥ï¼Œåªå¡«å†™éå¸¸ç¡®å®šçš„æ ‡ç­¾

æ¨ç†æŒ‡å¯¼ï¼š
- å·¥ä½œç¹å¿™+åŠ ç­ â†’ lifestyleå¯èƒ½æ˜¯"ç†¬å¤œ"
- æƒ…ç»ªä»æ­£å¸¸å˜æ¶ˆæ â†’ emotionå¡«å†™æœ€ç»ˆçŠ¶æ€
- è¦æ±‚è½¬äººå·¥+æ”»å‡»æ€§è¯­è¨€ â†’ stageå¯èƒ½æ˜¯"æµå¤±å®¢æˆ·æœŸ"
- æ¶ˆææƒ…ç»ªç”¨æˆ· â†’ retention_strategyå»ºè®®"å®¢æˆ·å…³æ€€"
- å‘¨æœ«åŠ ç­ â†’ å¯èƒ½æ˜¯é«˜å‹èŒä¸šç±»å‹

è§„åˆ™ï¼š
1. åªèƒ½é€‰æ‹©ä¸Šè¿°é¢„å®šä¹‰é€‰é¡¹ï¼Œä¸èƒ½è‡ªåˆ›
2. å¤šä¸ªé€‰é¡¹ç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼šå¦‚"ç¨‹åºå‘˜,è®¾è®¡å¸ˆ"
3. æ— åˆé€‚é€‰é¡¹æ—¶å¡«null
4. ä¸èƒ½ç”¨"å’Œ"ã€"ä¸"ç­‰è¿æ¥è¯

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›æ ‡ç­¾ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬ï¼š
{{
    "occupation": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "age": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "region": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "lifestyle": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "family_status": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "emotion": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "character": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "values": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "aesthetic_style": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "ability": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "willingness": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "preferences": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "current_use": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "potential_needs": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "decision_factors": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "purchase_intent_score": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "stage": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "value": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null",
    "retention_strategy": "ä»é¢„å®šä¹‰é€‰é¡¹é€‰æ‹©æˆ–null"
}}

è¾“å‡ºè¦æ±‚ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. åªè¾“å‡ºJSONå†…å®¹ï¼Œä¸è¦æ·»åŠ å…¶ä»–æ–‡å­—
3. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¾“å‡º"""

    def _format_options(self) -> str:
        """æ ¼å¼åŒ–é¢„å®šä¹‰é€‰é¡¹"""
        sections = []
        
        # ç¤¾ä¼šç”»åƒ
        social = profile_variables["social_profile"]
        sections.append(f"occupation: {social['occupation']}")
        sections.append(f"age: {social['age']}")
        sections.append(f"region: {social['region']}")
        sections.append(f"lifestyle: {social['lifestyle']}")
        sections.append(f"family_status: {social['family_status']}")
        sections.append(f"emotion: {social['emotion']}")
        
        # æ€§æ ¼ç‰¹å¾
        personality = profile_variables["personality_traits"]
        sections.append(f"character: {personality['character']}")
        sections.append(f"values: {personality['values']}")
        sections.append(f"aesthetic_style: {personality['aesthetic_style']}")
        
        # æ¶ˆè´¹ç”»åƒ
        consumption = profile_variables["consumption_profile"]
        sections.append(f"ability: {consumption['ability']}")
        sections.append(f"willingness: {consumption['willingness']}")
        sections.append(f"preferences: {consumption['preferences']}")
        
        # äº§å“æ„å›¾
        product = profile_variables["product_intent"]
        sections.append(f"current_use: {product['current_use']}")
        sections.append(f"potential_needs: {product['potential_needs']}")
        sections.append(f"decision_factors: {product['decision_factors']}")
        sections.append(f"purchase_intent_score: {product['purchase_intent_score']}")
        
        # å®¢æˆ·ç”Ÿå‘½å‘¨æœŸ
        lifecycle = profile_variables["customer_lifecycle"]
        sections.append(f"stage: {lifecycle['stage']}")
        sections.append(f"value: {lifecycle['value']}")
        sections.append(f"retention_strategy: {lifecycle['retention_strategy']}")
        
        return "\n".join(sections)

    async def analyze_conversation(self, config: Optional[Dict] = None, state: Optional[Dict] = None) -> AnalysisResult:
        """ğŸ” ã€æ ¸å¿ƒæ–¹æ³•1ã€‘æ‰§è¡Œç¬¬ä¸€æ­¥å¯¹è¯åˆ†æ - è‡ªåŠ¨è·å–å½“å‰ä¼šè¯å†å²è®°å½•
        
        å‚æ•°:
            config: Optional[Dict] - é…ç½®ä¿¡æ¯
            state: Optional[Dict] - LangGraphçŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²
        è¿”å›:
            AnalysisResult - åˆ†æç»“æœï¼ˆåŒ…å«ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ã€æ€§æ ¼ç‰¹å¾ç­‰ï¼‰
        """
        try:
            # ğŸ” ç›´æ¥ä»stateä¸­è·å–å®Œæ•´å†å²æ¶ˆæ¯ï¼ˆLangGraphçŠ¶æ€æœºåˆ¶ï¼‰
            messages = []
            if state:
                # ç›´æ¥ä½¿ç”¨long_term_messagesè·å–å®Œæ•´å†å²å¯¹è¯
                messages = state.get("long_term_messages", [])
                if messages:
                    logger.info(f"ä»long_term_messagesè·å–åˆ°{len(messages)}æ¡å†å²æ¶ˆæ¯")
            
            if not messages:
                raise ValueError("å½“å‰ä¼šè¯æ²¡æœ‰å†å²èŠå¤©è®°å½•")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = self._build_analysis_prompt()
            # ğŸ¯ å…³é”®æ­¥éª¤ï¼šå°†å¯¹è¯è®°å½•ä¸åˆ†ææç¤ºç»„åˆï¼ˆå…ˆè§„èŒƒåŒ–å†å²æ¶ˆæ¯ï¼‰
            normalized_history = self._normalize_messages(messages)
            analysis_messages = normalized_history + [HumanMessage(content=analysis_prompt)]
            
            logger.info(f"æ‰§è¡Œç¬¬ä¸€æ­¥å¯¹è¯åˆ†æï¼Œä½¿ç”¨{len(messages)}æ¡å¯¹è¯æ¶ˆæ¯")
            # ğŸ¤– è°ƒç”¨AIæ¨¡å‹åˆ†æå†å²èŠå¤©è®°å½•
            analysis_response = await asyncio.to_thread(self.model.invoke, analysis_messages)
            
            # è°ƒè¯•ï¼šæ‰“å°åŸå§‹å“åº”
            logger.info(f"[DEBUG] AIæ¨¡å‹åŸå§‹å“åº”: {analysis_response.content}")
            
            # è§£æJSONå“åº”ï¼ˆä½¿ç”¨response_formatååº”è¯¥ç›´æ¥æ˜¯JSONæ ¼å¼ï¼‰
            import json
            
            try:
                analysis_data = json.loads(analysis_response.content.strip())
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                logger.error(f"åŸå§‹å“åº”å†…å®¹: {repr(analysis_response.content)}")
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æ¸…ç†markdownæ ‡è®°
                import re
                content = analysis_response.content.strip()
                content = re.sub(r'^```json\s*', '', content)
                content = re.sub(r'\s*```$', '', content)
                content = content.strip()
                try:
                    analysis_data = json.loads(content)
                    logger.warning("é€šè¿‡æ¸…ç†markdownæ ‡è®°æˆåŠŸè§£æJSON")
                except json.JSONDecodeError:
                    raise ValueError(f"AIæ¨¡å‹è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼: {analysis_response.content[:200]}...")
            
            return AnalysisResult(**analysis_data)
            
        except Exception as e:
            logger.error(f"å¯¹è¯åˆ†æå¤±è´¥: {e}")
            raise
    
    async def generate(self, messages: List[BaseMessage]) -> UserProfile:
        """ğŸ·ï¸ ã€æ ¸å¿ƒæ–¹æ³•2ã€‘ç”Ÿæˆç”¨æˆ·ç”»åƒï¼ˆå®Œæ•´æµç¨‹ï¼‰- å¤„ç†å†å²èŠå¤©è®°å½•
        
        å‚æ•°:
            messages: List[BaseMessage] - å†å²èŠå¤©è®°å½•åˆ—è¡¨
        è¿”å›:
            UserProfile - å®Œæ•´çš„ç”¨æˆ·ç”»åƒæ ‡ç­¾
        """
        if not messages:
            raise ValueError("èŠå¤©è®°å½•ä¸ºç©º")
        
        try:
            # ğŸ” ç¬¬ä¸€æ­¥ï¼šåˆ†æå†å²å¯¹è¯è®°å½•ï¼ˆå†…éƒ¨ä¼šè‡ªåŠ¨è¿‡æ»¤æ¶ˆæ¯ï¼‰
            config_dict = {"configurable": {"messages": messages}}
            analysis_result = await self.analyze_conversation(config_dict)
            
            # ğŸ·ï¸ ç¬¬äºŒæ­¥ï¼šåŸºäºåˆ†æç»“æœç”Ÿæˆæ ‡å‡†åŒ–æ ‡ç­¾
            profile = await self.generate_labels_from_analysis(analysis_result)
            
            return profile
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç”¨æˆ·ç”»åƒå¤±è´¥: {e}")
            raise
    
    async def generate_labels_from_analysis(self, analysis_result: AnalysisResult) -> UserProfile:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆç”¨æˆ·ç”»åƒæ ‡ç­¾"""
        try:
            analysis_data = analysis_result.model_dump()
            
            # è¾“å‡ºåˆ†æç»“æœï¼ˆè°ƒè¯•ç”¨ï¼‰
            print("ğŸ” åŸºäºåˆ†æç»“æœç”Ÿæˆæ ‡ç­¾:")
            for key, value in analysis_data.items():
                print(f"  {key}: {value}")
            print()
            
            # ç”Ÿæˆæ ‡ç­¾
            labeling_prompt = self._build_labeling_prompt(analysis_data)
            labeling_messages = [SystemMessage(content="ä½ æ˜¯æ ‡ç­¾ç”Ÿæˆä¸“å®¶"), HumanMessage(content=labeling_prompt)]
            
            logger.info("ç”Ÿæˆæ ‡å‡†åŒ–æ ‡ç­¾")
            labeling_response = await asyncio.to_thread(self.model.invoke, labeling_messages)
            
            # è°ƒè¯•ï¼šæ‰“å°åŸå§‹å“åº”
            logger.info(f"[DEBUG] æ ‡ç­¾ç”ŸæˆåŸå§‹å“åº”: {labeling_response.content}")
            
            # è§£æJSONå“åº”ï¼ˆä½¿ç”¨response_formatååº”è¯¥ç›´æ¥æ˜¯JSONæ ¼å¼ï¼‰
            import json
            try:
                profile_data = json.loads(labeling_response.content.strip())
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                logger.error(f"åŸå§‹å“åº”å†…å®¹: {repr(labeling_response.content)}")
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æ¸…ç†markdownæ ‡è®°
                import re
                content = labeling_response.content.strip()
                content = re.sub(r'^```json\s*', '', content)
                content = re.sub(r'\s*```$', '', content)
                content = content.strip()
                try:
                    profile_data = json.loads(content)
                    logger.warning("é€šè¿‡æ¸…ç†markdownæ ‡è®°æˆåŠŸè§£æJSON")
                except json.JSONDecodeError:
                    raise ValueError(f"AIæ¨¡å‹è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼: {labeling_response.content[:200]}...")
            
            return UserProfile(**profile_data)
            
        except Exception as e:
            logger.error(f"åŸºäºåˆ†æç»“æœç”Ÿæˆæ ‡ç­¾å¤±è´¥: {e}")
            raise

# LangGraph é›†æˆ
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START
from langchain_core.runnables import RunnableConfig


# è‡ªå®šä¹‰è¾“å‡ºç±» - åªåŒ…å«éœ€è¦çš„å­—æ®µ
@dataclass
class ProfileLabelOutput:
    """ç”¨æˆ·ç”»åƒæ ‡ç­¾è¾“å‡º - åªåŒ…å«å¿…è¦å­—æ®µ"""
    user_profile_label: Optional[UserProfile] = field(default=None)
    error_message: Optional[str] = field(default=None)

@dataclass
class ProfileAnalysisOutput:
    """ç”¨æˆ·ç”»åƒåˆ†æè¾“å‡º - åªåŒ…å«å¿…è¦å­—æ®µ"""
    analysis_result: Optional[AnalysisResult] = field(default=None)
    error_message: Optional[str] = field(default=None)

# å¯¼å…¥AgentState
from states import AgentState

async def profile_analysis_node(state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
    """ğŸ”„ ã€LangGraphèŠ‚ç‚¹1ã€‘ç¬¬ä¸€æ­¥åˆ†æèŠ‚ç‚¹ - è‡ªåŠ¨è·å–å½“å‰ä¼šè¯å†å²èŠå¤©è®°å½•åˆ†æ"""
    try:
        # ğŸ“ è‡ªåŠ¨è·å–å½“å‰ä¼šè¯çš„å†å²èŠå¤©è®°å½•
        thread_id = config.get("configurable", {}).get("thread_id")
        if not thread_id:
            return {"error_message": "ç¼ºå°‘ä¼šè¯çº¿ç¨‹IDï¼Œæ— æ³•è·å–å†å²èŠå¤©è®°å½•"}
        
        # ç›´æ¥ä»stateä¸­è·å–å®Œæ•´å†å²æ¶ˆæ¯ï¼ˆLangGraphçŠ¶æ€æœºåˆ¶ï¼‰
        # ç›´æ¥ä½¿ç”¨long_term_messagesè·å–å®Œæ•´å†å²å¯¹è¯
        messages = state.get("long_term_messages", [])
        if messages:
            logger.info(f"profile_analysis_nodeä»long_term_messagesè·å–åˆ°{len(messages)}æ¡å†å²æ¶ˆæ¯")
        
        if not messages:
            return {"error_message": "å½“å‰ä¼šè¯æš‚æ— å†å²èŠå¤©è®°å½•"}
        
        # è·å–é…ç½®
        model_provider = config.get("configurable", {}).get("model_provider", "openrouter")
        model_name = config.get("configurable", {}).get("model_name", "x-ai/grok-3")
        temperature = config.get("configurable", {}).get("temperature", 0.3)
        
        # ğŸ¤– åˆ›å»ºç”Ÿæˆå™¨å¹¶åˆ†æå†å²èŠå¤©è®°å½•
        generator = ProfileGenerator(model_provider, model_name, temperature)
        analysis_result = await generator.analyze_conversation(config, state)
        
        return {
            "analysis_result": analysis_result,
            "error_message": None
        }
    
    except Exception as e:
        logger.error(f"å¯¹è¯åˆ†æå¤±è´¥: {e}")
        return {"error_message": str(e)}

def create_profile_analysis_graph():
    """åˆ›å»ºç¬¬ä¸€æ­¥åˆ†æå·¥ä½œæµ - ä¸“é—¨ç”¨äºæ›¿ä»£profile_agent"""
    # å®šä¹‰è¾“å…¥æ¨¡å‹ï¼ŒåªåŒ…å«å¿…è¦çš„è¾“å…¥å­—æ®µ
    class ProfileAnalysisInput(BaseModel):
        """ç”¨æˆ·ç”»åƒåˆ†æè¾“å…¥"""
        pass  # ç©ºè¾“å…¥ï¼Œæ‰€æœ‰æ•°æ®é€šè¿‡LangGraphçš„messagesè‡ªåŠ¨æ³¨å…¥
    
    graph = StateGraph(input=ProfileAnalysisInput, state_schema=AgentState, output=ProfileAnalysisOutput)
    graph.add_node("analysis_generator", profile_analysis_node)
    graph.add_edge(START, "analysis_generator")
    
    compiled_graph = graph.compile()
    return compiled_graph

# å¯¼å‡ºç¬¬ä¸€æ­¥åˆ†æå·¥ä½œæµ
profile_analysis_graph = create_profile_analysis_graph()

async def profile_label_node(state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
    """ğŸ”„ ã€LangGraphèŠ‚ç‚¹2ã€‘ç”¨æˆ·ç”»åƒæ ‡ç­¾ç”ŸæˆèŠ‚ç‚¹ - è‡ªåŠ¨è·å–å½“å‰ä¼šè¯å†å²èŠå¤©è®°å½•çš„å®Œæ•´æµç¨‹"""
    try:
        # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å®Œæ•´çš„configå†…å®¹
        logger.info(f"[DEBUG] profile_label_node æ¥æ”¶åˆ°çš„ config: {config}")
        logger.info(f"[DEBUG] profile_label_node æ¥æ”¶åˆ°çš„ state: {state}")
        
        # è·å–é…ç½®
        model_provider = config.get("configurable", {}).get("model_provider", "openrouter")
        model_name = config.get("configurable", {}).get("model_name", "x-ai/grok-3")
        temperature = config.get("configurable", {}).get("temperature", 0.3)
        
        generator = ProfileGenerator(model_provider, model_name, temperature)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
        analysis_result = state.get("analysis_result")
        
        if not analysis_result:
            # ğŸ“ è‡ªåŠ¨è·å–å½“å‰ä¼šè¯çš„å†å²èŠå¤©è®°å½•
            thread_id = config.get("configurable", {}).get("thread_id")
            logger.info(f"[DEBUG] æå–åˆ°çš„ thread_id: {thread_id}")
            
            if not thread_id:
                return {"error_message": "ç¼ºå°‘ä¼šè¯çº¿ç¨‹IDï¼Œæ— æ³•è·å–å†å²èŠå¤©è®°å½•"}
            
            # ç›´æ¥ä»stateä¸­è·å–å®Œæ•´å†å²æ¶ˆæ¯ï¼ˆLangGraphçŠ¶æ€æœºåˆ¶ï¼‰
            # ç›´æ¥ä½¿ç”¨long_term_messagesè·å–å®Œæ•´å†å²å¯¹è¯
            messages = state.get("long_term_messages", [])
            if messages:
                logger.info(f"profile_label_nodeä»long_term_messagesè·å–åˆ°{len(messages)}æ¡å†å²æ¶ˆæ¯")
            
            if not messages:
                return {"error_message": "å½“å‰ä¼šè¯æš‚æ— å†å²èŠå¤©è®°å½•ï¼Œæ— æ³•ç”Ÿæˆæ ‡ç­¾"}
            
            # ğŸ” ç¬¬ä¸€æ­¥ï¼šåˆ†æå†å²å¯¹è¯è®°å½•ï¼ˆä¼šè‡ªåŠ¨è¿‡æ»¤åªä¿ç•™äººç±»å’ŒAIå¯¹è¯ï¼‰
            analysis_result = await generator.analyze_conversation(config, state)
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºåˆ†æç»“æœç”Ÿæˆæ ‡ç­¾
        profile = await generator.generate_labels_from_analysis(analysis_result)
        
        return {
            "user_profile_label": profile,
            "analysis_result": analysis_result,  # åŒæ—¶è¿”å›åˆ†æç»“æœ
            "error_message": None
        }
    
    except Exception as e:
        logger.error(f"ç”¨æˆ·ç”»åƒæ ‡ç­¾ç”Ÿæˆå¤±è´¥: {e}")
        return {"error_message": str(e)}

def create_profile_label_graph():
    """åˆ›å»ºç”¨æˆ·ç”»åƒæ ‡ç­¾ç”Ÿæˆå·¥ä½œæµ"""
    # å®šä¹‰è¾“å…¥æ¨¡å‹ï¼ŒåªåŒ…å«å¿…è¦çš„è¾“å…¥å­—æ®µ
    class ProfileLabelInput(BaseModel):
        """ç”¨æˆ·ç”»åƒæ ‡ç­¾ç”Ÿæˆè¾“å…¥"""
        pass  # ç©ºè¾“å…¥ï¼Œæ‰€æœ‰æ•°æ®é€šè¿‡LangGraphçš„messagesè‡ªåŠ¨æ³¨å…¥
    
    graph = StateGraph(input=ProfileLabelInput, state_schema=AgentState, output=ProfileLabelOutput)
    graph.add_node("profile_generator", profile_label_node)
    graph.add_edge(START, "profile_generator")
    
    compiled_graph = graph.compile()
    return compiled_graph

# å¯¼å‡ºä¸»è¦æ¥å£
profile_label_graph = create_profile_label_graph()


if __name__ == "__main__":
    print("ç”¨æˆ·ç”»åƒç”Ÿæˆæ¨¡å— - åˆ†æ­¥å¼ä¼˜åŒ–ç‰ˆæœ¬åŠ è½½å®Œæˆ")