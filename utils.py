import asyncio
import json
import os
from openai import AsyncOpenAI
from Configurations import Configuration
import aiohttp
import io
import re
from typing import List, Any, Optional
from datetime import datetime, timezone, timedelta
import random
import uuid
import hashlib
BEIJING_TZ = timezone(timedelta(hours=8))
from agents.persona_config.config_manager import config_manager
_cfg = config_manager.get_config() or {}

# å»¶è¿Ÿåˆå§‹åŒ–clientï¼Œé¿å…åœ¨æ¨¡å—å¯¼å…¥æ—¶é˜»å¡
_client = None

# å»¶è¿ŸåŠ è½½ dashscopeï¼Œé¿å…åœ¨æœªå®‰è£…æˆ–æœªé…ç½®æ—¶å½±å“å…¶ä»–åŠŸèƒ½
_dashscope_loaded = False
def _ensure_dashscope_loaded() -> bool:
    global _dashscope_loaded
    if _dashscope_loaded:
        return True
    try:
        import dashscope  # noqa: F401
        _dashscope_loaded = True
        return True
    except Exception:
        return False

def _use_openrouter() -> bool:
    # å…¨é¢è½¬å‘ OpenRouterï¼šå§‹ç»ˆè¿”å› True
    return True

def _normalize_model_name_for_openrouter(model_name: str) -> str:
    if not model_name:
        return model_name
    # åœ¨ OpenRouter ä¸Šä½¿ç”¨ OpenAI å®¶æ—æ¨¡å‹æ—¶åŠ å‰ç¼€ openai/
    if model_name.startswith("gpt-") and "/" not in model_name:
        return f"openai/{model_name}"
    return model_name

# =====================
# StepFun TTS é›†æˆ
# æ–‡æ¡£å‚è€ƒï¼š`https://platform.stepfun.com/docs/guide/tts`ã€`https://platform.stepfun.com/docs/api-reference/audio/create_audio`
# =====================

async def synthesize_tts_stepfun(text: str, voice: str = None, audio_format: str = "mp3", speed: float = 1.0, pitch: float = 0.0) -> Optional[str]:
    """è°ƒç”¨æ™ºèƒ½é˜¶è·ƒ StepFun TTS ç”Ÿæˆè¯­éŸ³ï¼Œè¿”å›å…¬ç½‘å¯è®¿é—®çš„éŸ³é¢‘URLã€‚

    å‚æ•°æŒ‰ä»“åº“è¿è¡Œæ—¶é…ç½®ä¸å‡½æ•°å…¥å‚åˆå¹¶ï¼›å¤±è´¥è¿”å› Noneã€‚
    """
    if not isinstance(text, str) or not text.strip():
        return None
    import os
    api_key = os.getenv("STEPFUN_API_KEY")
    if not api_key:
        print("[TTS] æœªæ£€æµ‹åˆ° STEPFUN_API_KEYï¼Œè·³è¿‡åˆæˆ")
        return None
    # è¿è¡Œæ—¶é…ç½®
    try:
        cfg = Configuration.from_context()
    except Exception:
        cfg = None
    voice = voice or (cfg.tts_voice if cfg else _cfg.get("tts_voice", "huolinvsheng"))
    audio_format = audio_format or (cfg.tts_format if cfg else _cfg.get("tts_format", "mp3"))
    speed = float(speed or (cfg.tts_speed if cfg else _cfg.get("tts_speed", 1.0)))
    pitch = float(pitch or (cfg.tts_pitch if cfg else _cfg.get("tts_pitch", 0.0)))

    # ç«¯ç‚¹/æ¨¡å‹å¯ç”±ç¯å¢ƒæˆ–è¿è¡Œæ—¶é…ç½®è¦†ç›–
    endpoint = os.getenv("STEPFUN_TTS_ENDPOINT") or "https://api.stepfun.com/v1/audio/speech"
    try:
        cfg_model = (cfg.tts_model if cfg else _cfg.get("tts_model", "step-tts-vivid"))
    except Exception:
        cfg_model = _cfg.get("tts_model", "step-tts-vivid")
    model = os.getenv("STEPFUN_TTS_MODEL") or cfg_model
    url = endpoint
    print(f"[TTS] è°ƒç”¨ StepFun: endpoint={url}, model={model}, voice={voice}, format={audio_format}, speed={speed}, pitch={pitch}")
    payload = {
        "input": text,
        "model": model,
        "voice": voice,
        "format": audio_format,
        "speed": speed,
        "pitch": pitch,
    }
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "Accept": "application/json, audio/mpeg, audio/mp3"
    }
    try:
        timeout = aiohttp.ClientTimeout(total=60)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(url, json=payload, headers=headers) as resp:
                ctype = resp.headers.get("Content-Type", "")
                print(f"[TTS] HTTP {resp.status}, content-type={ctype}")
                if resp.status != 200:
                    # æŸäº›å®ç°ä¼šç›´æ¥è¿”å›éŸ³é¢‘æµï¼ˆcontent-type: audio/*ï¼‰ï¼Œæ­¤æ—¶æŒ‰äºŒè¿›åˆ¶å¤„ç†
                    try:
                        if ctype.startswith("audio/"):
                            audio_bytes = await resp.read()
                            fname = f"speech_{uuid.uuid4().hex[:8]}.{audio_format or 'mp3'}"
                            link = await _upload_bytes_public(audio_bytes, fname)
                            print(f"[TTS] äºŒè¿›åˆ¶éŸ³é¢‘â†’transfer.sh ä¸Šä¼ ç»“æœ: {link}")
                            return link
                    except Exception:
                        print("[TTS] å¤„ç†éŸ³é¢‘æµå¤±è´¥")
                    return None

                # ä¼˜å…ˆå°è¯•JSONè¿”å›
                text_ct = resp.headers.get("Content-Type", "")
                if "application/json" in text_ct or not text_ct or "json" in text_ct:
                    try:
                        j = await resp.json(content_type=None)
                        print(f"[TTS] JSON è¿”å›: keys={list(j.keys()) if isinstance(j, dict) else type(j)}")
                    except Exception:
                        j = None
                    # 1) ç›´æ¥URL
                    if isinstance(j, dict):
                        audio_url = None
                        # å¸¸è§å­—æ®µå…¼å®¹
                        audio_url = (
                            (j.get("data") or {}).get("url") if isinstance(j.get("data"), dict) else None
                        ) or j.get("url") or j.get("audio_url")
                        if audio_url and isinstance(audio_url, str) and audio_url.startswith("http"):
                            print(f"[TTS] ç›´æ¥è·å¾—URL: {audio_url}")
                            return audio_url
                        # 2) base64 å†…å®¹
                        base64_data = (
                            (j.get("data") or {}).get("audio") if isinstance(j.get("data"), dict) else None
                        ) or j.get("audio") or j.get("content")
                        if isinstance(base64_data, str) and base64_data:
                            try:
                                import base64
                                # å¤„ç† data:audio/mpeg;base64, å‰ç¼€
                                if "," in base64_data and base64_data.strip().startswith("data:"):
                                    base64_data = base64_data.split(",", 1)[1]
                                audio_bytes = base64.b64decode(base64_data)
                                fname = f"speech_{uuid.uuid4().hex[:8]}.{audio_format or 'mp3'}"
                                link = await _upload_bytes_public(audio_bytes, fname)
                                print(f"[TTS] base64â†’transfer.sh ä¸Šä¼ ç»“æœ: {link}")
                                return link
                            except Exception:
                                print("[TTS] è§£æbase64å¤±è´¥")
                                return None
                    return None
                else:
                    # éJSONï¼šå°è¯•æŒ‰éŸ³é¢‘äºŒè¿›åˆ¶å¤„ç†
                    audio_bytes = await resp.read()
                    if audio_bytes:
                        fname = f"speech_{uuid.uuid4().hex[:8]}.{audio_format or 'mp3'}"
                        link = await _upload_bytes_public(audio_bytes, fname)
                        print(f"[TTS] äºŒè¿›åˆ¶â†’transfer.sh ä¸Šä¼ ç»“æœ: {link}")
                        return link
                    return None
    except Exception:
        print("[TTS] StepFun è¯·æ±‚å¼‚å¸¸")
        return None

async def _upload_bytes_public(data: bytes, filename: str) -> Optional[str]:
    """ä¸Šä¼ äºŒè¿›åˆ¶åˆ°å…¬å…±ä¸´æ—¶æ–‡ä»¶æ‰˜ç®¡ï¼Œè¿”å›å…¬ç½‘å¯è®¿é—®é“¾æ¥ã€‚

    é¡ºåºï¼štransfer.sh â†’ 0x0.st â†’ file.io â†’ tmpfiles.org
    """
    if not data:
        return None
    timeout = aiohttp.ClientTimeout(total=30)
    try:
        async with aiohttp.ClientSession(timeout=timeout) as session:
            # 1) transfer.sh (PUT)
            try:
                url = f"https://transfer.sh/{filename}"
                async with session.put(url, data=data, headers={"Content-Type": "application/octet-stream"}) as r:
                    body = await r.text()
                    print(f"[TTS-UP] transfer.sh status={r.status}, body={body[:80]}")
                    if r.status in (200, 201):
                        link = body.strip()
                        if link.startswith("http"):
                            return link
            except Exception as e:
                print(f"[TTS-UP] transfer.sh å¤±è´¥: {e}")

            # 2) 0x0.st (multipart/form-data POST file)
            try:
                form = aiohttp.FormData()
                form.add_field("file", data, filename=filename, content_type="application/octet-stream")
                # 0x0.st å¯¹é»˜è®¤ User-Agent å¯èƒ½è¿”å› 403ï¼Œæ¨¡æ‹Ÿ curl UA
                async with session.post("https://0x0.st", data=form, headers={"User-Agent": "curl/8.0", "Accept": "*/*"}) as r:
                    text = (await r.text()).strip()
                    print(f"[TTS-UP] 0x0.st status={r.status}, body={text[:80]}")
                    if r.status in (200, 201) and text.startswith("http"):
                        return text
            except Exception as e:
                print(f"[TTS-UP] 0x0.st å¤±è´¥: {e}")

            # 3) file.io (multipart/form-data)
            try:
                form = aiohttp.FormData()
                form.add_field("file", data, filename=filename, content_type="application/octet-stream")
                async with session.post("https://file.io", data=form) as r:
                    j = await r.json(content_type=None)
                    print(f"[TTS-UP] file.io status={r.status}, json_keys={list(j.keys()) if isinstance(j, dict) else type(j)}")
                    link = (j or {}).get("link")
                    if r.status in (200, 201) and isinstance(link, str) and link.startswith("http"):
                        return link
            except Exception as e:
                print(f"[TTS-UP] file.io å¤±è´¥: {e}")

            # 4) tmpfiles.org (multipart/form-data)
            try:
                form = aiohttp.FormData()
                form.add_field("file", data, filename=filename, content_type="application/octet-stream")
                async with session.post("https://tmpfiles.org/api/v1/upload", data=form) as r:
                    j = await r.json(content_type=None)
                    print(f"[TTS-UP] tmpfiles status={r.status}, json_keys={list(j.keys()) if isinstance(j, dict) else type(j)}")
                    data_obj = (j or {}).get("data") if isinstance(j, dict) else None
                    page_url = (data_obj or {}).get("url") if isinstance(data_obj, dict) else None
                    file_name = (data_obj or {}).get("file_name") if isinstance(data_obj, dict) else None
                    if isinstance(page_url, str) and page_url.startswith("http"):
                        # æƒ…å†µAï¼šå·²ç»æ˜¯ç›´æ¥ä¸‹è½½é“¾æ¥ï¼Œç›´æ¥è¿”å›
                        if "/dl/" in page_url:
                            return page_url
                        # æƒ…å†µBï¼šåˆ†äº«é¡µ /s/<id>[/<name>] æˆ– æ ¹è·¯å¾„ /<id>[/<name>] â†’ ç»Ÿä¸€è½¬æ¢ä¸º /dl/<id>/<name>
                        try:
                            parts = page_url.rstrip("/").split("/")
                            # æœŸæœ› parts å½¢å¦‚ [scheme, '', host, ...path]
                            path_parts = parts[3:] if len(parts) > 3 else []
                            if not path_parts:
                                return page_url
                            if path_parts[0] == "s":
                                tail = path_parts[1:]
                            else:
                                tail = path_parts
                            if len(tail) >= 2:
                                file_id, inferred_name = tail[0], tail[1]
                                return f"https://tmpfiles.org/dl/{file_id}/{inferred_name}"
                            elif len(tail) == 1:
                                file_id = tail[0]
                                name = file_name or filename
                                return f"https://tmpfiles.org/dl/{file_id}/{name}" if name else f"https://tmpfiles.org/dl/{file_id}"
                        except Exception:
                            pass
                        # æ— æ³•è§£æåˆ™è¿”å›é¡µé¢é“¾æ¥ä½œä¸ºå…œåº•
                        return page_url
            except Exception as e:
                print(f"[TTS-UP] tmpfiles å¤±è´¥: {e}")
    except Exception as e:
        print(f"[TTS-UP] ä¼šè¯åˆ›å»ºå¤±è´¥: {e}")
        return None
    return None

async def get_openai_client():
    """å¼‚æ­¥è·å– OpenRouter å…¼å®¹å®¢æˆ·ç«¯ï¼Œç»Ÿä¸€èµ° OpenRouterã€‚"""
    global _client
    if _client is None:
        print("[DEBUG] åˆå§‹åŒ–OpenRouterå…¼å®¹å®¢æˆ·ç«¯...")
        api_key = await asyncio.to_thread(os.getenv, "OPENROUTER_API_KEY")
        if not api_key:
            raise RuntimeError("æœªæ£€æµ‹åˆ° OPENROUTER_API_KEYã€‚è¯·è®¾ç½®åé‡è¯•ï¼Œå·²å…¨é¢åˆ‡æ¢ä¸º OpenRouterã€‚")
        referer = os.getenv("HTTP_REFERER", "")
        title = os.getenv("X_TITLE", "")
        # è®¾ç½®è¯·æ±‚è¶…æ—¶ï¼Œé¿å…äº‘ç«¯é•¿æ—¶é—´æŒ‚èµ·
        http_client_timeout = float(os.getenv("OPENROUTER_HTTP_TIMEOUT", "30"))
        _client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            default_headers={
                "HTTP-Referer": referer,
                "X-Title": title,
            },
            timeout=http_client_timeout,
        )
        print("[DEBUG] OpenRouterå…¼å®¹å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    return _client

def generate_video_id(video_url: str) -> str:
    """ä¸ºè§†é¢‘ç”Ÿæˆå”¯ä¸€ID"""
    # ä½¿ç”¨URLçš„hashä½œä¸ºåŸºç¡€
    url_hash = hashlib.md5(video_url.encode()).hexdigest()[:8]
    # æ·»åŠ æ—¶é—´æˆ³å’Œéšæœºæ•°ç¡®ä¿å”¯ä¸€æ€§
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    random_suffix = str(uuid.uuid4())[:4]
    return f"video_{url_hash}_{timestamp}_{random_suffix}"

def generate_frame_id(video_id: str, frame_index: int) -> str:
    """ä¸ºè§†é¢‘å¸§ç”Ÿæˆå”¯ä¸€ID"""
    return f"{video_id}_frame_{frame_index:03d}"

def generate_audio_id(video_id: str) -> str:
    """ä¸ºéŸ³é¢‘ç”Ÿæˆå”¯ä¸€ID"""
    return f"{video_id}_audio"

async def describe_image_urls(urls: List[str]) -> List[str]:
    """
    ä½¿ç”¨ GPT-4o å¯¹å›¾ç‰‡é“¾æ¥è¿›è¡Œæè¿°ï¼ˆé€å¼ å¤„ç†ï¼‰
    """
    print("=" * 80)
    print("ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å¼€å§‹æ‰§è¡Œdescribe_image_urls")
    print("=" * 80)
    print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] éœ€è¦å¤„ç†çš„å›¾ç‰‡URLæ•°é‡: {len(urls)}")
    for i, url in enumerate(urls, 1):
        print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å›¾ç‰‡ {i}: {url}")

    if not urls:
        print("ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] æ²¡æœ‰å›¾ç‰‡URLéœ€è¦å¤„ç†ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []

    try:
        print("ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] æ­£åœ¨è·å–OpenAIå®¢æˆ·ç«¯...")
        client = await get_openai_client()
        print("ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] OpenAIå®¢æˆ·ç«¯è·å–æˆåŠŸ")
    except Exception as e:
        print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] è·å–OpenAIå®¢æˆ·ç«¯å¤±è´¥: {e}")
        import traceback
        print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
        return [f"[è·å–è§†è§‰æ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥: {e}]" for _ in urls]

    descriptions = []
    # ä¼˜å…ˆä½¿ç”¨è¿è¡Œæ—¶çš„ vision_modelï¼›æœªæ˜¾å¼é…ç½®åˆ™å¼ºåˆ¶ä½¿ç”¨ z-ai/glm-4.5vï¼ˆä¸å†å›é€€åˆ° model_nameï¼Œé¿å…é€‰åˆ°ä¸æ”¯æŒå›¾åƒçš„èŠå¤©æ¨¡å‹ï¼‰
    vision_model = _normalize_model_name_for_openrouter(_cfg.get("vision_model") or "z-ai/glm-4.5v")
    print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å°†ä½¿ç”¨çš„è§†è§‰æ¨¡å‹: {vision_model}")

    for i, url in enumerate(urls, 1):
        print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å¼€å§‹å¤„ç†ç¬¬ {i} å¼ å›¾ç‰‡...")
        try:
            print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] æ­£åœ¨è°ƒç”¨è§†è§‰æ¨¡å‹åˆ†æå›¾ç‰‡: {url[:100]}...")
            response = await client.chat.completions.create(
                model=vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼š"},
                            {"type": "image_url", "image_url": {"url": url}}
                        ]
                    }
                ],
                max_tokens=300
            )
            print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] è§†è§‰æ¨¡å‹è°ƒç”¨å®Œæˆï¼Œå“åº”ç±»å‹: {type(response)}")
            description = response.choices[0].message.content.strip()
            print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å›¾ç‰‡ {i} æè¿°æˆåŠŸï¼Œé•¿åº¦: {len(description)} å­—ç¬¦")
            print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å›¾ç‰‡ {i} æè¿°å†…å®¹: {description[:200]}...")
        except Exception as e:
            print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] å›¾ç‰‡ {i} æè¿°å¤±è´¥: {e}")
            import traceback
            print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            description = f"[å›¾ç‰‡æè¿°å¤±è´¥: {e}]"

        descriptions.append(description)

    print(f"ğŸ–¼ï¸ [DEBUG-è§†è§‰è¯†åˆ«] æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼Œå…± {len(descriptions)} ä¸ªæè¿°")
    return descriptions

async def transcribe_audio_urls(urls: List[str]) -> List[str]:
    """
    è¯­éŸ³è½¬å†™ä¼˜å…ˆä½¿ç”¨é˜¿é‡Œäº‘ SenseVoiceï¼ˆdashscopeï¼‰ï¼Œå¤±è´¥æ—¶å›é€€åˆ° OpenAI Whisperã€‚

    æ³¨æ„ï¼šSenseVoice è¦æ±‚è¾“å…¥ä¸ºå…¬ç½‘å¯è®¿é—®çš„ URLï¼Œä¸æ”¯æŒç›´æ¥ä¸Šä¼ æ–‡ä»¶å­—èŠ‚ã€‚
    """
    print("=" * 80)
    print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] å¼€å§‹æ‰§è¡Œtranscribe_audio_urls")
    print("=" * 80)
    print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] éœ€è¦å¤„ç†çš„éŸ³é¢‘URLæ•°é‡: {len(urls)}")
    for i, url in enumerate(urls, 1):
        print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] éŸ³é¢‘ {i}: {url}")

    if not urls:
        print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æ²¡æœ‰éŸ³é¢‘URLéœ€è¦å¤„ç†ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []

    print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æ£€æŸ¥é˜¿é‡Œäº‘SenseVoiceé…ç½®...")
    # å¦‚æœé…ç½®äº†é˜¿é‡Œäº‘ API Key ä¸”å®‰è£…äº† dashscopeï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨ SenseVoice
    dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
    print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] DASHSCOPE_API_KEYé…ç½®çŠ¶æ€: {'å·²é…ç½®' if dashscope_api_key else 'æœªé…ç½®'}")

    if dashscope_api_key and _ensure_dashscope_loaded():
        print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] å°è¯•ä½¿ç”¨é˜¿é‡Œäº‘SenseVoiceè¿›è¡ŒéŸ³é¢‘è½¬å½•...")
        try:
            # å°è¯•ä»è¿è¡Œæ—¶é…ç½®è¯»å– language hintï¼Œä¾‹å¦‚ "zh"/"en"/"yue"/"ja"/"ko"/"auto"
            language_hint = None
            try:
                language_hint = _cfg.get("asr_language") or _cfg.get("sensevoice_language")
                print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] è¯­è¨€è®¾ç½®: {language_hint}")
            except Exception:
                language_hint = None

            results = await _sensevoice_transcribe_urls(urls, language_code=language_hint)
            print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] SenseVoiceå¤„ç†å®Œæˆï¼Œç»“æœæ•°é‡: {len(results)}")

            # è‹¥ç»“æœåŸºæœ¬å¯ç”¨ï¼Œåˆ™ç›´æ¥è¿”å›
            if results and any(isinstance(x, str) and x.strip() for x in results):
                print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] SenseVoiceç»“æœæœ‰æ•ˆï¼Œç›´æ¥è¿”å›")
                return results
            else:
                print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] SenseVoiceç»“æœæ— æ•ˆï¼Œå›é€€åˆ°Whisper")
        except Exception as e:
            print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] SenseVoiceè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°Whisper: {e}")
            import traceback
            print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] SenseVoiceè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")

    print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] ä½¿ç”¨OpenAI Whisperè¿›è¡ŒéŸ³é¢‘è½¬å½•...")
    # å›é€€åˆ° Whisperï¼ˆç°æœ‰å®ç°ï¼‰
    try:
        client = await get_openai_client()
        print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] OpenAIå®¢æˆ·ç«¯è·å–æˆåŠŸ")
    except Exception as e:
        print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] è·å–OpenAIå®¢æˆ·ç«¯å¤±è´¥: {e}")
        return [f"[è·å–éŸ³é¢‘è½¬å½•å®¢æˆ·ç«¯å¤±è´¥: {e}]" for _ in urls]

    transcriptions: List[str] = []
    whisper_model = _cfg.get("whisper_model", "whisper-1")
    print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] å°†ä½¿ç”¨çš„Whisperæ¨¡å‹: {whisper_model}")

    async with aiohttp.ClientSession() as session:
        for i, url in enumerate(urls, 1):
            print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æ­£åœ¨å¤„ç†ç¬¬ {i} ä¸ªéŸ³é¢‘: {url[:100]}...")
            try:
                print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] ä¸‹è½½éŸ³é¢‘æ–‡ä»¶...")
                async with session.get(url) as resp:
                    status = resp.status
                    print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] HTTPå“åº”çŠ¶æ€ç : {status}")

                    if resp.status == 200:
                        audio_data = await resp.read()
                        print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] éŸ³é¢‘æ•°æ®ä¸‹è½½å®Œæˆï¼Œå¤§å°: {len(audio_data)} bytes")

                        audio_file = io.BytesIO(audio_data)
                        audio_file.name = "audio.mp3"

                        prompt = "è¯·ç›´æ¥æå–è¿™æ®µè¯­éŸ³çš„æ ¸å¿ƒå†…å®¹ï¼Œæ§åˆ¶åœ¨200å­—ä»¥å†…ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€‚"
                        print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] è½¬å½•æç¤ºè¯: {prompt}")

                        # è‹¥æœªé…ç½®å®˜æ–¹ OpenAI Keyï¼Œè·³è¿‡ Whisper å…œåº•
                        if not os.getenv("OPENAI_API_KEY"):
                            print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æœªé…ç½®OPENAI_API_KEYï¼Œè·³è¿‡éŸ³é¢‘è½¬å†™")
                            transcriptions.append("[æœªé…ç½®OPENAI_API_KEYï¼Œè·³è¿‡éŸ³é¢‘è½¬å†™]")
                            continue

                        print("ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æ­£åœ¨è°ƒç”¨Whisper API...")
                        response = await client.audio.transcriptions.create(
                            model=whisper_model,
                            file=audio_file,
                            prompt=prompt,
                            response_format="text"
                        )

                        transcribed_text = response.strip() if isinstance(response, str) else response.text.strip()
                        print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] Whisperè½¬å½•å®Œæˆï¼ŒåŸå§‹é•¿åº¦: {len(transcribed_text)} å­—ç¬¦")

                        if len(transcribed_text) > 150:
                            print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] å†…å®¹è¿‡é•¿({len(transcribed_text)}å­—)ï¼Œä½¿ç”¨GPTæç‚¼é‡è¦å†…å®¹...")
                            try:
                                important_content = await extract_important_content(transcribed_text, max_length=100)
                                transcriptions.append(important_content)
                                print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æç‚¼å®Œæˆï¼Œæœ€ç»ˆé•¿åº¦: {len(important_content)} å­—")
                            except Exception as e:
                                print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] å†…å®¹æç‚¼å¤±è´¥: {e}")
                                transcriptions.append(transcribed_text[:150] + "...")
                        else:
                            transcriptions.append(transcribed_text)
                            print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] è½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcribed_text)} å­—")
                    else:
                        error_msg = f"[è¯­éŸ³è·å–å¤±è´¥: {resp.status}]"
                        transcriptions.append(error_msg)
                        print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] {error_msg}")
            except Exception as e:
                error_msg = f"[è¯­éŸ³è½¬å½•å¤±è´¥: {e}]"
                transcriptions.append(error_msg)
                print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] {error_msg}")
                import traceback
                print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")

    print(f"ğŸµ [DEBUG-éŸ³é¢‘è½¬å½•] æ‰€æœ‰éŸ³é¢‘å¤„ç†å®Œæˆï¼Œå…± {len(transcriptions)} ä¸ªè½¬å½•ç»“æœ")
    return transcriptions

async def _sensevoice_transcribe_urls(urls: List[str], language_code: Optional[str] = None) -> List[str]:
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ SenseVoice å½•éŸ³è¯­éŸ³è¯†åˆ«ï¼ˆdashscopeï¼‰å¯¹ä¸€ç»„éŸ³é¢‘ URL è¿›è¡Œè½¬å†™ã€‚
    è¿”å›ä¸è¾“å…¥ç­‰é•¿çš„ç»“æœåˆ—è¡¨ã€‚
    """
    # è·å–ç»“æœå…ƒæ•°æ®ï¼ˆå†…ç½® WAITâ†’FETCH å…œåº•ã€é‡è¯•ï¼‰
    results_meta = await _sensevoice_get_results_meta(urls, language_code)

    parsed_texts: List[str] = []
    for item in results_meta:
        if item.get("subtask_status") != "SUCCEEDED":
            code = item.get("code", "")
            msg = item.get("message", "")
            parsed_texts.append(f"[SenseVoiceå­ä»»åŠ¡å¤±è´¥: {code} {msg}]")
            continue
        t_url = item.get("transcription_url")
        if not t_url:
            parsed_texts.append("[SenseVoiceç¼ºå°‘ç»“æœURL]")
            continue
        j = await _fetch_json_resilient(t_url)
        parsed_texts.append(_parse_sensevoice_json(j))

    # é•¿æ–‡æœ¬åšæ‘˜è¦
    final_texts: List[str] = []
    for text in parsed_texts:
        if not isinstance(text, str):
            final_texts.append("[SenseVoiceç»“æœè§£æå¤±è´¥]")
            continue
        t = text.strip()
        if len(t) > 150:
            try:
                summarized = await extract_important_content(t, max_length=100)
                final_texts.append(summarized)
            except Exception:
                final_texts.append(t[:120] + "...")
        else:
            final_texts.append(t)
    return final_texts

def _parse_sensevoice_json(j: Any) -> str:
    """ä» SenseVoice çš„è½¬å†™ JSON ä¸­æå–æ–‡æœ¬ï¼Œç§»é™¤æƒ…ç»ª/äº‹ä»¶æ ‡ç­¾ã€‚"""
    try:
        # ä¼˜å…ˆè§£æ transcripts -> sentences
        transcripts = (j or {}).get("transcripts") or (j or {}).get("Transcript")
        if transcripts and isinstance(transcripts, list):
            # å–ç¬¬ä¸€ä¸ª channel çš„å†…å®¹
            first = transcripts[0]
            # ä¸€äº›ç¤ºä¾‹ä½¿ç”¨ key "text" å­˜å‚¨å¯Œæ–‡æœ¬ï¼ˆå«æ ‡ç­¾ï¼‰
            text_field = first.get("text") or ""
            sentences = first.get("sentences") or []
            if sentences and isinstance(sentences, list):
                joined = " ".join(s.get("text", "") for s in sentences if isinstance(s, dict))
                return _strip_sv_tags(joined)
            if text_field:
                return _strip_sv_tags(text_field)
        # å…¶ä»–ç»“æ„å…œåº•ï¼šç›´æ¥å­—ç¬¦ä¸²åŒ–
        return _strip_sv_tags(str(j))
    except Exception:
        return "[SenseVoiceç»“æœè§£æå¼‚å¸¸]"

def _strip_sv_tags(text: str) -> str:
    """å»é™¤ SenseVoice å¯Œæ–‡æœ¬ä¸­çš„æ ‡ç­¾ï¼Œå¦‚ <|Speech|>ã€<|HAPPY|>ã€<|Applause|> ç­‰ã€‚"""
    try:
        return re.sub(r"<\|/?[^|]+\|>", "", text).strip()
    except Exception:
        return text

async def _fetch_json_resilient(url: str, retries: int = 3, backoff_base: float = 0.5) -> Any:
    """å¸¦é‡è¯•ä¸æŒ‡æ•°é€€é¿çš„ JSON æ‹‰å–ï¼Œç¼“è§£å¶å‘ SSL EOF/ç½‘ç»œé—ªæ–­ã€‚
    - retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    - backoff_base: åˆå§‹é€€é¿ç§’æ•°
    """
    last_err = None
    for attempt in range(retries + 1):
        try:
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url, ssl=False) as r:
                    if r.status == 200:
                        return await r.json(content_type=None)
                    # ç‰¹æ®Šå¤„ç†405é”™è¯¯ï¼Œæä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                    elif r.status == 405:
                        print(f"[DEBUG] HTTP 405 Method Not Allowed for URL: {url}")
                        print("[DEBUG] å¯èƒ½åŸå› ï¼šLangSmithç¯å¢ƒé™åˆ¶æˆ–æœåŠ¡å™¨ä¸æ”¯æŒGETæ–¹æ³•")
                        last_err = RuntimeError(f"HTTP 405 - Method Not Allowed (LangSmithç¯å¢ƒå¯èƒ½å­˜åœ¨è®¿é—®é™åˆ¶)")
                    else:
                        last_err = RuntimeError(f"HTTP {r.status}")
        except Exception as e:
            last_err = e
        if attempt < retries:
            await asyncio.sleep(backoff_base * (2 ** attempt))
    return {"error": str(last_err) if last_err else "unknown"}

async def _sensevoice_get_results_meta(urls: List[str], language_code: Optional[str]) -> List[dict]:
    """
    ç¨³å¥åœ°æäº¤ SenseVoice ä»»åŠ¡å¹¶è·å– results å…ƒæ•°æ®ï¼š
    - å…ˆ async_call â†’ waitï¼›è‹¥ wait è§¦å‘ç½‘ç»œå¼‚å¸¸ï¼ˆå¦‚ SSL EOFï¼‰ï¼Œé€€é¿é‡è¯•ï¼›
    - è‹¥ wait å¤±è´¥æˆ–çŠ¶æ€é OKï¼Œåˆ™å°è¯• fetch è½®è¯¢ï¼ˆé¿å…å•æ¬¡é•¿è¿æ¥é—®é¢˜ï¼‰ã€‚
    """
    from dashscope.audio.asr import Transcription  # type: ignore
    from http import HTTPStatus

    params = dict(
        model="sensevoice-v1",
        file_urls=urls,
        language_hints=[language_code] if language_code else ["auto"],
    )

    # æäº¤ä»»åŠ¡
    task_response = await asyncio.to_thread(Transcription.async_call, **params)
    if not task_response or not getattr(task_response, "output", None) or not getattr(task_response.output, "task_id", None):
        maybe_msg = getattr(task_response, "message", None) if task_response else None
        raise RuntimeError(f"SenseVoice æäº¤å¤±è´¥ï¼šæœªè·å¾—ä»»åŠ¡ID{f'ï¼ˆ{maybe_msg}ï¼‰' if maybe_msg else ''}")
    task_id = task_response.output.task_id

    # ç­‰å¾…ç»“æœï¼ˆå¸¦é‡è¯•ï¼Œå¤„ç† SSL EOF ç­‰ç¬æ–­é—®é¢˜ï¼‰
    last_wait_err = None
    for attempt in range(3):
        try:
            transcribe_response = await asyncio.to_thread(Transcription.wait, task_id)
            if transcribe_response and transcribe_response.status_code == HTTPStatus.OK:
                output = transcribe_response.output or {}
                return output.get("results", []) or []
            last_wait_err = RuntimeError(f"éOKçŠ¶æ€: {getattr(transcribe_response, 'status_code', None)}")
        except Exception as e:
            last_wait_err = e
        await asyncio.sleep(0.5 * (2 ** attempt))

    # å…œåº•ï¼šä½¿ç”¨ fetch è½®è¯¢ï¼Œé¿å…é•¿è¿æ¥é—®é¢˜
    try:
        for _ in range(10):
            fetch_resp = await asyncio.to_thread(Transcription.fetch, task_id)
            if not fetch_resp:
                await asyncio.sleep(0.5)
                continue
            status = getattr(fetch_resp, "output", {}) or {}
            task_status = (status.get("task_status") or getattr(fetch_resp, "task_status", None))
            if task_status in ("SUCCEEDED", "FAILED"):
                out = getattr(fetch_resp, "output", {}) or {}
                return out.get("results", []) or []
            await asyncio.sleep(0.8)
    except Exception:
        pass

    raise RuntimeError(f"SenseVoice ç­‰å¾…å¤±è´¥ï¼š{last_wait_err}")

async def transcribe_audio_urls_with_emotion(urls: List[str]) -> List[dict]:
    """
    è¿”å›åŒ…å«æ–‡æœ¬ä¸æƒ…æ„Ÿçš„ç»“æœåˆ—è¡¨ï¼š[{"text": str, "emotion": str}]ã€‚
    - ä¼˜å…ˆ SenseVoiceï¼šä»ç»“æœä¸­è§£ææƒ…æ„Ÿæ ‡ç­¾ï¼ˆHAPPY/SAD/ANGRY/NEUTRALï¼‰ï¼Œå¹¶æ¸…æ´—æ ‡ç­¾ã€‚
    - å›é€€ Whisperï¼šä»…è¿”å›æ–‡æœ¬ï¼Œemotion ç½®ä¸º "æœªçŸ¥"ã€‚

    æ”¯æŒé…ç½®é€‰é¡¹ï¼š
    - è®¾ç½®ç¯å¢ƒå˜é‡ DISABLE_SENSEVOICE=1 å¯å¼ºåˆ¶ä½¿ç”¨Whisperï¼Œé¿å…LangSmithç¯å¢ƒçš„ç½‘ç»œé™åˆ¶
    """
    if not urls:
        return []

    # æ£€æŸ¥æ˜¯å¦ç¦ç”¨SenseVoiceï¼ˆé€‚ç”¨äºLangSmithç­‰å—é™ç¯å¢ƒï¼‰
    disable_sensevoice = os.getenv("DISABLE_SENSEVOICE", "0") == "1"
    if disable_sensevoice:
        print("[DEBUG] SenseVoiceå·²è¢«ç¦ç”¨ï¼Œç›´æ¥ä½¿ç”¨Whisper")
        texts = await transcribe_audio_urls(urls)
        return [{"text": t, "emotion": "æœªçŸ¥"} for t in texts]

    dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
    if dashscope_api_key and _ensure_dashscope_loaded():
        try:
            # è·å–ç»“æœå…ƒæ•°æ®ï¼ˆå†…ç½® WAITâ†’FETCH å…œåº•ã€é‡è¯•ï¼‰
            results_meta = await _sensevoice_get_results_meta(urls, None)

            parsed: List[dict] = []
            for item in results_meta:
                if item.get("subtask_status") != "SUCCEEDED":
                    code = item.get("code", "")
                    msg = item.get("message", "")
                    parsed.append({"text": f"[SenseVoiceå­ä»»åŠ¡å¤±è´¥: {code} {msg}]", "emotion": "æœªçŸ¥"})
                    continue
                t_url = item.get("transcription_url")
                if not t_url:
                    parsed.append({"text": "[SenseVoiceç¼ºå°‘ç»“æœURL]", "emotion": "æœªçŸ¥"})
                    continue
                j = await _fetch_json_resilient(t_url)
                text, emotion = _parse_sensevoice_json_with_emotion(j)
                parsed.append({"text": text, "emotion": emotion})

            # å¯¹è¿‡é•¿æ–‡æœ¬åšæ‘˜è¦
            final: List[dict] = []
            for r in parsed:
                txt = r.get("text", "")
                if isinstance(txt, str) and len(txt) > 150:
                    try:
                        summarized = await extract_important_content(txt, max_length=100)
                        final.append({"text": summarized, "emotion": r.get("emotion", "æœªçŸ¥")})
                    except Exception:
                        final.append({"text": txt[:120] + "...", "emotion": r.get("emotion", "æœªçŸ¥")})
                else:
                    final.append(r)
            return final
        except Exception as e:
            print(f"âš ï¸ SenseVoiceï¼ˆå«æƒ…æ„Ÿï¼‰è°ƒç”¨å¤±è´¥ï¼Œå›é€€ Whisper: {e}")

    # Whisper å›é€€ï¼šä»…æ–‡æœ¬
    texts = await transcribe_audio_urls(urls)
    return [{"text": t, "emotion": "æœªçŸ¥"} for t in texts]

def _parse_sensevoice_json_with_emotion(j: Any) -> tuple[str, str]:
    """
    ä» SenseVoice çš„è½¬å†™ JSON ä¸­æå– (text, emotion)ã€‚
    emotion å–å€¼æ˜ å°„ä¸ºä¸­æ–‡ï¼šHAPPYâ†’é«˜å…´, SADâ†’ä¼¤å¿ƒ, ANGRYâ†’ç”Ÿæ°”, NEUTRALâ†’ä¸­æ€§ï¼›æ— åˆ™è¿”å› "æœªçŸ¥"ã€‚
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
        if isinstance(j, dict) and "error" in j:
            error_msg = j.get("error", "")
            if "405" in error_msg or "Method Not Allowed" in error_msg:
                return "[è¯­éŸ³è½¬å½•å¤±è´¥: Error code: 405]", "æœªçŸ¥"
            else:
                return f"[è¯­éŸ³è½¬å½•å¤±è´¥: {error_msg}]", "æœªçŸ¥"

        transcripts = (j or {}).get("transcripts") or (j or {}).get("Transcript")
        raw_text = ""
        if transcripts and isinstance(transcripts, list):
            first = transcripts[0]
            text_field = first.get("text") or ""
            sentences = first.get("sentences") or []
            if sentences and isinstance(sentences, list):
                raw_text = " ".join(s.get("text", "") for s in sentences if isinstance(s, dict))
            elif text_field:
                raw_text = text_field
        else:
            raw_text = str(j)

        emotion_en = _extract_sv_emotion_tag(raw_text)
        emotion_cn = _map_emotion_to_zh(emotion_en) if emotion_en else "æœªçŸ¥"
        clean_text = _strip_sv_tags(raw_text)
        return clean_text, emotion_cn
    except Exception:
        return "[SenseVoiceç»“æœè§£æå¼‚å¸¸]", "æœªçŸ¥"

def _extract_sv_emotion_tag(text: str) -> Optional[str]:
    """æå–æœ€åå‡ºç°çš„æƒ…æ„Ÿæ ‡ç­¾ï¼Œå¦‚ <|HAPPY|>ã€‚è¿”å›è‹±æ–‡ä»£å·æˆ– Noneã€‚"""
    try:
        tags = re.findall(r"<\|([A-Z]+)\|>", text)
        # ä»…å…³æ³¨æƒ…æ„Ÿæ ‡ç­¾
        valid = [t for t in tags if t in {"HAPPY", "SAD", "ANGRY", "NEUTRAL"}]
        return valid[-1] if valid else None
    except Exception:
        return None

def _map_emotion_to_zh(tag: Optional[str]) -> str:
    mapping = {
        "HAPPY": "é«˜å…´",
        "SAD": "ä¼¤å¿ƒ",
        "ANGRY": "ç”Ÿæ°”",
        "NEUTRAL": "ä¸­æ€§",
    }
    return mapping.get(tag or "", "æœªçŸ¥")


async def extract_important_content(text: str, max_length: int = 100) -> str:
    """
    æå–æ–‡æœ¬ä¸­çš„é‡è¦å†…å®¹ï¼Œæ§åˆ¶åœ¨æŒ‡å®šå­—æ•°ä»¥å†…
    """
    client = await get_openai_client()
    if len(text) <= max_length:
        return text
    
    try:
        response = await client.chat.completions.create(
            model=_normalize_model_name_for_openrouter(_cfg.get("generation_model", _cfg.get("model_name", "gpt-4o-mini"))),  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
            messages=[
                {
                    "role": "system",
                    "content": f"ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬æ‘˜è¦ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹è¯­éŸ³è½¬å½•æ–‡æœ¬ä¸­æå–æœ€é‡è¦çš„å†…å®¹ï¼Œæ§åˆ¶åœ¨{max_length}å­—ä»¥å†…ã€‚ä¿ç•™å…³é”®ä¿¡æ¯ï¼Œå»é™¤å†—ä½™å†…å®¹ã€‚"
                },
                {
                    "role": "user", 
                    "content": f"è¯·æå–ä»¥ä¸‹è¯­éŸ³å†…å®¹çš„é‡è¦ä¿¡æ¯ï¼Œæ§åˆ¶åœ¨{max_length}å­—ä»¥å†…ï¼š\n\n{text}"
                }
            ],
            max_tokens=300,
            temperature=0.1
        )
        
        result = response.choices[0].message.content.strip()
        return result
        
    except Exception as e:
        print(f"âš ï¸ é‡è¦å†…å®¹æå–å¤±è´¥: {e}")
        # é™çº§å¤„ç†ï¼šç®€å•æˆªå–
        return text[:max_length] + "..." if len(text) > max_length else text


def parse_datetime_to_beijing(dt_str):
    """å°†ISOå­—ç¬¦ä¸²è½¬ä¸ºä¸œå…«åŒºdatetimeå¯¹è±¡"""
    if not dt_str:
        return None
    if isinstance(dt_str, datetime):
        if dt_str.tzinfo is None:
            return dt_str.replace(tzinfo=BEIJING_TZ)
        return dt_str.astimezone(BEIJING_TZ)
    if isinstance(dt_str, str):
        try:
            return datetime.fromisoformat(dt_str.replace('Z', '+08:00')).astimezone(BEIJING_TZ)
        except Exception:
            return None
    return None

def ensure_beijing_aware(dt):
    # åªåšç±»å‹é€ä¼ ï¼Œä¸åšä»»ä½•è½¬æ¢ï¼Œè¾“å…¥è¾“å‡ºéƒ½ä¸ºstræˆ–None
    return dt
def extract_xml(text: str, tag: str) -> str:
    """
    ä»ç»™å®šçš„æ–‡æœ¬ä¸­æå–æŒ‡å®šXMLæ ‡ç­¾çš„å†…å®¹ã€‚
    è¿™ä¸ªå‡½æ•°æ˜¯è§£æå¤§è¯­è¨€æ¨¡å‹è¿”å›çš„ç»“æ„åŒ–å“åº”çš„å…³é”®å·¥å…·ã€‚

    å·¥ä½œåŸç†:
    - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ `re.search` æ¥æŸ¥æ‰¾æ¨¡å¼ `<tag>(.*?)</tag>`ã€‚
    - `re.DOTALL` æ ‡å¿—å…è®¸ `.` åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„ä»»æ„å­—ç¬¦ï¼Œ
      è¿™å¯¹äºæå–å¯èƒ½åŒ…å«å¤šè¡Œå†…å®¹çš„XMLæ ‡ç­¾è‡³å…³é‡è¦ã€‚
    - å¦‚æœæ‰¾åˆ°åŒ¹é…é¡¹ï¼Œ`match.group(1)`ä¼šè¿”å›ç¬¬ä¸€ä¸ªæ•è·ç»„çš„å†…å®¹ï¼Œ
      ä¹Ÿå°±æ˜¯å¼€å§‹å’Œç»“æŸæ ‡ç­¾ä¹‹é—´çš„æ‰€æœ‰æ–‡æœ¬ã€‚

    Args:
        text (str): åŒ…å«XMLçš„æ–‡æœ¬ã€‚
        tag (str): è¦æå–å†…å®¹çš„XMLæ ‡ç­¾åã€‚

    Returns:
        str: æŒ‡å®šXMLæ ‡ç­¾çš„å†…å®¹ï¼Œå¦‚æœæœªæ‰¾åˆ°æ ‡ç­¾åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æœç´¢æŒ‡å®šæ ‡ç­¾å¯¹ä¹‹é—´çš„å†…å®¹
    match = re.search(f'<{tag}>(.*?)</{tag}>', text, re.DOTALL)
    # å¦‚æœæ‰¾åˆ°åŒ¹é…é¡¹ï¼Œè¿”å›æ•è·çš„å†…å®¹ï¼Œå¦åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    return match.group(1) if match else ""

def format_messages(messages: List[Any]) -> str:
    """æ ¼å¼åŒ–å¯¹è¯æ¶ˆæ¯."""
    if not messages:
        return ""
    lines = []
    for msg in messages[-10:]:  # ä¿ç•™æœ€è¿‘10æ¡å¯¹è¯
        # å…¼å®¹ dict å’Œå¯¹è±¡
        role = None
        content = None
        if isinstance(msg, dict):
            role = msg.get("role", "")
            content = msg.get("content", "")
        elif hasattr(msg, "role") and hasattr(msg, "content"):
            role = getattr(msg, "role", "")
            content = getattr(msg, "content", "")
        else:
            # å…œåº•ï¼šè½¬å­—ç¬¦ä¸²
            role = str(type(msg))
            content = str(msg)

        if role == "user" or role == "human":
            lines.append(f"ç”¨æˆ·ï¼š{content}")
        elif role == "assistant" or role == "ai":
            lines.append(f"åŠ©æ‰‹ï¼š{content}")
        else:
            lines.append(f"{role}ï¼š{content}")
    return "\n".join(lines)

def calculate_smart_interval(user_last_reply_time: str, last_active_send_time: str) -> int:
    """è®¡ç®—æ™ºèƒ½è§¦å‘é—´éš”ã€‚æ‰€æœ‰å‚æ•°å‡ä¸ºå­—ç¬¦ä¸²ï¼Œå†…éƒ¨éœ€è¦  æ—¶è½¬ä¸ºdatetime"""
    now = datetime.now(BEIJING_TZ)

    user_last_reply_dt = parse_datetime_to_beijing(user_last_reply_time)
    last_active_send_dt = parse_datetime_to_beijing(last_active_send_time)

    if not user_last_reply_dt:
        return 86400  # é»˜è®¤1å¤©
    user_reply_diff = now - user_last_reply_dt
    user_reply_days = user_reply_diff.days

    # æ™ºèƒ½é—´éš”è§„åˆ™ï¼ˆå¯æ ¹æ®ä¸šåŠ¡è°ƒæ•´ï¼‰
    if user_reply_days >= 60:
        return 31536000  # 1å¹´ï¼Œè½¬äººå·¥
    if user_reply_days >= 30:
        return random.randint(10 * 86400, 20 * 86400)
    if user_reply_days >= 7:
        return random.randint(3 * 86400, 5 * 86400)
    if user_reply_days >= 1:
        return random.randint(86400, 2 * 86400)
    # 2å°æ—¶å†…
    hours_since_reply = user_reply_diff.total_seconds() / 3600
    if hours_since_reply <= 2:
        return random.randint(3 * 3600, 18 * 3600)
    return 86400  # é»˜è®¤1å¤©

def parse_event_decision(response: str) -> dict:
    """è§£æäº‹ä»¶å†³ç­–å“åº”."""
    try:
        # å°è¯•æå–JSON
        if "{" in response and "}" in response:
            start = response.find("{")
            end = response.rfind("}") + 1
            json_str = response[start:end]
            return json.loads(json_str)
        else:
            raise ValueError("å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„JSON")
    except Exception as e:
        print(f"[ERROR] è§£æäº‹ä»¶å†³ç­–å“åº”å¤±è´¥: {e}")
        print(f"[ERROR] åŸå§‹å“åº”: {response}")
        return {
            "event_type": "pending_activation",
            "event_time": datetime.now(BEIJING_TZ).isoformat(),
            "appointment_time": None
        }

async def describe_video_urls(urls: List[str]) -> List[str]:
    """
    ä¸“ä¸šè§†é¢‘åˆ†æå¤„ç† - åŸºäºé˜¿é‡Œäº‘ç™¾ç‚¼è§†é¢‘ç†è§£APIæ€è·¯ï¼ˆçº¯å†…å­˜å¤šå¸§å¤„ç†ï¼‰
    
    å¤„ç†æµç¨‹ï¼š
    1. æµå¼ä¸‹è½½è§†é¢‘æ•°æ®åˆ°å†…å­˜
    2. ä½¿ç”¨PythonåŒ…æå–å¤šä¸ªå…³é”®å¸§ï¼ˆæ¯ç§’1-2å¸§ï¼‰
    3. æå–éŸ³é¢‘æ•°æ®
    4. ä½¿ç”¨aihubmix o4-miniåˆ†æå¤šä¸ªå…³é”®å¸§
    5. ä½¿ç”¨OpenAI Whisperè½¬å½•éŸ³é¢‘
    6. ç»¼åˆå¤šæ¨¡æ€ä¿¡æ¯ç”Ÿæˆè§†é¢‘æè¿°
    
    å‚è€ƒï¼šé˜¿é‡Œäº‘ç™¾ç‚¼è§†é¢‘ç†è§£APIæ€è·¯ï¼Œä½†ä½¿ç”¨ç°æœ‰æ¨¡å‹
    """
    # æ”¯æŒçš„è§†é¢‘æ ¼å¼
    VIDEO_FORMATS = {
        "wmv", "asf", "asx", "rm", "rmvb", "mp4", "mpeg", "mpg", "3gp", 
        "mov", "m4v", "avi", "dat", "mkv", "flv", "vob", "ogv", "webm", 
        "ts", "mts", "m2ts", "divx", "xvid", "swf", "f4v", "f4p", "f4a", "f4b"
    }
    
    descriptions = []
    for url in urls:
        try:
            # æ£€æŸ¥URLæ˜¯å¦ä¸ºæ”¯æŒçš„è§†é¢‘æ ¼å¼
            url_lower = url.lower()
            is_video = any(url_lower.endswith(f".{fmt}") for fmt in VIDEO_FORMATS) or any(f".{fmt}?" in url_lower for fmt in VIDEO_FORMATS)
            
            if not is_video:
                print(f"[DEBUG] URLæ ¼å¼æ£€æŸ¥å¤±è´¥: {url}")
                descriptions.append(f"[éè§†é¢‘æ ¼å¼æˆ–æ ¼å¼ä¸æ”¯æŒ: {url}]")
                continue
            
            print(f"ğŸ¬ å¼€å§‹ä¸“ä¸šè§†é¢‘åˆ†æ: {url}")
            
            # æ–¹æ¡ˆ1ï¼šå¤šå¸§è§†é¢‘åˆ†æï¼ˆäº‘å¹³å°å‹å¥½ï¼‰
            try:
                description = await _analyze_video_multiframe(url)
                descriptions.append(description)
                
            except Exception as multiframe_error:
                print(f"âš ï¸ å¤šå¸§è§†é¢‘åˆ†æå¤±è´¥: {multiframe_error}")
                
                # æ–¹æ¡ˆ2ï¼šç›´æ¥URLåˆ†æï¼ˆé™çº§ï¼‰
                try:
                    description = await _analyze_video_url_direct(url)
                    descriptions.append(description)
                    
                except Exception as direct_error:
                    print(f"âš ï¸ ç›´æ¥URLåˆ†æå¤±è´¥: {direct_error}")
                    
                    # æ–¹æ¡ˆ3ï¼šæ™ºèƒ½URLåˆ†æ
                    try:
                        description = await _analyze_video_url_intelligent(url)
                        descriptions.append(description)
                        
                    except Exception as intelligent_error:
                        print(f"âš ï¸ æ™ºèƒ½URLåˆ†æå¤±è´¥: {intelligent_error}")
                        
                        # æ–¹æ¡ˆ4ï¼šé™çº§å¤„ç† - åŸºæœ¬ä¿¡æ¯
                        filename = url.split('/')[-1].split('?')[0] if '/' in url else url
                        file_extension = filename.split('.')[-1].lower() if '.' in filename else "æœªçŸ¥æ ¼å¼"
                        description = f"è§†é¢‘æ–‡ä»¶ï¼š{filename}ï¼ˆ{file_extension}æ ¼å¼ï¼‰ã€‚å½“å‰ç¯å¢ƒé™åˆ¶ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†çš„è§†é¢‘å†…å®¹åˆ†æã€‚"
                        descriptions.append(description)
            
        except Exception as e:
            description = f"[è§†é¢‘å¤„ç†å¤±è´¥: {e}]"
            descriptions.append(description)
    
    return descriptions

async def _analyze_video_multiframe(video_url: str) -> str:
    """å¤šå¸§è§†é¢‘åˆ†æ - æµå¼ä¸‹è½½è§†é¢‘ï¼Œæå–å¤šä¸ªå…³é”®å¸§å’ŒéŸ³é¢‘ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
    print(f"ğŸ¬ å¼€å§‹å¤šå¸§è§†é¢‘åˆ†æ: {video_url}")
    
    # ç”Ÿæˆå”¯ä¸€è§†é¢‘ID
    video_id = generate_video_id(video_url)
    print(f"ğŸ“‹ è§†é¢‘ID: {video_id}")
    
    try:
        # 1. æµå¼ä¸‹è½½è§†é¢‘æ•°æ®åˆ°å†…å­˜
        video_data = await _download_video_to_memory(video_url)
        video_size_mb = len(video_data) / (1024 * 1024)
        print(f"âœ… è§†é¢‘æ•°æ®ä¸‹è½½å®Œæˆï¼Œå¤§å°: {video_size_mb:.2f} MB")
        
        # æ£€æŸ¥è§†é¢‘å¤§å°ï¼Œé¿å…å¤„ç†è¿‡å¤§çš„æ–‡ä»¶
        if video_size_mb > 100:  # è¶…è¿‡100MBçš„è§†é¢‘
            print(f"âš ï¸ è§†é¢‘æ–‡ä»¶è¿‡å¤§({video_size_mb:.2f}MB)ï¼Œä½¿ç”¨é™çº§å¤„ç†")
            return await _analyze_video_url_direct(video_url)
        
        # 2. æå–å¤šä¸ªå…³é”®å¸§ï¼ˆæ¯ç§’1-2å¸§ï¼‰
        frame_images = await _extract_frames_from_memory(video_data, video_id)
        print(f"âœ… æå–äº† {len(frame_images)} ä¸ªå…³é”®å¸§")
        
        # 3. æå–éŸ³é¢‘æ•°æ®
        audio_data = await _extract_audio_from_memory(video_data, video_id)
        audio_size_mb = len(audio_data) / (1024 * 1024) if audio_data else 0
        print(f"âœ… éŸ³é¢‘æ•°æ®æå–å®Œæˆï¼Œå¤§å°: {audio_size_mb:.2f} MB")
        
        # 4. ä½¿ç”¨ aihubmix o4-mini åˆ†æå¤šä¸ªå…³é”®å¸§
        frame_descriptions = []
        if frame_images:
            try:
                frame_descriptions = await _analyze_frames_with_aihubmix(frame_images, video_id)
                print(f"âœ… å…³é”®å¸§åˆ†æå®Œæˆï¼Œå…± {len(frame_descriptions)} ä¸ªæè¿°")
            except Exception as frame_error:
                print(f"âš ï¸ å…³é”®å¸§åˆ†æå¤±è´¥: {frame_error}")
                frame_descriptions = [f"ç¬¬{i+1}å¸§ï¼šåˆ†æå¤±è´¥" for i in range(min(len(frame_images), 5))]
        
        # 5. ä½¿ç”¨ OpenAI Whisper è½¬å½•éŸ³é¢‘
        audio_transcription = ""
        if audio_data:
            try:
                audio_transcription = await _transcribe_audio_from_memory(audio_data, video_id)
                print(f"âœ… éŸ³é¢‘è½¬å½•å®Œæˆ")
            except Exception as audio_error:
                print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥: {audio_error}")
                audio_transcription = "æ— æ³•æå–éŸ³é¢‘å†…å®¹"
        
        # 6. ç»¼åˆå¤šæ¨¡æ€ä¿¡æ¯ç”Ÿæˆè§†é¢‘æè¿°
        try:
            result = await _synthesize_multiframe_video_description(frame_descriptions, audio_transcription, video_url, video_id)
        except Exception as synthesis_error:
            print(f"âš ï¸ ç»¼åˆæè¿°ç”Ÿæˆå¤±è´¥: {synthesis_error}")
            # é™çº§å¤„ç†
            frame_summary = "ï¼›".join(frame_descriptions[:3]) if frame_descriptions else "æ— æ³•æå–è§†é¢‘å¸§"
            audio_summary = audio_transcription if audio_transcription != "æ— æ³•æå–éŸ³é¢‘å†…å®¹" else "æ— éŸ³é¢‘"
            result = f"ğŸ¬ è§†é¢‘å†…å®¹ï¼š{frame_summary}ã€‚éŸ³é¢‘å†…å®¹ï¼š{audio_summary}"
        
        # 7. ä¸»åŠ¨æ¸…ç†å¤§å†…å­˜å¯¹è±¡ï¼ˆè™½ç„¶Pythonä¼šè‡ªåŠ¨æ¸…ç†ï¼Œä½†æ˜¾å¼æ¸…ç†æ›´å®‰å…¨ï¼‰
        del video_data
        del frame_images
        del audio_data
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        print(f"âœ… å†…å­˜æ¸…ç†å®Œæˆï¼Œè§†é¢‘ID: {video_id}")
        return result
        
    except Exception as e:
        print(f"âŒ å¤šå¸§è§†é¢‘åˆ†æå¤±è´¥: {e}")
        # ç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿæ¸…ç†å†…å­˜
        try:
            import gc
            gc.collect()
        except:
            pass
        raise

async def _analyze_video_url_direct(video_url: str) -> str:
    """ç›´æ¥åˆ†æè§†é¢‘URLï¼Œä½¿ç”¨aihubmix o4-miniå’ŒOpenAI Whisperï¼ˆçº¯å†…å­˜å¤„ç†ï¼‰"""
    import asyncio
    print(f"ğŸ”§ ç›´æ¥åˆ†æè§†é¢‘URL: {video_url}")
    
    try:
        # æ–¹æ¡ˆ1ï¼šå°è¯•ä½¿ç”¨ aihubmix o4-mini åˆ†æè§†é¢‘ç”»é¢
        try:
            # å¼‚æ­¥è·å–API keyï¼Œé¿å…é˜»å¡
            aihubmix_api_key = await asyncio.to_thread(os.getenv, "AIHUBMIX_API_KEY")
            print(f"[DEBUG] è·å–AIHUBMIX_API_KEY: {aihubmix_api_key[:10] if aihubmix_api_key else 'None'}...")
            if aihubmix_api_key:
                from openai import AsyncOpenAI
                aihubmix_client = AsyncOpenAI(
                    api_key=aihubmix_api_key,
                    base_url="https://aihubmix.com/v1"
                )
                
                # ä½¿ç”¨ image_url å¤„ç†è§†é¢‘ï¼ˆå¯èƒ½åªçœ‹åˆ°ç¬¬ä¸€å¸§æˆ–ç¼©ç•¥å›¾ï¼‰
                response = await aihubmix_client.chat.completions.create(
                    model="o4-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "è¿™æ˜¯ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œè¯·è¯¦ç»†æè¿°ä½ çœ‹åˆ°çš„ç”»é¢å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€ç‰©ä½“ã€åŠ¨ä½œã€æ–‡å­—ã€å­—å¹•ã€é•œå¤´è¯­è¨€ç­‰ã€‚å¦‚æœåªèƒ½çœ‹åˆ°ç¬¬ä¸€å¸§ï¼Œè¯·è¯´æ˜è¿™æ˜¯è§†é¢‘çš„é™æ€ç”»é¢ï¼š"},
                                {"type": "image_url", "image_url": {"url": video_url}}
                            ]
                        }
                    ],
                    max_tokens=400
                )
                
                frame_description = response.choices[0].message.content.strip()
                print(f"âœ… aihubmixè§†é¢‘ç”»é¢åˆ†æå®Œæˆ")
                
                # æ–¹æ¡ˆ2ï¼šå°è¯•ä½¿ç”¨ OpenAI Whisper è½¬å½•éŸ³é¢‘
                audio_transcription = ""
                try:
                    # ä½¿ç”¨ç°æœ‰çš„ transcribe_audio_urls å‡½æ•°
                    audio_transcriptions = await transcribe_audio_urls([video_url])
                    if audio_transcriptions and not audio_transcriptions[0].startswith("[è¯­éŸ³è½¬å½•å¤±è´¥"):
                        audio_transcription = audio_transcriptions[0]
                        print(f"âœ… éŸ³é¢‘è½¬å½•å®Œæˆ")
                    else:
                        audio_transcription = "æ— æ³•æå–éŸ³é¢‘å†…å®¹"
                        print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥")
                except Exception as audio_error:
                    print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥: {audio_error}")
                    audio_transcription = "æ— æ³•æå–éŸ³é¢‘å†…å®¹"
                
                # æ–¹æ¡ˆ3ï¼šç»¼åˆç”Ÿæˆè§†é¢‘æè¿°
                return await _synthesize_video_description_simple(frame_description, audio_transcription, video_url)
                
        except Exception as aihubmix_error:
            print(f"âš ï¸ aihubmixåˆ†æå¤±è´¥: {aihubmix_error}")
        
        # æ–¹æ¡ˆ4ï¼šå°è¯•ä½¿ç”¨ OpenAI GPT-4o
        try:
            client = await get_openai_client()
            response = await client.chat.completions.create(
                model=_normalize_model_name_for_openrouter(_cfg.get("vision_model") or "z-ai/glm-4.5v"),
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "è¿™æ˜¯ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œè¯·è¯¦ç»†æè¿°ä½ çœ‹åˆ°çš„ç”»é¢å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€ç‰©ä½“ã€åŠ¨ä½œã€æ–‡å­—ã€å­—å¹•ã€é•œå¤´è¯­è¨€ç­‰ã€‚å¦‚æœåªèƒ½çœ‹åˆ°ç¬¬ä¸€å¸§ï¼Œè¯·è¯´æ˜è¿™æ˜¯è§†é¢‘çš„é™æ€ç”»é¢ï¼š"},
                            {"type": "image_url", "image_url": {"url": video_url}}
                        ]
                    }
                ],
                max_tokens=400
            )
            
            frame_description = response.choices[0].message.content.strip()
            print(f"âœ… OpenAIè§†é¢‘ç”»é¢åˆ†æå®Œæˆ")
            
            # å°è¯•éŸ³é¢‘è½¬å½•
            audio_transcription = ""
            try:
                audio_transcriptions = await transcribe_audio_urls([video_url])
                if audio_transcriptions and not audio_transcriptions[0].startswith("[è¯­éŸ³è½¬å½•å¤±è´¥"):
                    audio_transcription = audio_transcriptions[0]
                    print(f"âœ… éŸ³é¢‘è½¬å½•å®Œæˆ")
                else:
                    audio_transcription = "æ— æ³•æå–éŸ³é¢‘å†…å®¹"
                    print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥")
            except Exception as audio_error:
                print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥: {audio_error}")
                audio_transcription = "æ— æ³•æå–éŸ³é¢‘å†…å®¹"
            
            return await _synthesize_video_description_simple(frame_description, audio_transcription, video_url)
            
        except Exception as openai_error:
            print(f"âš ï¸ OpenAIåˆ†æå¤±è´¥: {openai_error}")
        
        # æ–¹æ¡ˆ5ï¼šæ™ºèƒ½URLåˆ†æ
        return await _analyze_video_url_intelligent(video_url)
        
    except Exception as e:
        print(f"âŒ URLç›´æ¥åˆ†æå¤±è´¥: {e}")
        raise

async def _analyze_video_url_intelligent(video_url: str) -> str:
    """æ™ºèƒ½åˆ†æè§†é¢‘URLï¼ŒåŸºäºURLç‰¹å¾æ¨æµ‹å†…å®¹"""
    print(f"ğŸ§  æ™ºèƒ½åˆ†æè§†é¢‘URL: {video_url}")
    
    # ä»URLä¸­æå–ä¿¡æ¯
    url_lower = video_url.lower()
    filename = video_url.split('/')[-1].split('?')[0] if '/' in video_url else video_url
    file_extension = filename.split('.')[-1].lower() if '.' in filename else "æœªçŸ¥æ ¼å¼"
    
    # åˆ†æURLç‰¹å¾
    analysis_parts = []
    
    # 1. æ–‡ä»¶æ ¼å¼åˆ†æ
    if file_extension in ["mp4", "mov", "avi", "mkv"]:
        analysis_parts.append(f"æ ‡å‡†è§†é¢‘æ ¼å¼ï¼ˆ{file_extension}ï¼‰")
    elif file_extension in ["3gp", "m4v"]:
        analysis_parts.append(f"ç§»åŠ¨è®¾å¤‡è§†é¢‘æ ¼å¼ï¼ˆ{file_extension}ï¼‰")
    elif file_extension in ["webm", "ogv"]:
        analysis_parts.append(f"ç½‘é¡µè§†é¢‘æ ¼å¼ï¼ˆ{file_extension}ï¼‰")
    else:
        analysis_parts.append(f"è§†é¢‘æ ¼å¼ï¼ˆ{file_extension}ï¼‰")
    
    # 2. æ–‡ä»¶ååˆ†æ
    if any(keyword in filename.lower() for keyword in ["video", "vid", "movie", "film"]):
        analysis_parts.append("æ–‡ä»¶ååŒ…å«è§†é¢‘ç›¸å…³å…³é”®è¯")
    
    # 3. URLè·¯å¾„åˆ†æ
    if "/wechat/" in url_lower:
        analysis_parts.append("æ¥è‡ªå¾®ä¿¡çš„è§†é¢‘æ–‡ä»¶")
    elif "/video/" in url_lower:
        analysis_parts.append("æ¥è‡ªè§†é¢‘ç›®å½•")
    elif "/media/" in url_lower:
        analysis_parts.append("æ¥è‡ªåª’ä½“ç›®å½•")
    
    # 4. æ—¶é—´æˆ³åˆ†æ
    import re
    timestamp_match = re.search(r'(\d{10,13})', filename)
    if timestamp_match:
        timestamp = timestamp_match.group(1)
        if len(timestamp) == 13:  # æ¯«ç§’æ—¶é—´æˆ³
            from datetime import datetime
            try:
                dt = datetime.fromtimestamp(int(timestamp) / 1000)
                analysis_parts.append(f"åˆ›å»ºæ—¶é—´ï¼š{dt.strftime('%Y-%m-%d %H:%M:%S')}")
            except:
                pass
    
    # 5. ç”Ÿæˆæ™ºèƒ½æè¿°
    if analysis_parts:
        description = f"è§†é¢‘æ–‡ä»¶ï¼š{filename}ã€‚ç‰¹å¾åˆ†æï¼š{'ï¼›'.join(analysis_parts)}ã€‚"
    else:
        description = f"è§†é¢‘æ–‡ä»¶ï¼š{filename}ï¼ˆ{file_extension}æ ¼å¼ï¼‰ã€‚"
    
    description += " å½“å‰ç¯å¢ƒé™åˆ¶ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†çš„è§†é¢‘å†…å®¹åˆ†æã€‚å¦‚éœ€å®Œæ•´åˆ†æï¼Œå»ºè®®ä½¿ç”¨æ”¯æŒè§†é¢‘å¤„ç†çš„ä¸“ä¸šAPIã€‚"
    
    return f"ğŸ¬ {description}"

async def _synthesize_video_description_simple(frame_description: str, audio_transcription: str, video_url: str) -> str:
    """ç»¼åˆè§†é¢‘ç”»é¢å’ŒéŸ³é¢‘ä¿¡æ¯ç”Ÿæˆç®€å•æè¿°"""
    
    # æ„å»ºç»¼åˆæç¤ºè¯
    prompt = f"""
# è§†é¢‘åˆ†æä»»åŠ¡
è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„è§†é¢‘æè¿°ï¼š

## è§†é¢‘ç”»é¢åˆ†æç»“æœï¼š
{frame_description}

## éŸ³é¢‘è½¬å½•å†…å®¹ï¼š
{audio_transcription if audio_transcription != "æ— æ³•æå–éŸ³é¢‘å†…å®¹" else "æ— éŸ³é¢‘å†…å®¹"}

## ä»»åŠ¡è¦æ±‚ï¼š
1. ç»“åˆç”»é¢å’ŒéŸ³é¢‘ä¿¡æ¯ï¼Œç”Ÿæˆè§†é¢‘çš„è¯¦ç»†æ¦‚è¿°
2. å¦‚æœåªèƒ½çœ‹åˆ°ç¬¬ä¸€å¸§ï¼Œè¯·è¯´æ˜è¿™æ˜¯è§†é¢‘çš„é™æ€ç”»é¢
3. çªå‡ºè§†é¢‘çš„æ ¸å¿ƒä¿¡æ¯å’Œå…³é”®æƒ…èŠ‚
4. ä¿æŒå®¢è§‚å‡†ç¡®ï¼Œä¸æ·»åŠ æ¨æµ‹å†…å®¹

## è¾“å‡ºè¦æ±‚ï¼š
- æ§åˆ¶åœ¨300å­—ä»¥å†…
- æ ¼å¼ï¼šå…ˆæè¿°ç”»é¢å†…å®¹ï¼Œå†ç»“åˆéŸ³é¢‘ä¿¡æ¯æ€»ç»“
"""

    try:
        # ä½¿ç”¨ç°æœ‰æ¨¡å‹ç”Ÿæˆç»¼åˆæè¿°
        response = await get_openai_client().chat.completions.create(
            model=_cfg.get("generation_model", _cfg.get("model_name", "gpt-4o-mini")),
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘åˆ†æå¸ˆï¼Œæ“…é•¿ç»“åˆè§†è§‰å’ŒéŸ³é¢‘ä¿¡æ¯è¿›è¡Œè§†é¢‘å†…å®¹åˆ†æã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=500,
            temperature=0.3
        )
        
        description = response.choices[0].message.content.strip()
        print(f"âœ… è§†é¢‘åˆ†æå®Œæˆ: {video_url}")
        return f"ğŸ¬ è§†é¢‘åˆ†æç»“æœï¼š{description}"
        
    except Exception as e:
        print(f"âš ï¸ è§†é¢‘æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        # é™çº§å¤„ç†ï¼šç®€å•æ‹¼æ¥
        return f"ğŸ¬ è§†é¢‘å†…å®¹ï¼š{frame_description}ã€‚éŸ³é¢‘å†…å®¹ï¼š{audio_transcription}"

async def _download_video_to_memory(video_url: str) -> bytes:
    """æµå¼ä¸‹è½½è§†é¢‘æ•°æ®åˆ°å†…å­˜"""
    async with aiohttp.ClientSession() as session:
        async with session.get(video_url) as response:
            if response.status == 200:
                video_data = await response.read()
                return video_data
            else:
                raise Exception(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {response.status}")

async def _extract_frames_from_memory(video_data: bytes, video_id: str) -> List[bytes]:
    """ä»å†…å­˜ä¸­çš„è§†é¢‘æ•°æ®æå–å…³é”®å¸§"""
    try:
        # å°è¯•ä½¿ç”¨ moviepyï¼ˆæ¨èï¼‰
        try:
            return await _extract_frames_with_moviepy(video_data, video_id)
        except ImportError:
            print("âš ï¸ moviepyæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨opencv-python")
        except Exception as e:
            print(f"âš ï¸ moviepyå¤„ç†å¤±è´¥: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ¡ˆ")
        
        # å°è¯•ä½¿ç”¨ opencv-python
        try:
            return await _extract_frames_with_opencv(video_data, video_id)
        except ImportError:
            print("âš ï¸ opencv-pythonæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨imageio")
        except Exception as e:
            print(f"âš ï¸ opencv-pythonå¤„ç†å¤±è´¥: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ¡ˆ")
        
        # å°è¯•ä½¿ç”¨ imageio
        try:
            return await _extract_frames_with_imageio(video_data, video_id)
        except ImportError:
            print("âš ï¸ imageioæœªå®‰è£…ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
        except Exception as e:
            print(f"âš ï¸ imageioå¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
        
        # é™çº§æ–¹æ¡ˆï¼šåªæä¾›åŸºæœ¬ä¿¡æ¯
        raise Exception("æ‰€æœ‰Pythonè§†é¢‘å¤„ç†åŒ…éƒ½ä¸å¯ç”¨ï¼Œè¯·å®‰è£…moviepyæˆ–opencv-python")
        
    except Exception as e:
        print(f"âŒ è§†é¢‘å¸§æå–å¤±è´¥: {e}")
        raise

async def _extract_frames_with_moviepy(video_data: bytes, video_id: str) -> List[bytes]:
    """ä½¿ç”¨moviepyä»å†…å­˜æ•°æ®æå–å…³é”®å¸§ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    import io
    import asyncio
    import tempfile
    import os
    
    print(f"ğŸ¬ ä½¿ç”¨moviepyå¤„ç†è§†é¢‘: {video_id}")
    
    # å°†åŒæ­¥æ“ä½œç§»åˆ°çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
    def _extract_frames_sync(video_data: bytes, video_id: str) -> List[bytes]:
        from moviepy.editor import VideoFileClip
        import cv2
        import numpy as np
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
        temp_file_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix='.mp4', prefix=f"{video_id}_", delete=False) as temp_file:
                temp_file.write(video_data)
                temp_file_path = temp_file.name
            
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶: {temp_file_path}")
            
            # åŠ è½½è§†é¢‘
            video = VideoFileClip(temp_file_path)
            duration = video.duration
            fps = video.fps
            
            # æå–å…³é”®å¸§ï¼ˆæ¯ç§’1å¸§ï¼‰
            frame_interval = int(fps)  # æ¯ç§’1å¸§
            frame_images = []
            
            # ä½¿ç”¨æ­£ç¡®çš„æ–¹å¼è·å–å¸§
            for i in range(0, int(duration * fps), frame_interval):
                try:
                    # è·å–æŒ‡å®šæ—¶é—´çš„å¸§
                    frame = video.get_frame(i / fps)
                    # è½¬æ¢ä¸ºJPEGæ ¼å¼çš„bytes
                    _, buffer = cv2.imencode('.jpg', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
                    frame_images.append(buffer.tobytes())
                except Exception as e:
                    print(f"âš ï¸ æå–ç¬¬{i}å¸§å¤±è´¥: {e}")
                    continue
            
            video.close()
            return frame_images
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            _safe_delete_temp_file(temp_file_path)
    
    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
    frame_images = await asyncio.to_thread(_extract_frames_sync, video_data, video_id)
    print(f"âœ… ä½¿ç”¨moviepyæå–äº† {len(frame_images)} ä¸ªå…³é”®å¸§")
    return frame_images

async def _extract_frames_with_opencv(video_data: bytes, video_id: str) -> List[bytes]:
    """ä½¿ç”¨opencv-pythonä»å†…å­˜æ•°æ®æå–å…³é”®å¸§ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    import io
    import asyncio
    import tempfile
    import os
    
    print(f"ğŸ¬ ä½¿ç”¨opencv-pythonå¤„ç†è§†é¢‘: {video_id}")
    
    # å°†åŒæ­¥æ“ä½œç§»åˆ°çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
    def _extract_frames_sync(video_data: bytes, video_id: str) -> List[bytes]:
        import cv2
        import numpy as np
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
        temp_file_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix='.mp4', prefix=f"{video_id}_", delete=False) as temp_file:
                temp_file.write(video_data)
                temp_file_path = temp_file.name
            
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶: {temp_file_path}")
            
            # ä½¿ç”¨opencvè¯»å–è§†é¢‘
            cap = cv2.VideoCapture(temp_file_path)
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            frame_interval = int(fps)  # æ¯ç§’1å¸§
            frame_images = []
            
            for i in range(0, total_frames, frame_interval):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                if ret:
                    # è½¬æ¢ä¸ºJPEGæ ¼å¼çš„bytes
                    _, buffer = cv2.imencode('.jpg', frame)
                    frame_images.append(buffer.tobytes())
            
            cap.release()
            return frame_images
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            _safe_delete_temp_file(temp_file_path)
    
    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
    frame_images = await asyncio.to_thread(_extract_frames_sync, video_data, video_id)
    print(f"âœ… ä½¿ç”¨opencv-pythonæå–äº† {len(frame_images)} ä¸ªå…³é”®å¸§")
    return frame_images

async def _extract_frames_with_imageio(video_data: bytes, video_id: str) -> List[bytes]:
    """ä½¿ç”¨imageioä»å†…å­˜æ•°æ®æå–å…³é”®å¸§ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    import io
    import asyncio
    import tempfile
    import os
    
    print(f"ğŸ¬ ä½¿ç”¨imageioå¤„ç†è§†é¢‘: {video_id}")
    
    # å°†åŒæ­¥æ“ä½œç§»åˆ°çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
    def _extract_frames_sync(video_data: bytes, video_id: str) -> List[bytes]:
        import imageio
        import cv2
        import numpy as np
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
        temp_file_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix='.mp4', prefix=f"{video_id}_", delete=False) as temp_file:
                temp_file.write(video_data)
                temp_file_path = temp_file.name
            
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶: {temp_file_path}")
            
            reader = imageio.get_reader(temp_file_path)
            fps = reader.get_meta_data()['fps']
            total_frames = reader.get_length()
            
            frame_interval = int(fps)  # æ¯ç§’1å¸§
            frame_images = []
            
            for i in range(0, total_frames, frame_interval):
                try:
                    frame = reader.get_data(i)
                    # è½¬æ¢ä¸ºJPEGæ ¼å¼çš„bytes
                    _, buffer = cv2.imencode('.jpg', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
                    frame_images.append(buffer.tobytes())
                except IndexError:
                    break
            
            reader.close()
            return frame_images
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            _safe_delete_temp_file(temp_file_path)
    
    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
    frame_images = await asyncio.to_thread(_extract_frames_sync, video_data, video_id)
    print(f"âœ… ä½¿ç”¨imageioæå–äº† {len(frame_images)} ä¸ªå…³é”®å¸§")
    return frame_images

async def _extract_audio_from_memory(video_data: bytes, video_id: str) -> bytes:
    """ä»å†…å­˜ä¸­çš„è§†é¢‘æ•°æ®æå–éŸ³é¢‘"""
    try:
        # å°è¯•ä½¿ç”¨ moviepy
        try:
            return await _extract_audio_with_moviepy(video_data, video_id)
        except ImportError:
            print("âš ï¸ moviepyæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨pydub")
        except Exception as e:
            print(f"âš ï¸ moviepyéŸ³é¢‘æå–å¤±è´¥: {e}ï¼Œå°è¯•å…¶ä»–æ–¹æ¡ˆ")
        
        # å°è¯•ä½¿ç”¨ pydub
        try:
            return await _extract_audio_with_pydub(video_data, video_id)
        except ImportError:
            print("âš ï¸ pydubæœªå®‰è£…ï¼Œæ— æ³•æå–éŸ³é¢‘")
        except Exception as e:
            print(f"âš ï¸ pydubéŸ³é¢‘æå–å¤±è´¥: {e}")
        
        return None
        
    except Exception as e:
        print(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {e}")
        return None

async def _extract_audio_with_moviepy(video_data: bytes, video_id: str) -> bytes:
    """ä½¿ç”¨moviepyä»å†…å­˜æ•°æ®æå–éŸ³é¢‘ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    import io
    import asyncio
    import tempfile
    import os
    
    print(f"ğŸµ ä½¿ç”¨moviepyæå–éŸ³é¢‘: {video_id}")
    
    # å°†åŒæ­¥æ“ä½œç§»åˆ°çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
    def _extract_audio_sync(video_data: bytes, video_id: str) -> bytes:
        from moviepy.editor import VideoFileClip
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
        temp_file_path = None
        audio_temp_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix='.mp4', prefix=f"{video_id}_", delete=False) as temp_file:
                temp_file.write(video_data)
                temp_file_path = temp_file.name
            
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶: {temp_file_path}")
            
            # åŠ è½½è§†é¢‘
            video = VideoFileClip(temp_file_path)
            audio = video.audio
            
            if audio is not None:
                # åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
                with tempfile.NamedTemporaryFile(suffix='.mp3', prefix=f"{video_id}_audio_", delete=False) as audio_temp_file:
                    audio_temp_path = audio_temp_file.name
                
                print(f"ğŸ“ åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {audio_temp_path}")
                
                # æå–éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
                audio.write_audiofile(audio_temp_path, verbose=False, logger=None)
                
                # è¯»å–éŸ³é¢‘æ•°æ®
                with open(audio_temp_path, 'rb') as f:
                    audio_data = f.read()
                
                return audio_data
            else:
                return None
        finally:
            # ç¡®ä¿æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            _safe_delete_temp_file(temp_file_path)
            
            _safe_delete_temp_file(audio_temp_path)
    
    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
    audio_data = await asyncio.to_thread(_extract_audio_sync, video_data, video_id)
    if audio_data:
        print(f"âœ… éŸ³é¢‘æå–å®Œæˆï¼Œå¤§å°: {len(audio_data)} bytes")
    else:
        print("âš ï¸ è§†é¢‘ä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“")
    return audio_data

async def _extract_audio_with_pydub(video_data: bytes, video_id: str) -> bytes:
    """ä½¿ç”¨pydubä»å†…å­˜æ•°æ®æå–éŸ³é¢‘ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    import io
    import asyncio
    import tempfile
    import os
    
    print(f"ğŸµ ä½¿ç”¨pydubæå–éŸ³é¢‘: {video_id}")
    
    # å°†åŒæ­¥æ“ä½œç§»åˆ°çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
    def _extract_audio_sync(video_data: bytes, video_id: str) -> bytes:
        from pydub import AudioSegment
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
        temp_file_path = None
        audio_temp_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix='.mp4', prefix=f"{video_id}_", delete=False) as temp_file:
                temp_file.write(video_data)
                temp_file_path = temp_file.name
            
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶: {temp_file_path}")
            
            # åŠ è½½éŸ³é¢‘
            audio = AudioSegment.from_file(temp_file_path)
            
            # åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨å”¯ä¸€IDå‘½å
            with tempfile.NamedTemporaryFile(suffix='.mp3', prefix=f"{video_id}_audio_", delete=False) as audio_temp_file:
                audio_temp_path = audio_temp_file.name
            
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {audio_temp_path}")
            
            # å¯¼å‡ºä¸ºMP3æ ¼å¼
            audio.export(audio_temp_path, format="mp3")
            
            # è¯»å–éŸ³é¢‘æ•°æ®
            with open(audio_temp_path, 'rb') as f:
                audio_data = f.read()
            
            return audio_data
        finally:
            # ç¡®ä¿æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            _safe_delete_temp_file(temp_file_path)
            
            _safe_delete_temp_file(audio_temp_path)
    
    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
    audio_data = await asyncio.to_thread(_extract_audio_sync, video_data, video_id)
    print(f"âœ… éŸ³é¢‘æå–å®Œæˆï¼Œå¤§å°: {len(audio_data)} bytes")
    return audio_data

async def _analyze_frames_with_aihubmix(frame_images: List[bytes], video_id: str) -> List[str]:
    """ä½¿ç”¨aihubmix o4-miniåˆ†æå¤šä¸ªå…³é”®å¸§"""
    import asyncio
    client = await get_openai_client()
    # å¼‚æ­¥è·å–API keyï¼Œé¿å…é˜»å¡
    aihubmix_api_key = await asyncio.to_thread(os.getenv, "AIHUBMIX_API_KEY")
    print(f"[DEBUG] è·å–AIHUBMIX_API_KEY: {aihubmix_api_key[:10] if aihubmix_api_key else 'None'}...")
    if not aihubmix_api_key:
        print("âš ï¸ æœªé…ç½®AIHUBMIX_API_KEYï¼Œä½¿ç”¨OpenAI GPT-4o")
        return await _analyze_frames_with_openai(frame_images, video_id)
    
    # from openai import AsyncOpenAI # This line is now redundant as client is global
    # aihubmix_client = AsyncOpenAI( # This line is now redundant as client is global
    #     api_key=aihubmix_api_key,
    #     base_url="https://aihubmix.com/v1"
    # )
    
    frame_descriptions = []
    
    # é™åˆ¶å¤„ç†å¸§æ•°ï¼Œé¿å…APIè°ƒç”¨è¿‡å¤š
    max_frames = min(len(frame_images), 5)  # æœ€å¤šå¤„ç†5å¸§
    
    for i, frame_data in enumerate(frame_images[:max_frames]):
        try:
            # ç”Ÿæˆå¸§ID
            frame_id = generate_frame_id(video_id, i)
            print(f"ğŸ” åˆ†æå¸§ {frame_id}")
            
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸ºbase64
            import base64
            frame_base64 = base64.b64encode(frame_data).decode('utf-8')
            frame_url = f"data:image/jpeg;base64,{frame_base64}"
            
            response = await client.chat.completions.create(
                model="o4-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": f"è¿™æ˜¯è§†é¢‘çš„ç¬¬{i+1}ä¸ªå…³é”®å¸§ï¼Œè¯·è¯¦ç»†æè¿°ç”»é¢å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€ç‰©ä½“ã€åŠ¨ä½œã€æ–‡å­—ã€å­—å¹•ã€é•œå¤´è¯­è¨€ç­‰ï¼š"},
                            {"type": "image_url", "image_url": {"url": frame_url}}
                        ]
                    }
                ],
                max_completion_tokens=200
            )
            
            description = response.choices[0].message.content.strip()
            frame_descriptions.append(f"ç¬¬{i+1}å¸§ï¼š{description}")
            print(f"âœ… å¸§ {frame_id} åˆ†æå®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ ç¬¬{i+1}å¸§åˆ†æå¤±è´¥: {e}")
            frame_descriptions.append(f"ç¬¬{i+1}å¸§ï¼šåˆ†æå¤±è´¥")
    
    return frame_descriptions

async def _analyze_frames_with_openai(frame_images: List[bytes], video_id: str) -> List[str]:
    """ä½¿ç”¨OpenAI GPT-4oåˆ†æå¤šä¸ªå…³é”®å¸§"""
    client = await get_openai_client()
    frame_descriptions = []
    
    # é™åˆ¶å¤„ç†å¸§æ•°ï¼Œé¿å…APIè°ƒç”¨è¿‡å¤š
    max_frames = min(len(frame_images), 5)  # æœ€å¤šå¤„ç†5å¸§
    
    for i, frame_data in enumerate(frame_images[:max_frames]):
        try:
            # ç”Ÿæˆå¸§ID
            frame_id = generate_frame_id(video_id, i)
            print(f"ğŸ” åˆ†æå¸§ {frame_id}")
            
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸ºbase64
            import base64
            frame_base64 = base64.b64encode(frame_data).decode('utf-8')
            frame_url = f"data:image/jpeg;base64,{frame_base64}"
            
            response = await client.chat.completions.create(
                model=_normalize_model_name_for_openrouter(_cfg.get("vision_model") or "z-ai/glm-4.5v"),
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": f"è¿™æ˜¯è§†é¢‘çš„ç¬¬{i+1}ä¸ªå…³é”®å¸§ï¼Œè¯·è¯¦ç»†æè¿°ç”»é¢å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€ç‰©ä½“ã€åŠ¨ä½œã€æ–‡å­—ã€å­—å¹•ã€é•œå¤´è¯­è¨€ç­‰ï¼š"},
                            {"type": "image_url", "image_url": {"url": frame_url}}
                        ]
                    }
                ],
                max_tokens=200
            )
            
            description = response.choices[0].message.content.strip()
            frame_descriptions.append(f"ç¬¬{i+1}å¸§ï¼š{description}")
            print(f"âœ… å¸§ {frame_id} åˆ†æå®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ ç¬¬{i+1}å¸§åˆ†æå¤±è´¥: {e}")
            frame_descriptions.append(f"ç¬¬{i+1}å¸§ï¼šåˆ†æå¤±è´¥")
    
    return frame_descriptions

async def _transcribe_audio_from_memory(audio_data: bytes, video_id: str) -> str:
    """ä»å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®è½¬å½•éŸ³é¢‘"""
    client = await get_openai_client()
    try:
        # ç”ŸæˆéŸ³é¢‘ID
        audio_id = generate_audio_id(video_id)
        print(f"ğŸµ å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_id}")
        
        # åˆ›å»ºå†…å­˜æ–‡ä»¶å¯¹è±¡
        audio_file = io.BytesIO(audio_data)
        audio_file.name = "audio.mp3"  # OpenAI SDKè¦æ±‚æœ‰name
        
        # ä½¿ç”¨promptæŒ‡å¯¼Whisperç›´æ¥è¾“å‡ºå‹ç¼©å†…å®¹
        prompt = "è¯·ç›´æ¥æå–è¿™æ®µè¯­éŸ³çš„æ ¸å¿ƒå†…å®¹ï¼Œæ§åˆ¶åœ¨200å­—ä»¥å†…ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€‚"
        
        if not os.getenv("OPENAI_API_KEY"):
            return "æ— æ³•æå–éŸ³é¢‘å†…å®¹"
        response = await client.audio.transcriptions.create(
            model=_cfg.get("whisper_model", "whisper-1"),
            file=audio_file,
            prompt=prompt,
            response_format="text"
        )
        
        # å½“ä½¿ç”¨ response_format="text" æ—¶ï¼ŒAPI ç›´æ¥è¿”å›å­—ç¬¦ä¸²
        transcribed_text = response.strip() if isinstance(response, str) else response.text.strip()
        
        # æ£€æŸ¥å­—æ•°ï¼Œå¦‚æœè¶…è¿‡150å­—å°±ç”¨GPTæç‚¼é‡è¦å†…å®¹
        if len(transcribed_text) > 150:
            print(f"ğŸµ è¯­éŸ³å†…å®¹è¿‡é•¿({len(transcribed_text)}å­—)ï¼Œä½¿ç”¨GPTæç‚¼é‡è¦å†…å®¹...")
            important_content = await extract_important_content(transcribed_text, max_length=100)
            print(f"âœ… è¯­éŸ³å†…å®¹å·²æç‚¼ï¼Œé•¿åº¦: {len(important_content)}å­—")
            return important_content
        else:
            print(f"âœ… è¯­éŸ³å†…å®¹å·²å¤„ç†ï¼Œé•¿åº¦: {len(transcribed_text)}å­—")
            return transcribed_text
            
    except Exception as e:
        print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
        return "æ— æ³•æå–éŸ³é¢‘å†…å®¹"

async def _synthesize_multiframe_video_description(frame_descriptions: List[str], audio_transcription: str, video_url: str, video_id: str) -> str:
    """ç»¼åˆå¤šå¸§è§†é¢‘ç”»é¢å’ŒéŸ³é¢‘ä¿¡æ¯ç”Ÿæˆè¯¦ç»†æè¿°"""
    
    print(f"ğŸ“ å¼€å§‹åˆæˆè§†é¢‘æè¿°: {video_id}")
    
    # æ„å»ºç»¼åˆæç¤ºè¯
    prompt = f"""
# è§†é¢‘åˆ†æä»»åŠ¡
è¯·åŸºäºä»¥ä¸‹å¤šå¸§ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„è§†é¢‘æè¿°ï¼š

## å…³é”®å¸§åˆ†æç»“æœï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰ï¼š
{chr(10).join(frame_descriptions) if frame_descriptions else "æ— æ³•æå–è§†é¢‘å¸§"}

## éŸ³é¢‘è½¬å½•å†…å®¹ï¼š
{audio_transcription if audio_transcription != "æ— æ³•æå–éŸ³é¢‘å†…å®¹" else "æ— éŸ³é¢‘å†…å®¹"}

## ä»»åŠ¡è¦æ±‚ï¼š
1. åˆ†ææ¯ä¸ªå…³é”®å¸§çš„ç”»é¢ä¿¡æ¯ï¼ŒåŒ…æ‹¬äººç‰©ã€ç‰©ä½“ã€åŠ¨ä½œã€æ–‡å­—ã€å­—å¹•ã€é•œå¤´è¯­è¨€ç­‰
2. å°†å…³é”®å¸§ä¿¡æ¯æŒ‰æ—¶é—´é¡ºåºä¸²è”èµ·æ¥ï¼Œç”Ÿæˆè§†é¢‘çš„è¯¦ç»†æ¦‚è¿°
3. ç»“åˆéŸ³é¢‘è½¬å½•å†…å®¹ï¼Œè¿˜åŸè¯¥ç‰‡æ®µçš„å®Œæ•´å‰§æƒ…
4. è¾“å‡ºæ ¼å¼ï¼šå…ˆæè¿°å„å…³é”®å¸§ï¼Œå†æ€»ç»“æ•´ä¸ªè§†é¢‘å†…å®¹

## è¾“å‡ºè¦æ±‚ï¼š
- æ§åˆ¶åœ¨400å­—ä»¥å†…
- ä¿æŒå®¢è§‚å‡†ç¡®ï¼Œä¸æ·»åŠ æ¨æµ‹å†…å®¹
- çªå‡ºè§†é¢‘çš„æ ¸å¿ƒä¿¡æ¯å’Œå…³é”®æƒ…èŠ‚
- ä½“ç°è§†é¢‘çš„æ—¶åºå˜åŒ–å’Œå‰§æƒ…å‘å±•
"""

    try:
        # ä½¿ç”¨ç°æœ‰æ¨¡å‹ç”Ÿæˆç»¼åˆæè¿°
        client = await get_openai_client()
        response = await client.chat.completions.create(
            model=_normalize_model_name_for_openrouter(_cfg.get("generation_model", _cfg.get("model_name", "gpt-4o-mini"))),
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘åˆ†æå¸ˆï¼Œæ“…é•¿ç»“åˆå¤šå¸§è§†è§‰å’ŒéŸ³é¢‘ä¿¡æ¯è¿›è¡Œè§†é¢‘å†…å®¹åˆ†æã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=600,
            temperature=0.3,
            timeout=30  # æ·»åŠ è¶…æ—¶è®¾ç½®
        )
        
        description = response.choices[0].message.content.strip()
        print(f"âœ… å¤šå¸§è§†é¢‘åˆ†æå®Œæˆ: {video_id}")
        return f"ğŸ¬ å¤šå¸§è§†é¢‘åˆ†æç»“æœï¼š{description}"
            
    except Exception as e:
        print(f"âš ï¸ å¤šå¸§è§†é¢‘æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        # é™çº§å¤„ç†ï¼šç®€å•æ‹¼æ¥
        frame_summary = "ï¼›".join(frame_descriptions[:3]) if frame_descriptions else "æ— æ³•æå–è§†é¢‘å¸§"
        audio_summary = audio_transcription if audio_transcription != "æ— æ³•æå–éŸ³é¢‘å†…å®¹" else "æ— éŸ³é¢‘"
        
        # å¦‚æœå¸§æè¿°ä¸ºç©ºï¼Œæä¾›åŸºæœ¬ä¿¡æ¯
        if not frame_descriptions or all("åˆ†æå¤±è´¥" in desc for desc in frame_descriptions):
            frame_summary = f"æˆåŠŸæå–äº†{len(frame_descriptions)}ä¸ªå…³é”®å¸§ï¼Œä½†åˆ†æå¤±è´¥"
        
        return f"ğŸ¬ è§†é¢‘å†…å®¹ï¼š{frame_summary}ã€‚éŸ³é¢‘å†…å®¹ï¼š{audio_summary}"

def _get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    try:
        import psutil
        process = psutil.Process()
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        return f"{memory_mb:.2f} MB"
    except ImportError:
        return "æœªçŸ¥ï¼ˆéœ€è¦å®‰è£…psutilï¼‰"

def _log_memory_usage(stage: str):
    """è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    memory_usage = _get_memory_usage()
    print(f"ğŸ“Š å†…å­˜ä½¿ç”¨æƒ…å†µ [{stage}]: {memory_usage}")

async def describe_webpage_urls(urls: List[str]) -> List[str]:
    """
    æŠ“å–å¹¶æç‚¼é€šç”¨ç½‘é¡µé“¾æ¥çš„ä¸»è¦å†…å®¹ï¼ˆæ”¯æŒå…¬ä¼—å·æ–‡ç« ç­‰ï¼‰ï¼Œç”¨äºåœ¨å¯¹è¯ä¸­ç†è§£é“¾æ¥å†…å®¹ã€‚

    - å¯¹æ¯ä¸ªURLå¹¶å‘ä¸‹è½½HTML
    - ä¼˜å…ˆæå– <article> / <main> / å…¬ä¼—å· #js_content çš„æ­£æ–‡
    - ç»“åˆ<title>ç”Ÿæˆç®€çŸ­æ‘˜è¦ï¼ˆçº¦180å­—ï¼‰
    - ç½‘ç»œ/è§£æå¤±è´¥æ—¶è¿”å›å¯è¯»çš„é”™è¯¯æç¤º
    """
    print("=" * 80)
    print("ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å¼€å§‹æ‰§è¡Œdescribe_webpage_urls")
    print("=" * 80)
    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] éœ€è¦å¤„ç†çš„ç½‘é¡µURLæ•°é‡: {len(urls)}")
    for i, url in enumerate(urls, 1):
        print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ç½‘é¡µ {i}: {url}")

    if not urls:
        print("ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ²¡æœ‰ç½‘é¡µURLéœ€è¦å¤„ç†ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []

    import aiohttp
    from bs4 import BeautifulSoup

    headers_base = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        ),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Cache-Control": "no-cache",
        "Pragma": "no-cache",
    }

    async def fetch_and_summarize(url: str) -> str:
        print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å¼€å§‹å¤„ç†ç½‘é¡µ: {url}")

        try:
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ­£åœ¨è®¾ç½®è¯·æ±‚å¤´...")
            # é’ˆå¯¹ç‰¹å®šåŸŸåæ·»åŠ é¢å¤–å¤´ï¼ˆä¾‹å¦‚å¾®ä¿¡å…¬ä¼—å·ï¼‰
            headers = dict(headers_base)
            if "mp.weixin.qq.com" in url:
                headers.update({
                    "Referer": "https://weixin.qq.com/",
                    "Upgrade-Insecure-Requests": "1",
                })
                print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ£€æµ‹åˆ°å¾®ä¿¡å…¬ä¼—å·ï¼Œæ·»åŠ ç‰¹æ®Šè¯·æ±‚å¤´")

            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ­£åœ¨å‘èµ·HTTPè¯·æ±‚...")
            async with aiohttp.ClientSession(headers=headers) as session:
                async with session.get(url, timeout=15) as resp:
                    status = resp.status
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] HTTPå“åº”çŠ¶æ€ç : {status}")

                    text_body = await resp.text(errors="ignore")
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] è·å–å“åº”å†…å®¹ï¼Œé•¿åº¦: {len(text_body)} å­—ç¬¦")

                    if status != 200 or ("ç¯å¢ƒå¼‚å¸¸" in text_body and "å»éªŒè¯" in text_body):
                        print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ£€æµ‹åˆ°å¼‚å¸¸å“åº”ï¼Œä½¿ç”¨Jina AIä»£ç†...")
                        # å…œåº•ï¼šä½¿ç”¨ Jina AI Reader ä»£ç†æ‹‰å–çº¯æ–‡æœ¬
                        proxy_url = f"https://r.jina.ai/{url}"
                        try:
                            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ­£åœ¨è°ƒç”¨ä»£ç†: {proxy_url}")
                            async with session.get(proxy_url, timeout=20) as proxy_resp:
                                proxy_status = proxy_resp.status
                                print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä»£ç†å“åº”çŠ¶æ€ç : {proxy_status}")

                                if proxy_resp.status == 200:
                                    proxy_text = await proxy_resp.text(errors="ignore")
                                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä»£ç†è·å–å†…å®¹æˆåŠŸï¼Œé•¿åº¦: {len(proxy_text)} å­—ç¬¦")
                                    # ä»£ç†è¿”å›å·²æ˜¯æ–‡æœ¬ï¼Œç›´æ¥è¿›å…¥åç»­æç‚¼
                                    html = f"<html><body><article>{proxy_text}</article></body></html>"
                                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä½¿ç”¨ä»£ç†å†…å®¹è¿›è¡Œè§£æ")
                                else:
                                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä»£ç†è°ƒç”¨å¤±è´¥: HTTP {proxy_status}")
                                    return f"[ç½‘é¡µè·å–å¤±è´¥: HTTP {status}ï¼Œä»£ç† {proxy_resp.status}]"
                        except Exception as proxy_err:
                            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä»£ç†è°ƒç”¨å¼‚å¸¸: {proxy_err}")
                            return f"[ç½‘é¡µè·å–å¤±è´¥: HTTP {status}ï¼Œä»£ç†å¼‚å¸¸: {proxy_err}]"
                    else:
                        # æ­£å¸¸HTML
                        html = text_body
                        print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä½¿ç”¨åŸå§‹HTMLå†…å®¹è¿›è¡Œè§£æ")
        except Exception as e:
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ç½‘é¡µè·å–å¼‚å¸¸: {e}")
            import traceback
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            return f"[ç½‘é¡µè·å–å¤±è´¥: {e}]"

        try:
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å¼€å§‹HTMLè§£æ...")
            soup = BeautifulSoup(html, "html.parser")
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] BeautifulSoupè§£æå®Œæˆ")

            # æ ‡é¢˜
            title = ""
            try:
                if soup.title and soup.title.get_text():
                    title = soup.title.get_text(strip=True)
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æå–åˆ°æ ‡é¢˜: {title}")
            except Exception as e:
                print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æå–æ ‡é¢˜å¤±è´¥: {e}")
                title = ""

            # é’ˆå¯¹å…¬ä¼—å·æ–‡ç« çš„ç‰¹åŒ–é€‰æ‹©å™¨
            content_node = None
            if "mp.weixin.qq.com" in url:
                content_node = soup.find(id="js_content") or soup.select_one("#js_content, .rich_media_content")
                if content_node:
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä½¿ç”¨å¾®ä¿¡å…¬ä¼—å·ä¸“ç”¨é€‰æ‹©å™¨æå–å†…å®¹")
                else:
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å¾®ä¿¡å…¬ä¼—å·ä¸“ç”¨é€‰æ‹©å™¨æœªæ‰¾åˆ°å†…å®¹")

            # é€šç”¨èŠ‚ç‚¹
            if content_node is None:
                content_node = soup.find("article") or soup.find("main")
                if content_node:
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ä½¿ç”¨é€šç”¨é€‰æ‹©å™¨(article/main)æå–å†…å®¹")
                else:
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] é€šç”¨é€‰æ‹©å™¨æœªæ‰¾åˆ°å†…å®¹ï¼Œä½¿ç”¨å…œåº•æ–¹æ³•")

            # å…œåº•ï¼šèšåˆå¸¸è§æ–‡æœ¬æ ‡ç­¾
            if content_node is None:
                parts = []
                for tag in soup.find_all(["h1", "h2", "h3", "p", "li"]):
                    text_piece = tag.get_text(" ", strip=True)
                    if text_piece:
                        parts.append(text_piece)
                content_text = "\n".join(parts)
                print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å…œåº•æ–¹æ³•æå–åˆ° {len(parts)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")
            else:
                content_text = content_node.get_text(" ", strip=True)

            # æ¸…ç†ç©ºç™½
            content_text = re.sub(r"\s+", " ", content_text).strip()
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ¸…ç†åå†…å®¹é•¿åº¦: {len(content_text)} å­—ç¬¦")

            if not content_text:
                print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æœªæå–åˆ°æœ‰æ•ˆå†…å®¹")
                return title or "[æœªèƒ½è§£æç½‘é¡µæ­£æ–‡]"

            # å†…å®¹è¿‡é•¿æ—¶æç‚¼è¦ç‚¹ï¼ˆ~180å­—ï¼‰
            summary = content_text
            max_len = 180
            if len(summary) > max_len:
                print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å†…å®¹è¿‡é•¿({len(summary)}å­—ç¬¦)ï¼Œæ­£åœ¨æç‚¼...")
                try:
                    summary = await extract_important_content(summary, max_length=max_len)
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] AIæç‚¼å®Œæˆï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
                except Exception as e:
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] AIæç‚¼å¤±è´¥ï¼Œä½¿ç”¨æˆªæ–­: {e}")
                    summary = summary[:max_len] + "..."
                    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æˆªæ–­å®Œæˆï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")

            if title:
                result = f"{title}ï¼š{summary}"
            else:
                result = summary

            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ç½‘é¡µå¤„ç†å®Œæˆï¼Œæœ€ç»ˆç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
            return result
        except Exception as e:
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ç½‘é¡µè§£æå¼‚å¸¸: {e}")
            import traceback
            print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            return f"[ç½‘é¡µè§£æå¤±è´¥: {e}]"

    # é¡ºåºå¤„ç†ä»¥æ§åˆ¶å¹¶å‘ï¼Œé¿å…å¤–éƒ¨ç«™ç‚¹é£æ§ï¼›å¦‚éœ€æ›´å¿«å¯åˆ‡æ¢ä¸ºgather
    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] å¼€å§‹é¡ºåºå¤„ç† {len(urls)} ä¸ªURL...")
    results: List[str] = []
    for i, u in enumerate(urls, 1):
        print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(urls)} ä¸ªURL: {u[:100]}...")
        desc = await fetch_and_summarize(u)
        results.append(desc)
        print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] ç¬¬ {i} ä¸ªURLå¤„ç†å®Œæˆï¼Œç»“æœé•¿åº¦: {len(desc)} å­—ç¬¦")

    print(f"ğŸŒ [DEBUG-å¤–éƒ¨é“¾æ¥è¯†åˆ«] æ‰€æœ‰ç½‘é¡µå¤„ç†å®Œæˆï¼Œå…± {len(results)} ä¸ªç»“æœ")
    return results

def _safe_delete_temp_file(file_path: str, max_retries: int = 3, delay: float = 0.1):
    """å®‰å…¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œé€‚ç”¨äºLangSmithéƒ¨ç½²ç¯å¢ƒ"""
    if not file_path or not os.path.exists(file_path):
        return
    
    for attempt in range(max_retries):
        try:
            # åœ¨LangSmithç¯å¢ƒä¸­ï¼Œæ–‡ä»¶å¯èƒ½è¢«çŸ­æš‚é”å®š
            import time
            time.sleep(delay * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
            
            os.unlink(file_path)
            print(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file_path}")
            return
        except Exception as e:
            if attempt == max_retries - 1:
                print(f"âš ï¸ æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {file_path}: {e}")
                # åœ¨LangSmithä¸­ï¼Œå¦‚æœæ— æ³•åˆ é™¤ï¼Œè®°å½•ä½†ç»§ç»­æ‰§è¡Œ
                print(f"ğŸ“ ä¸´æ—¶æ–‡ä»¶å°†åœ¨ç³»ç»Ÿæ¸…ç†æ—¶è‡ªåŠ¨åˆ é™¤: {file_path}")
            else:
                print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")

def _cleanup_temp_files(temp_files: list):
    """æ‰¹é‡æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    for file_path in temp_files:
        _safe_delete_temp_file(file_path)

async def get_audio_duration_ms(audio_url: str) -> Optional[int]:
    """è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰

    Args:
        audio_url: éŸ³é¢‘æ–‡ä»¶çš„URL

    Returns:
        int: éŸ³é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œè·å–å¤±è´¥æ—¶è¿”å›None
    """
    if not audio_url or not isinstance(audio_url, str):
        return None

    try:
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        timeout = aiohttp.ClientTimeout(total=30)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(audio_url) as response:
                if response.status != 200:
                    print(f"[AUDIO] ä¸‹è½½å¤±è´¥: HTTP {response.status}")
                    return None

                # è¯»å–éŸ³é¢‘æ•°æ®
                audio_data = await response.read()
                if not audio_data:
                    print("[AUDIO] ä¸‹è½½åˆ°çš„éŸ³é¢‘æ•°æ®ä¸ºç©º")
                    return None

        # æ–¹æ¡ˆ1ï¼šå°è¯•ä½¿ç”¨mutagenï¼ˆè½»é‡çº§ï¼Œæ— é˜»å¡è°ƒç”¨é—®é¢˜ï¼‰
        try:
            from mutagen.mp3 import MP3
            from mutagen import File
            from io import BytesIO

            def _get_duration_mutagen(data):
                try:
                    audio_file = BytesIO(data)
                    audio = File(audio_file)
                    if audio and hasattr(audio, 'info') and hasattr(audio.info, 'length'):
                        return int(audio.info.length * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                    return None
                except Exception as e:
                    print(f"[AUDIO] Mutagenè§£æå¤±è´¥: {e}")
                    return None

            import asyncio
            duration_ms = await asyncio.to_thread(_get_duration_mutagen, audio_data)

            if duration_ms is not None:
                print(f"[AUDIO] éŸ³é¢‘æ—¶é•¿: {duration_ms}æ¯«ç§’ (ä½¿ç”¨mutagen)")
                return duration_ms

        except ImportError:
            print("[AUDIO] æœªå®‰è£…mutagenåº“ï¼Œå°è¯•ä½¿ç”¨pydub")

        # æ–¹æ¡ˆ2ï¼šä½¿ç”¨pydubï¼ˆå¦‚æœmutagenä¸å¯ç”¨ï¼‰
        try:
            from pydub import AudioSegment
            from io import BytesIO

            def _get_audio_duration_pydub(audio_data):
                try:
                    audio_file = BytesIO(audio_data)
                    audio = AudioSegment.from_file(audio_file)
                    if audio is None:
                        return None
                    return len(audio)
                except Exception as e:
                    print(f"[AUDIO] Pydubè§£æå¤±è´¥: {e}")
                    return None

            duration_ms = await asyncio.to_thread(_get_audio_duration_pydub, audio_data)

            if duration_ms is not None:
                print(f"[AUDIO] éŸ³é¢‘æ—¶é•¿: {duration_ms}æ¯«ç§’ (ä½¿ç”¨pydub)")
                return duration_ms

        except ImportError:
            print("[AUDIO] æœªå®‰è£…pydubåº“")
        except Exception as e:
            print(f"[AUDIO] Pydubå¼‚æ­¥æ‰§è¡Œå¤±è´¥: {e}")

        # æ–¹æ¡ˆ3ï¼šç®€å•ä¼°ç®—ï¼ˆåŸºäºæ–‡ä»¶å¤§å°ç²—ç•¥ä¼°ç®—ï¼‰
        try:
            # MP3å¹³å‡æ¯”ç‰¹ç‡ä¼°ç®—ï¼ˆç²—ç•¥ï¼‰
            file_size_kb = len(audio_data) / 1024
            # å‡è®¾å¹³å‡128kbpsï¼Œè®¡ç®—æ—¶é•¿ï¼ˆç§’ï¼‰
            estimated_seconds = (file_size_kb * 8) / 128
            estimated_ms = int(estimated_seconds * 1000)

            print(f"[AUDIO] éŸ³é¢‘æ—¶é•¿ä¼°ç®—: {estimated_ms}æ¯«ç§’ (åŸºäºæ–‡ä»¶å¤§å°)")
            return estimated_ms

        except Exception as e:
            print(f"[AUDIO] ä¼°ç®—æ—¶é•¿å¤±è´¥: {e}")

        print("[AUDIO] æ‰€æœ‰æ–¹æ³•éƒ½æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿")
        return None

    except Exception as e:
        print(f"[AUDIO] è·å–éŸ³é¢‘æ—¶é•¿å¼‚å¸¸: {e}")
        return None

# =====================
# å›¾ç‰‡ææ–™æŸ¥è¯¢åŠŸèƒ½
# =====================

async def query_material_images(thread_id: str, assistant_id: str = None) -> List[dict]:
    """
    æŸ¥è¯¢å¯ç”¨çš„å¤šåª’ä½“ææ–™ - è·å–æ‰€æœ‰ç±»å‹

    Args:
        thread_id: å¯¹è¯çº¿ç¨‹ID
        assistant_id: åŠ©æ‰‹IDï¼ˆå¯é€‰ï¼‰

    Returns:
        List[dict]: æ‰€æœ‰ææ–™çš„åˆ—è¡¨ï¼Œæ ¼å¼ä¸º[{"id": str, "name": str, "materialType": int, "content": str}]
    """
    try:
        # æ„å»ºæŸ¥è¯¢URL
        base_url = os.getenv("BACKEND_URL", "")
        url = f"{base_url}"

        # æ„å»ºè¯·æ±‚æ•°æ® - ä½¿ç”¨type=0è·å–æ‰€æœ‰ç±»å‹
        payload = {
            "threadId": thread_id,
            "page": 1,
            "limit": 50,
            "type": 0,  # è·å–æ‰€æœ‰ç±»å‹çš„ç´ æ
            "flag": 0
        }

        print(f"[MATERIAL_QUERY] ===== å‘é€ç´ ææŸ¥è¯¢è¯·æ±‚ =====")
        print(f"[MATERIAL_QUERY] è¯·æ±‚URL: {url}")
        print(f"[MATERIAL_QUERY] è¯·æ±‚æ–¹æ³•: POST")
        print(f"[MATERIAL_QUERY] è¯·æ±‚ä½“ (JSON):")
        import json
        print(json.dumps(payload, indent=2, ensure_ascii=False))
        print(f"[MATERIAL_QUERY] è¯·æ±‚å¤´: Content-Type: application/json")
        print(f"[MATERIAL_QUERY] è¶…æ—¶è®¾ç½®: 30ç§’")
        print(f"[MATERIAL_QUERY] ===== è¯·æ±‚å‘é€å®Œæˆ =====")

        # å‘é€è¯·æ±‚
        timeout = aiohttp.ClientTimeout(total=30)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(url, json=payload) as response:
                print(f"[MATERIAL_QUERY] ===== æ¥æ”¶å“åº” =====")
                print(f"[MATERIAL_QUERY] å“åº”çŠ¶æ€ç : {response.status}")
                print(f"[MATERIAL_QUERY] å“åº”å¤´: {dict(response.headers)}")

                if response.status != 200:
                    print(f"[MATERIAL_QUERY] âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status}")
                    response_text = await response.text()
                    print(f"[MATERIAL_QUERY] é”™è¯¯å“åº”å†…å®¹: {response_text}")
                    print(f"[MATERIAL_QUERY] ===== å“åº”å¤„ç†å®Œæˆ =====")
                    return []

                data = await response.json()
                print(f"[MATERIAL_QUERY] å“åº”ä½“ (JSON):")
                print(json.dumps(data, indent=2, ensure_ascii=False))
                print(f"[MATERIAL_QUERY] APIå“åº”çŠ¶æ€ç : {data.get('code', 'unknown')}")

                if data.get('code') != 200:
                    print(f"[MATERIAL_QUERY] âŒ APIè¿”å›ä¸šåŠ¡é”™è¯¯: {data.get('msg', 'unknown error')}")
                    print(f"[MATERIAL_QUERY] ===== å“åº”å¤„ç†å®Œæˆ =====")
                    return []

                materials = data.get('data', [])
                print(f"[MATERIAL_QUERY] è·å–åˆ° {len(materials)} ä¸ªææ–™")

                # ä¿ç•™å®Œæ•´çš„ææ–™ä¿¡æ¯ï¼ŒåŒ…æ‹¬materialType
                filtered_materials = []
                print(f"[MATERIAL_QUERY] ===== å¤„ç†ææ–™æ•°æ® =====")
                for i, material in enumerate(materials):
                    material_id = material.get('id', '').strip()
                    name = material.get('name', '').strip()
                    material_type = material.get('materialType', 2)  # é»˜è®¤å›¾ç‰‡ç±»å‹
                    content = material.get('content', '')

                    print(f"[MATERIAL_QUERY] ææ–™ {i+1}:")
                    print(f"  - ID: {material_id}")
                    print(f"  - åç§°: {name}")
                    print(f"  - ç±»å‹: {material_type}")
                    print(f"  - å†…å®¹: {content[:50]}{'...' if len(content) > 50 else ''}")

                    if material_id and name:
                        filtered_materials.append({
                            "id": material_id,
                            "name": name,
                            "materialType": material_type,
                            "content": content
                        })
                    else:
                        print(f"  âŒ è·³è¿‡æ— æ•ˆææ–™ (ç¼ºå°‘IDæˆ–åç§°)")

                print(f"[MATERIAL_QUERY] ===== æ•°æ®å¤„ç†å®Œæˆ =====")
                print(f"[MATERIAL_QUERY] è¿‡æ»¤åå‰©ä½™ {len(filtered_materials)} ä¸ªæœ‰æ•ˆææ–™")
                print(f"[MATERIAL_QUERY] ===== ç´ ææŸ¥è¯¢æµç¨‹ç»“æŸ =====")
                return filtered_materials

    except Exception as e:
        print(f"[MATERIAL_QUERY] ===== å‘ç”Ÿå¼‚å¸¸ =====")
        print(f"[MATERIAL_QUERY] âŒ æŸ¥è¯¢ææ–™å¼‚å¸¸: {e}")
        import traceback
        print(f"[MATERIAL_QUERY] å¼‚å¸¸å †æ ˆ:")
        print(traceback.format_exc())
        print(f"[MATERIAL_QUERY] ===== å¼‚å¸¸å¤„ç†å®Œæˆ =====")
        return []

async def select_relevant_meterials(materials: List[dict], user_message: str, context_messages: List = None) -> Optional[dict]:
    """
    ä½¿ç”¨AIåˆ¤æ–­å½“å‰è¯­å¢ƒéœ€è¦å‘é€å“ªä¸ªææ–™ï¼ˆæ”¯æŒæ‰€æœ‰ç±»å‹ï¼‰

    Args:
        materials: å¯ç”¨çš„ææ–™åˆ—è¡¨ï¼ˆåŒ…å«æ‰€æœ‰ç±»å‹ï¼šå›¾ç‰‡ã€è§†é¢‘ã€å¡ç‰‡é“¾æ¥ç­‰ï¼‰
        user_message: ç”¨æˆ·æ¶ˆæ¯
        context_messages: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰

    Returns:
        Optional[dict]: é€‰ä¸­çš„ææ–™ä¿¡æ¯ï¼Œæ ¼å¼ä¸º{"id": str, "name": str, "materialType": int, "content": str}ï¼Œæ— åˆé€‚ææ–™æ—¶è¿”å›None
    """
    if not materials:
        print("[MATERIAL_SELECT] æ²¡æœ‰å¯ç”¨çš„ææ–™")
        return None

    try:
        # æ„å»ºææ–™åˆ—è¡¨æè¿°
        material_type_names = {
            2: "å›¾ç‰‡", 3: "è§†é¢‘", 4: "å¡ç‰‡é“¾æ¥", 5: "å¡ç‰‡", 6: "è¯­éŸ³", 7: "æ–‡ä»¶"
        }

        materials_text = "\n".join([
            f"{i+1}. [{material_type_names.get(m.get('materialType', 2), 'æœªçŸ¥ç±»å‹')}] {m['name']}"
            for i, m in enumerate(materials)
        ])

        # æ·»åŠ å¯¹è¯ä¸Šä¸‹æ–‡
        context_text = ""
        if context_messages:
            recent_messages = context_messages[-5:]  # æœ€è¿‘5æ¡æ¶ˆæ¯
            context_list = []
            for msg in recent_messages:
                if hasattr(msg, 'content'):
                    content = msg.content
                elif isinstance(msg, dict):
                    content = msg.get('content', '')
                else:
                    content = str(msg)

                # åŒºåˆ†ç”¨æˆ·å’ŒAIæ¶ˆæ¯
                if hasattr(msg, 'type') and msg.type == 'human':
                    context_list.append(f"ç”¨æˆ·: {content}")
                elif hasattr(msg, 'type') and msg.type in ['ai', 'assistant']:
                    context_list.append(f"AI: {content}")
                else:
                    context_list.append(f"æ¶ˆæ¯: {content}")

            context_text = "\n".join(context_list)

        # æ„å»ºæ™ºèƒ½é€‰æ‹©æç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½ææ–™é€‰æ‹©åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ä»ææ–™åº“ä¸­é€‰æ‹©æœ€åˆé€‚çš„ææ–™ã€‚

**ç”¨æˆ·æœ€æ–°æ¶ˆæ¯**: "{user_message}"

**å¯¹è¯ä¸Šä¸‹æ–‡**:
{context_text}

**å¯ç”¨çš„ææ–™åˆ—è¡¨**:
{materials_text}

**ææ–™ç±»å‹è¯´æ˜**:
- å›¾ç‰‡ï¼ˆmaterialType=2ï¼‰ï¼šé€‚åˆå±•ç¤ºé™æ€å†…å®¹ï¼Œå¦‚ç¯å¢ƒã€æ¡ˆä¾‹ã€æ•ˆæœå›¾ã€ä½ç½®ç­‰
- è§†é¢‘ï¼ˆmaterialType=3ï¼‰ï¼šé€‚åˆå±•ç¤ºåŠ¨æ€å†…å®¹ï¼Œå¦‚ä»‹ç»ã€æ¼”ç¤ºã€æ“ä½œæµç¨‹ç­‰
- å¡ç‰‡é“¾æ¥ï¼ˆmaterialType=4ï¼‰ï¼šé€‚åˆæä¾›è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚å•†å“è¯¦æƒ…ã€ä»·æ ¼ã€æœåŠ¡ä»‹ç»ç­‰
- å¡ç‰‡ï¼ˆmaterialType=5ï¼‰ï¼šé€‚åˆå±•ç¤ºç»“æ„åŒ–ä¿¡æ¯ï¼Œå¦‚äº§å“å¡ç‰‡ã€æœåŠ¡å¡ç‰‡ç­‰
- è¯­éŸ³ï¼ˆmaterialType=6ï¼‰ï¼šé€‚åˆè¯­éŸ³å›å¤ï¼Œå¦‚éŸ³é¢‘æ¶ˆæ¯ç­‰
- æ–‡ä»¶ï¼ˆmaterialType=7ï¼‰ï¼šé€‚åˆæ–‡æ¡£èµ„æ–™ï¼Œå¦‚PDFã€Wordç­‰

**æ™ºèƒ½é€‰æ‹©æŒ‡å—**:
1. **ç†è§£ç”¨æˆ·æ„å›¾**: æ·±å…¥åˆ†æç”¨æˆ·æ¶ˆæ¯çš„çœŸå®éœ€æ±‚
2. **ç±»å‹åŒ¹é…**: æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©æœ€åˆé€‚çš„ææ–™ç±»å‹
3. **å†…å®¹ç›¸å…³æ€§**: é€‰æ‹©å†…å®¹æœ€ç›¸å…³ã€èƒ½å¤Ÿç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„ææ–™
4. **ä¸Šä¸‹æ–‡å…³è”**: è€ƒè™‘å¯¹è¯å†å²ï¼Œé€‰æ‹©èƒ½å¤Ÿå»¶ç»­å¯¹è¯é€»è¾‘çš„ææ–™
5. **å®ç”¨æ€§ä¼˜å…ˆ**: é€‰æ‹©æœ€èƒ½å¸®åŠ©ç”¨æˆ·çš„ææ–™

**é€‰æ‹©ç­–ç•¥**:
- å¦‚æœç”¨æˆ·è¯¢é—®"åœ¨å“ªé‡Œ"æˆ–"æ€ä¹ˆèµ°"æˆ–"ä½ç½®"ï¼Œé€‰æ‹©åŒ…å«ä½ç½®ä¿¡æ¯çš„å›¾ç‰‡
- å¦‚æœç”¨æˆ·æƒ³è¦"çœ‹çœ‹æ ·å­"æˆ–"é•¿ä»€ä¹ˆæ ·"æˆ–"å¤–è§‚"ï¼Œé€‰æ‹©å›¾ç‰‡ç±»å‹
- å¦‚æœç”¨æˆ·è¯¢é—®"ç¯å¢ƒæ€ä¹ˆæ ·"æˆ–"åº—é¢"ï¼Œé€‰æ‹©å±•ç¤ºç¯å¢ƒçš„å›¾ç‰‡
- å¦‚æœç”¨æˆ·æƒ³è¦"å®¢æˆ·æ¡ˆä¾‹"æˆ–"æ•ˆæœå›¾"ï¼Œé€‰æ‹©å±•ç¤ºæ¡ˆä¾‹çš„å›¾ç‰‡æˆ–è§†é¢‘
- å¦‚æœç”¨æˆ·æƒ³è¦"çœ‹ä»‹ç»"æˆ–"äº†è§£è¯¦æƒ…"æˆ–"æ¼”ç¤º"ï¼Œé€‰æ‹©è§†é¢‘æˆ–å¡ç‰‡é“¾æ¥
- å¦‚æœç”¨æˆ·è¯¢é—®"ä»·æ ¼"æˆ–"æœåŠ¡è¯¦æƒ…"ï¼Œé€‰æ‹©å¡ç‰‡é“¾æ¥ç±»å‹
- å¦‚æœç”¨æˆ·æƒ³è¦"æ–‡æ¡£"æˆ–"èµ„æ–™"ï¼Œé€‰æ‹©æ–‡ä»¶ç±»å‹
- å¦‚æœç”¨æˆ·æƒ³è¦è¯­éŸ³å›å¤ï¼Œé€‰æ‹©è¯­éŸ³ç±»å‹

**è¾“å‡ºè¦æ±‚**:
è¯·è¿”å›JSONæ ¼å¼ï¼š
{{"selected_name": "ææ–™åç§°", "material_type": ææ–™ç±»å‹æ•°å­—, "reason": "é€‰æ‹©ç†ç”±"}}
å¦‚æœæ²¡æœ‰åˆé€‚çš„ææ–™ï¼Œè¿”å›ï¼š
{{"selected_name": null, "material_type": null, "reason": "æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„ææ–™"}}
"""

        # è°ƒç”¨AIè¿›è¡Œæ™ºèƒ½é€‰æ‹©
        try:
            client = await get_openai_client()
            response = await client.chat.completions.create(
                model=_normalize_model_name_for_openrouter(_cfg.get("generation_model", _cfg.get("model_name", "gpt-4o-mini"))),
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ææ–™é€‰æ‹©åŠ©æ‰‹ï¼Œæ“…é•¿ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶ä»ææ–™åº“ä¸­é€‰æ‹©æœ€åˆé€‚çš„ææ–™ç±»å‹å’Œå†…å®¹ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=300,
                temperature=0.2
            )

            result_text = response.choices[0].message.content.strip()
            print(f"[MATERIAL_SELECT] AIé€‰æ‹©ç»“æœ: {result_text}")

            # è§£æJSONç»“æœ
            try:
                result = json.loads(result_text)
                selected_name = result.get("selected_name")
                material_type = result.get("material_type")
                reason = result.get("reason", "")

                print(f"[MATERIAL_SELECT] è§£æç»“æœ - åç§°: {selected_name}, ç±»å‹: {material_type}, ç†ç”±: {reason}")

                # æ£€æŸ¥æ˜¯å¦æœ‰åˆé€‚çš„é€‰æ‹©
                if not selected_name or selected_name is None:
                    print("[MATERIAL_SELECT] AIåˆ¤æ–­æ— åˆé€‚ææ–™")
                    return None

                # æŸ¥æ‰¾å¯¹åº”çš„ææ–™
                for material in materials:
                    if material['name'] == selected_name and material.get('materialType') == material_type:
                        print(f"[MATERIAL_SELECT] æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ææ–™: {selected_name} (ç±»å‹: {material_type})")
                        return material

                # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•ä»…åç§°åŒ¹é…
                for material in materials:
                    if material['name'] == selected_name:
                        print(f"[MATERIAL_SELECT] æ‰¾åˆ°åç§°åŒ¹é…ææ–™: {selected_name} (å®é™…ç±»å‹: {material.get('materialType')})")
                        return material

                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                for material in materials:
                    if selected_name in material['name'] or material['name'] in selected_name:
                        print(f"[MATERIAL_SELECT] æ‰¾åˆ°æ¨¡ç³ŠåŒ¹é…ææ–™: {material['name']}")
                        return material

                print(f"[MATERIAL_SELECT] æœªæ‰¾åˆ°åŒ¹é…ææ–™: {selected_name}")
                return None

            except json.JSONDecodeError as e:
                print(f"[MATERIAL_SELECT] JSONè§£æå¤±è´¥: {e}")
                print(f"[MATERIAL_SELECT] åŸå§‹å“åº”: {result_text}")
                return None

        except Exception as e:
            print(f"[MATERIAL_SELECT] AIé€‰æ‹©å¤±è´¥: {e}")
            return None

    except Exception as e:
        print(f"[MATERIAL_SELECT] é€‰æ‹©ææ–™å¼‚å¸¸: {e}")
        return None



async def detect_image_request(user_message: str) -> bool:
    """
    ä½¿ç”¨AIæ¨¡å‹æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦åŒ…å«å‘é€å›¾ç‰‡çš„è¯·æ±‚

    Args:
        user_message: ç”¨æˆ·æ¶ˆæ¯

    Returns:
        bool: æ˜¯å¦éœ€è¦å‘é€å›¾ç‰‡
    """
    print("=" * 80)
    print("ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] å¼€å§‹æ‰§è¡Œdetect_image_request")
    print("=" * 80)
    print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] è¾“å…¥æ¶ˆæ¯: '{user_message}'")

    try:
        print("ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] æ­£åœ¨æ„å»ºAIæ£€æµ‹æç¤ºè¯...")

        # æ„å»ºAIæ£€æµ‹æç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨åˆ¤æ–­ç”¨æˆ·æ˜¯å¦éœ€è¦å‘é€å¤šåª’ä½“å†…å®¹ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€å¡ç‰‡é“¾æ¥ï¼‰ã€‚

è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯å¦æ˜ç¡®æˆ–éšå«è¡¨è¾¾äº†éœ€è¦ä½ å‘é€å¤šåª’ä½“å†…å®¹çš„éœ€æ±‚ã€‚

**ç”¨æˆ·æ¶ˆæ¯**: "{user_message}"

**åˆ¤æ–­æ ‡å‡†**:
1. æ˜ç¡®è¯·æ±‚å›¾ç‰‡ï¼šå¦‚"å‘å¼ ç…§ç‰‡"ã€"æ¥å¼ å›¾ç‰‡"ã€"çœ‹ä¸€ä¸‹æ•ˆæœ"ç­‰
2. è¯¢é—®è§†è§‰ä¿¡æ¯ï¼šå¦‚"é•¿ä»€ä¹ˆæ ·"ã€"åœ¨å“ªé‡Œ"ã€"æ€ä¹ˆèµ°"ç­‰
3. è¦æ±‚æŸ¥çœ‹æ¡ˆä¾‹ï¼šå¦‚"å®¢æˆ·æ¡ˆä¾‹"ã€"æ•ˆæœå›¾"ã€"ç¯å¢ƒç…§ç‰‡"ç­‰
4. å…¶ä»–éœ€è¦è§†è§‰å±•ç¤ºçš„æƒ…å†µ
5. è¯·æ±‚è§†é¢‘å†…å®¹ï¼šå¦‚"å‘ä¸ªè§†é¢‘"ã€"çœ‹çœ‹è§†é¢‘"ã€"è§†é¢‘ä»‹ç»"ç­‰
6. è¯·æ±‚å¡ç‰‡é“¾æ¥ï¼šå¦‚"å‘ä¸ªé“¾æ¥"ã€"çœ‹çœ‹è¯¦æƒ…"ã€"å¡ç‰‡é“¾æ¥"ç­‰
7. è¦æ±‚æŸ¥çœ‹æ¼”ç¤ºï¼šå¦‚"æ¼”ç¤ºè§†é¢‘"ã€"æ“ä½œè§†é¢‘"ç­‰

**è¾“å‡ºè¦æ±‚**:
- å¦‚æœéœ€è¦å‘é€å¤šåª’ä½“å†…å®¹ï¼Œè¿”å›ï¼šYES
- å¦‚æœä¸éœ€è¦å‘é€å¤šåª’ä½“å†…å®¹ï¼Œè¿”å›ï¼šNO
- åªè¿”å›YESæˆ–NOï¼Œä¸è¦å…¶ä»–å†…å®¹

è¯·åˆ¤æ–­ï¼š
"""
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] æç¤ºè¯æ„å»ºå®Œæˆï¼Œé•¿åº¦: {len(prompt)} å­—ç¬¦")

        print("ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] æ­£åœ¨è·å–OpenAIå®¢æˆ·ç«¯...")
        client = await get_openai_client()
        print("ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] OpenAIå®¢æˆ·ç«¯è·å–æˆåŠŸ")

        model_name = _normalize_model_name_for_openrouter(_cfg.get("generation_model", _cfg.get("model_name", "gpt-4o-mini")))
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] å°†ä½¿ç”¨çš„æ¨¡å‹: {model_name}")

        print("ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] æ­£åœ¨è°ƒç”¨AIæ¨¡å‹è¿›è¡Œåˆ¤æ–­...")
        response = await client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªå¤šåª’ä½“å†…å®¹è¯·æ±‚æ£€æµ‹åŠ©æ‰‹ï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯å¦éœ€è¦å‘é€å¤šåª’ä½“å†…å®¹ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€å¡ç‰‡é“¾æ¥ï¼‰ï¼Œè¿”å›YESæˆ–NOã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=10,  # åªè¿”å›YESæˆ–NOï¼Œ10ä¸ªtokenè¶³å¤Ÿ
            temperature=0.1  # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
        )
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] AIæ¨¡å‹è°ƒç”¨å®Œæˆï¼Œå“åº”ç±»å‹: {type(response)}")

        result = response.choices[0].message.content.strip().upper()
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] AIåˆ¤æ–­ç»“æœ: '{result}'")

        # åˆ¤æ–­ç»“æœ
        if result == "YES":
            print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] âœ… AIæ£€æµ‹åˆ°å›¾ç‰‡è¯·æ±‚: '{user_message}'")
            return True
        else:
            print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] âŒ AIåˆ¤æ–­ä¸éœ€è¦å‘é€å›¾ç‰‡: '{user_message}'")
            return False

    except Exception as e:
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] âŒ AIæ£€æµ‹å›¾ç‰‡è¯·æ±‚å¼‚å¸¸: {e}")
        import traceback
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}")

        # AIè°ƒç”¨å¤±è´¥æ—¶ï¼Œä½¿ç”¨ç®€å•çš„å…³é”®è¯å…œåº•
        print("ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] ä½¿ç”¨å…³é”®è¯å…œåº•æ£€æµ‹...")
        simple_keywords = ["å›¾ç‰‡", "ç…§ç‰‡", "æ¡ˆä¾‹", "æ•ˆæœ", "åœ°å€", "ä½ç½®", "ç¯å¢ƒ"]
        has_keyword = any(keyword in user_message.lower() for keyword in simple_keywords)
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] å…³é”®è¯æ£€æµ‹ç»“æœ: {has_keyword}")
        print(f"ğŸ” [DEBUG-å›¾ç‰‡è¯·æ±‚æ£€æµ‹] å…³é”®è¯å…œåº•æœ€ç»ˆç»“æœ: {has_keyword}")
        return has_keyword

