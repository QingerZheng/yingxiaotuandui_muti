"""
RAGç³»ç»Ÿå·¥å…·å‡½æ•°
æä¾›æ–‡æ¡£å¤„ç†ã€æ¨¡å‹åŠ è½½ç­‰é€šç”¨åŠŸèƒ½

æ”¯æŒåŠŸèƒ½:
1. å¤šæ ¼å¼æ–‡æ¡£åŠ è½½å’Œåˆ†å—
2. æ–‡æ¡£ä¸‹è½½å’Œç¼“å­˜
3. è¯­è¨€æ¨¡å‹ç®¡ç†
4. æ–‡ä»¶æ ¼å¼è¯†åˆ«
"""
import os
from typing import List

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import UnstructuredWordDocumentLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import UnstructuredFileLoader
import requests

# å¯¼å…¥å¤šæ¨¡æ€å¤„ç†åŠŸèƒ½
from .multimodal_processor import (
    get_multimodal_processor, 
    get_multimodal_supported_formats,
    create_multimodal_documents
)


def load_and_chunk_document(
    file_path: str,
    chunk_size: int = 200,
    chunk_overlap: int = 0,
    **loader_kwargs,
) -> List[Document]:
    """
    é€šç”¨æ–‡æ¡£åŠ è½½å’Œåˆ†å—å‡½æ•°ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆåŒ…æ‹¬å¤šæ¨¡æ€ï¼‰
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - Wordæ–‡æ¡£: .docx, .doc (æ–‡æœ¬+å›¾ç‰‡OCR+è¡¨æ ¼)
    - PDFæ–‡æ¡£: .pdf (æ–‡æœ¬+è¡¨æ ¼æå–+å›¾ç‰‡OCR)
    - æ–‡æœ¬æ–‡ä»¶: .txt, .md
    - å›¾ç‰‡æ–‡ä»¶: .jpg, .jpeg, .png, .bmp (OCRæ–‡å­—è¯†åˆ«)
    - PPTæ–‡æ¡£: .pptx, .ppt (æ–‡æœ¬+å›¾ç‰‡OCR+è¡¨æ ¼)
    - Excelæ–‡æ¡£: .xlsx, .xls (è¡¨æ ¼æ•°æ®)
    - å…¶ä»–æ ¼å¼: ä½¿ç”¨UnstructuredFileLoaderå°è¯•å¤„ç†
    
    Args:
        file_path (str): æ–‡æ¡£æ–‡ä»¶è·¯å¾„
        chunk_size (int): æ¯ä¸ªæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°
        chunk_overlap (int): æ–‡æœ¬å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
        **loader_kwargs: ä¼ é€’ç»™æ–‡æ¡£åŠ è½½å™¨çš„é¢å¤–å‚æ•°
        
    Returns:
        List[Document]: åˆ†å—åçš„æ–‡æ¡£åˆ—è¡¨

    Example:
        # å¤„ç†PDFæ–‡ä»¶
        pdf_chunks = load_and_chunk_document("document.pdf")
        
        # å¤„ç†å›¾ç‰‡æ–‡ä»¶ï¼ˆOCRï¼‰
        image_chunks = load_and_chunk_document("image.jpg")
    """
    
    # è·å–æ–‡ä»¶æ‰©å±•å
    file_extension = os.path.splitext(file_path)[1].lower()
    
    print(f"ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶æ ¼å¼: {file_extension}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¨¡æ€æ ¼å¼
    multimodal_formats = get_multimodal_supported_formats()
    
    if file_extension in multimodal_formats:
        print(f"ğŸ¯ ä½¿ç”¨å¤šæ¨¡æ€å¤„ç†å™¨: {multimodal_formats[file_extension]}")
        try:
            processor = get_multimodal_processor()
            multimodal_docs = create_multimodal_documents(file_path, processor)
            
            if multimodal_docs:
                # å¯¹å¤šæ¨¡æ€æ–‡æ¡£è¿›è¡Œåˆ†å—
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=chunk_size, 
                    chunk_overlap=chunk_overlap
                )
                chunked_docs = text_splitter.split_documents(multimodal_docs)
                print(f"âœ… å¤šæ¨¡æ€æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…± {len(chunked_docs)} ä¸ªç‰‡æ®µ")
                return chunked_docs
            else:
                print("âš ï¸  å¤šæ¨¡æ€å¤„ç†æœªæå–åˆ°å†…å®¹ï¼Œå°è¯•ä¼ ç»Ÿæ–¹æ³•")
        except Exception as e:
            print(f"âš ï¸  å¤šæ¨¡æ€å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•: {str(e)}")
         
    # ä¼ ç»Ÿæ–‡æ¡£å¤„ç†æ–¹å¼
    try:
        # æ ¹æ®æ–‡ä»¶æ ¼å¼é€‰æ‹©åˆé€‚çš„åŠ è½½å™¨
        if file_extension in ['.docx', '.doc']:
            print("ğŸ“ ä½¿ç”¨Wordæ–‡æ¡£åŠ è½½å™¨")
            loader = UnstructuredWordDocumentLoader(file_path, **loader_kwargs)
        elif file_extension == '.pdf':
            print("ğŸ“‘ ä½¿ç”¨PDFæ–‡æ¡£åŠ è½½å™¨")
            loader = PyPDFLoader(file_path)
            
            # å°è¯•é¢å¤–çš„PDFè¡¨æ ¼æå–
            try:
                processor = get_multimodal_processor()
                pdf_tables = processor.extract_tables_from_pdf(file_path)
                if pdf_tables:
                    print(f"ğŸ“Š é¢å¤–æå–äº† {len(pdf_tables)} ä¸ªPDFè¡¨æ ¼")
            except:
                pass  # å¿½ç•¥è¡¨æ ¼æå–é”™è¯¯
                
        elif file_extension in ['.txt', '.md']:
            print("ğŸ“ƒ ä½¿ç”¨æ–‡æœ¬æ–‡ä»¶åŠ è½½å™¨")
            loader = TextLoader(file_path, encoding='utf-8')
        else:
            print(f"ğŸ”§ ä½¿ç”¨é€šç”¨æ–‡æ¡£åŠ è½½å™¨å¤„ç† {file_extension} æ ¼å¼")
            loader = UnstructuredFileLoader(file_path, **loader_kwargs)
        
        # åŠ è½½æ–‡æ¡£
        docs = loader.load()
        print(f"âœ… æ–‡æ¡£åŠ è½½æˆåŠŸï¼Œå…± {len(docs)} é¡µ/æ®µ")
        
        # æ–‡æœ¬åˆ†å—
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, 
            chunk_overlap=chunk_overlap
        )
        chunked_docs = text_splitter.split_documents(docs)
        
        print(f"âœ… æ–‡æ¡£åˆ†å—å®Œæˆï¼Œå…± {len(chunked_docs)} ä¸ªç‰‡æ®µ")
        return chunked_docs
         
    except Exception as e:
        print(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
        raise

  
def download_doc(file_url_or_path: str) -> str:
    """
    å¤„ç†æ–‡æ¡£æ–‡ä»¶ï¼ˆæ”¯æŒæœ¬åœ°æ–‡ä»¶å’ŒURLä¸‹è½½ï¼‰
    
    Args:
        file_url_or_path (str): æ–‡æ¡£æ–‡ä»¶çš„URLæˆ–æœ¬åœ°æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°æ–‡ä»¶ç›´æ¥è¿”å›ï¼ŒURLä¸‹è½½åè¿”å›æœ¬åœ°è·¯å¾„ï¼‰

    æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼š
        - æœ¬åœ°æ–‡ä»¶è·¯å¾„: ./document.docx, /path/to/file.pdf
        - ç½‘ç»œURL: https://example.com/document.docx
        
    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š
        - Wordæ–‡æ¡£: .docx, .doc
        - PDFæ–‡æ¡£: .pdf
        - æ–‡æœ¬æ–‡ä»¶: .txt, .md
        - å›¾ç‰‡æ–‡ä»¶: .jpg, .png, .bmp (å¤šæ¨¡æ€)
        - PPTæ–‡æ¡£: .pptx, .ppt (å¤šæ¨¡æ€)
        - Excelæ–‡æ¡£: .xlsx, .xls (å¤šæ¨¡æ€)
        - å…¶ä»–æ–‡æ¡£æ ¼å¼
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
    if not file_url_or_path.startswith(('http://', 'https://', 'ftp://')):
        print(f"ğŸ“ æ£€æµ‹åˆ°æœ¬åœ°æ–‡ä»¶è·¯å¾„: {file_url_or_path}")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
        possible_paths = [
            file_url_or_path,  # åŸå§‹è·¯å¾„
            os.path.join(os.getcwd(), file_url_or_path),  # ç›¸å¯¹äºå½“å‰ç›®å½•
            os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), file_url_or_path)  # ç›¸å¯¹äºä¸Šçº§ç›®å½•
        ]
        
        # å°è¯•æ¯ä¸ªè·¯å¾„
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            print(f"ğŸ“‚ å°è¯•è·¯å¾„: {abs_path}")
            if os.path.exists(abs_path):
                file_extension = os.path.splitext(abs_path)[1].lower()
                print(f"âœ… æ‰¾åˆ°æ–‡ä»¶ï¼Œæ ¼å¼: {file_extension}")
                return abs_path
        
        # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œæ‰“å°å°è¯•è¿‡çš„è·¯å¾„å¹¶æŠ›å‡ºå¼‚å¸¸
        error_msg = "æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è¿‡ä»¥ä¸‹è·¯å¾„:\n" + "\n".join(f"- {p}" for p in possible_paths)
        raise FileNotFoundError(error_msg)
            
    # URLä¸‹è½½é€»è¾‘ä¿æŒä¸å˜
    try:
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ–‡æ¡£: {file_url_or_path}")
        
        # é¦–å…ˆå°è¯•ç®€å•ä¸‹è½½ï¼ˆé€‚ç”¨äºç›´æ¥æ–‡ä»¶é“¾æ¥ï¼‰
        try:
            doc_response = requests.get(file_url_or_path, timeout=30)
            doc_response.raise_for_status()
            
            # æ£€æŸ¥æ˜¯å¦è·å–åˆ°äº†å®é™…æ–‡ä»¶
            content_type = doc_response.headers.get('content-type', '').lower()
            if 'text/html' in content_type:
                raise ValueError("è·å–åˆ°HTMLé¡µé¢")
            
            print(f"âœ… ç®€å•ä¸‹è½½æˆåŠŸï¼Œå†…å®¹ç±»å‹: {content_type}")
            
        except (requests.exceptions.RequestException, ValueError) as e:
            print(f"âš ï¸  ç®€å•ä¸‹è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•ä½¿ç”¨æµè§ˆå™¨æ¨¡æ‹Ÿä¸‹è½½...")
            
            # ä½¿ç”¨æµè§ˆå™¨æ¨¡æ‹Ÿä¸‹è½½ï¼ˆé€‚ç”¨äºéœ€è¦é‡å®šå‘çš„é“¾æ¥ï¼‰
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            # å…è®¸é‡å®šå‘ï¼Œè®¾ç½®è¶…æ—¶
            doc_response = requests.get(file_url_or_path, headers=headers, allow_redirects=True, timeout=30)
            doc_response.raise_for_status()
        
            # å†æ¬¡æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
            content_type = doc_response.headers.get('content-type', '').lower()
            print(f"ğŸ“„ å“åº”å†…å®¹ç±»å‹: {content_type}")
            
            # å¦‚æœè¿˜æ˜¯HTMLé¡µé¢ï¼Œè¯´æ˜è¿™ä¸ªé“¾æ¥éœ€è¦ç‰¹æ®Šå¤„ç†
            if 'text/html' in content_type:
                print("âš ï¸  ä»ç„¶æ£€æµ‹åˆ°HTMLå“åº”ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨ä¸‹è½½æˆ–ä½¿ç”¨ä¸åŒçš„URL")
                raise ValueError(f"æ— æ³•ä»æ­¤URLè·å–æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦ç›´æ¥ä¸‹è½½é“¾æ¥: {file_url_or_path}")
        
        # ä»URLè·å–æ–‡ä»¶å
        filename = file_url_or_path.split("/")[-1]
        
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        file_extension = os.path.splitext(filename)[1].lower()
        
        # è·å–æ‰€æœ‰æ”¯æŒçš„æ ¼å¼ï¼ˆåŒ…æ‹¬å¤šæ¨¡æ€æ ¼å¼ï¼‰
        multimodal_formats = get_multimodal_supported_formats()
        base_formats = ['.pdf', '.docx', '.doc', '.txt', '.md']
        all_supported_formats = base_formats + list(multimodal_formats.keys())
        
        if file_extension in all_supported_formats:
            format_desc = multimodal_formats.get(file_extension, "æ–‡æ¡£æ–‡ä»¶")
            print(f"âœ… æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension} ({format_desc})")
        else:
            print(f"âš ï¸  æœªæ˜ç¡®æ”¯æŒçš„æ ¼å¼ {file_extension}ï¼Œå°†å°è¯•é€šç”¨å¤„ç†")
        
        with open(filename, "wb") as f:
            f.write(doc_response.content)
            
        print(f"âœ… æ–‡æ¡£ä¸‹è½½å®Œæˆ: {filename}")
        return filename
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥ {file_url_or_path}: {e}")
        raise
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        raise
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºç°æ„å¤–é”™è¯¯: {e}")
        raise


def get_supported_formats():
    """
    è¿”å›æ”¯æŒçš„æ–‡æ¡£æ ¼å¼åˆ—è¡¨ï¼ˆåŒ…æ‹¬å¤šæ¨¡æ€æ ¼å¼ï¼‰
    
    Returns:
        dict: æ”¯æŒçš„æ ¼å¼å’Œå¯¹åº”çš„æè¿°
    """
    # åŸºç¡€æ ¼å¼ï¼ˆçº¯æ–‡æœ¬ï¼‰
    base_formats = {
        '.txt': 'çº¯æ–‡æœ¬æ–‡ä»¶',
        '.md': 'Markdownæ–‡ä»¶',
    }
    
    # è·å–å¤šæ¨¡æ€æ ¼å¼ï¼ˆåŒ…æ‹¬PDFã€Wordã€PPTã€Excelã€å›¾ç‰‡ç­‰ï¼‰
    multimodal_formats = get_multimodal_supported_formats()
    base_formats.update(multimodal_formats)
    
    # æ·»åŠ å…¶ä»–æ ¼å¼è¯´æ˜
    base_formats['others'] = 'å…¶ä»–æ ¼å¼ (é€šè¿‡UnstructuredFileLoaderå¤„ç†)'
    
    return base_formats


def load_chat_model(model_name: str, temperature: float = 0, **kwargs):
    """
    åŠ è½½èŠå¤©æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨LangChainåŸç”Ÿæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        **kwargs: å…¶ä»–æ¨¡å‹å‚æ•°
        
    Returns:
        LangChainå…¼å®¹çš„LLMå®ä¾‹
    """
    try:
        # è§£ææ¨¡å‹åç§°
        if '/' in model_name:
            provider, model = model_name.split('/', 1)
        else:
            provider = 'openai'
            model = model_name
        
        # ç»Ÿä¸€é€šè¿‡é¡¹ç›®å·¥å‚åˆ›å»ºï¼ˆé»˜è®¤ OpenRouterï¼‰
        if provider in ['openai', 'openrouter'] or model.startswith('gpt-'):
            from llm import create_llm
            model_provider = 'openrouter' if provider != 'openai' else 'openai'
            return create_llm(
                model_provider=model_provider,
                model_name=model,
                temperature=temperature,
                **kwargs
            )
        elif provider == 'anthropic' or model.startswith('claude-'):
            from langchain_anthropic import ChatAnthropic
            return ChatAnthropic(
                model=model,
                temperature=temperature,
                **kwargs
            )
        elif provider == 'google' or model.startswith('gemini-'):
            from langchain_google_genai import ChatGoogleGenerativeAI
            return ChatGoogleGenerativeAI(
                model=model,
                temperature=temperature,
                **kwargs
            )
        else:
            # å›é€€åˆ°é¡¹ç›®çš„é‡‡æ ·å™¨å·¥å‚ï¼ˆéœ€è¦åŒ…è£…ï¼‰
            from sampler.factory import SamplerFactory
            sampler, _ = SamplerFactory.get_sampler_and_cost(model_name)
            
            # åˆ›å»ºLangChainå…¼å®¹çš„åŒ…è£…å™¨
            from langchain_core.language_models.base import BaseLanguageModel
            from langchain_core.outputs import LLMResult, Generation
            from langchain_core.callbacks.manager import CallbackManagerForLLMRun
            from typing import List, Optional, Any
            
            class SamplerLLMWrapper(BaseLanguageModel):
                def __init__(self, sampler, temperature=0):
                    super().__init__()
                    self.sampler = sampler
                    self.temperature = temperature
                
                def _generate(
                    self,
                    messages: List,
                    stop: Optional[List[str]] = None,
                    run_manager: Optional[CallbackManagerForLLMRun] = None,
                    **kwargs: Any,
                ) -> LLMResult:
                    # è½¬æ¢æ¶ˆæ¯æ ¼å¼
                    text = "\n".join([msg.content if hasattr(msg, 'content') else str(msg) for msg in messages])
                    response = self.sampler.sample(text, temperature=self.temperature)
                    return LLMResult(generations=[[Generation(text=response)]])
                
                @property
                def _llm_type(self) -> str:
                    return "sampler_wrapper"
            
            return SamplerLLMWrapper(sampler, temperature)
            
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ {model_name}: {e}")
        # æœ€åçš„å›é€€é€‰é¡¹ï¼šèµ°å·¥å‚å¹¶ä½¿ç”¨ openrouter é»˜è®¤æ¨¡å‹
        from llm import create_llm
        return create_llm(
            model_provider='openrouter',
            model_name='x-ai/grok-3',
            temperature=temperature,
            **kwargs
        )
